\documentclass[12pt,a4paper, twoside, autooneside=false]{scrartcl}
% scrartcl ist eine abgeleitete Artikel-Klasse im Koma-Skript
% zur Kontrolle des Umbruchs Klassenoption draft verwenden


% die folgenden Packete erlauben den Gebrauch von Umlauten und ß
% in der Latex Datei
\usepackage[utf8]{inputenc}
% \usepackage[latin1]{inputenc} %  Alternativ unter Windows
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{hyperref}


\usepackage[pdftex]{graphicx}
\usepackage{latexsym}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{color}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{blkarray}
\usepackage{tkz-graph}
%\usepackage{fancyhdr}
\usepackage[automark]{scrlayer-scrpage}
\usetikzlibrary{graphs,graphs.standard}
\usetikzlibrary {automata}
\usetikzlibrary{matrix,calc}
\usetikzlibrary{arrows}
\tikzset{every loop/.style={}}
\makeatletter
\tikzset{my loop/.style =  {to path={
  \pgfextra{\let\tikztotarget=\tikztostart}
  [looseness=12,min distance=10mm]
  \tikz@to@curve@path},font=\sffamily\small
  }}  
\makeatletter 
\usepackage[top=35mm,bottom=25mm,rmargin=25mm,lmargin=35mm]{geometry}


% Abstand obere Blattkante zur Kopfzeile ist 2.54cm - 15mm
\setlength{\topmargin}{-15mm}


% Umgebungen für Definitionen, Sätze, usw.
% Es werden Sätze, Definitionen etc innerhalb einer Section mit 
% 1.1, 1.2 etc durchnummeriert, ebenso die Gleichungen mit (1.1), (1.2) ..
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{korollar}[theorem]{Corollary}
\newtheorem{satz}[theorem]{Satz}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{beispiel}[theorem]{Example}
\newtheorem{uebung}[theorem]{"Ubung}
\newtheorem{algorithm}[theorem]{Algorithm}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{bemerkung}[theorem]{Bemerkung}
                  
\numberwithin{equation}{section} 
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\rk}{\mathtt{rk}}
\DeclareMathOperator{\n}{\mathtt{n}}
\newcommand{\M}{\mathcal{M}} %Matroid
\DeclareMathOperator{\grk}{\mathbf{grk}} %rank for graphs


% einige Abkuerzungen
\newcommand{\C}{\mathbb{C}} % komplexe
\newcommand{\K}{\mathbb{K}} % komplexe
\newcommand{\R}{\mathbb{R}} % reelle
\newcommand{\Q}{\mathbb{Q}} % rationale
\newcommand{\Z}{\mathbb{Z}} % ganze
\newcommand{\N}{\mathbb{N}} % natuerliche

\begin{document}
  % Keine Seitenzahlen im Vorspann
  %\fancyhead[R0,LE]
  % Titelblatt der Arbeit
     \cfoot{}
     \chead{}
     \ofoot{}
  \begin{titlepage}
  \thispagestyle{empty}
    \includegraphics[scale=0.25]{logo.png} 
    \vspace*{1cm} 

 \begin{center} \large 
    
    Bachelorarbeit
    \vspace*{2cm}

    {\huge The Tutte Polynomial}
    
    \vspace*{0.3cm}
    
    {\Large for Graphs and Matroids}
    
    \vspace*{1.5cm}

    Nelli Funk
    \vspace*{1.5cm}

    22.02.2024
    \vspace*{2cm}


    Betreuung:\\ Erstprüfer: Prof. Dr. André Uschmajew \\ Zweitprüfer: Prof. Dr. Dirk Hachenberger \\[1cm]
    Fakultät für Mathematik \\ 
    Lehrstuhl Mathematical Data Science \\[1cm]
		Universität Augsburg
  \end{center}
\end{titlepage}

  % Inhaltsverzeichnis


\newpage\null\thispagestyle{empty}\newpage
 \tableofcontents
\newpage

  % Ab sofort Seitenzahlen in der Kopfzeile anzeigen
%\pagestyle{fancy}
%\fancyhf{}
%\fancyhead[RO]{\leftmark}
%\fancyhead[L]{\leftmark}
%\fancyhead[LO]{\thepage}
%\renewcommand{\headrulewidth}{0pt}
   \rehead{\rightmark}
   \lohead{\leftmark}
   \ohead*{\pagemark}
\section{Introduction}
Algebraic graph theory is a fascinating subject. It offers the pleasure of seeing many surprising and useful connections between two beautiful parts of mathematics: algebra and graph theory. We will see many of those throughout this thesis. We start in section 2.1 by defining a graph as a tuple of a vertex set and an edge set, where an edge is a connection between two vertices. In section 2.2 we will define the geometric dual of a graph before we introduce the deletion-contraction algorithm in section 2.3. This algorithm uses recursive formulas to compute several graph invariants, such as the number of spanning trees or the number of acyclic orientations. The recursive formulas hold for the actions of deleting or contracting an edge, depending on its kind. We differentiate between loops, bridges and ordinary edges. But it is also possible to compute several graph polynomials with this algorithm. We will introduce the \textit{chromatic polynomial}, the \textit{flow polynomial} and the \textit{reliability polynomial}. \\
\indent The chromatic polynomial was introduced by George Birkhoff who aimed to prove the four color conjecture (now theorem). In general we will consider vertex colorings of a graph, where no two connected vertices have the same color. The chromatic polynomial takes the number of colors as an input and returns the number of different vertex colorings of such kind. The flow polynomial counts the number of nowhere-zero $A$-flows for a graph with an orientation and an additive abelian group $A$ with order $k$. Hence it takes the order of the group as an input and returns the number of nowhere-zero flows. For the reliability polynomial we consider a graph as a network and delete each edge with some propability $(1 - p)$. The reliability polynomial takes $p$ as an input and returns the propability that the network survives. \\ 
\indent
Thomas William Tutte \cite{Tu1947} was motivated by the first two polynomials to find a universal polynomial in such way, that any graph polynomial that satisfies some deletion-contraction recursion is in fact a specialization of the universal polynomial.
He named it the \textit{dichromate}, nowadays it is known as the \textit{Tutte polynomial} in his honor. Before defining this two variable polynomial on graphs, we want to define it on a more general construction called matroid. \\
\indent Chapter 3 is dedicated to give a short introduction into matroids, where we follow the same concept as for graphs in chapter 2. We start by defining a matroid through its ground set and its collection of independent sets. 
We then define the deletion and contraction action of subsets of matroids and use it to define the rank function of a matroid. We can also define a rank function on the dual of a matroid. These two rank functions are important for the definition of the Tutte polynomial on matroids. We will show that the Tutte polynomial satisfies some recursive deletion-contraction algorithm before we prove the recipe theorem from Dominic James Welsh \cite{We1999}. This theorem states that any matroid polynomial that satisfies a recursive deletion-contraction relation on ordinary edges and is multiplicative on direct sums, is in fact a specialization of the Tutte Polynomial for matroids. \\
\indent We will discuss how a graph can always be expressed as a matroid, but not every matroid can be expressed as a graph. The matroid for a graph $G = (V,E)$ has groundset $E$. We can compute the incidence matrix belonging to $G$ and consider the columns of the matrix as vectors in a vector space. The collection of independent sets for the matroid are the sets of edges whose corresponding vectors are linear independent. Hence the Tutte Polynomial can be defined on graphs. When proving that the graph polynomials from chapter 2 are specializations of the Tutte Polynomial, a particular problem arises. The recipe theorem can not be applied the way it was stated. Because there are two graph constructions that correspond to the direct some of matroids, the one point join and the distinct union of graphs. Also when we construct a matroid for some graph, we loose a lot of information about the vertices of the graph. For example, isolated vertices an no longer be observed. But this information is quite important for many graph polynomials. In section 4.4 we prove a recipe theorem for graph polynomials, that fixes this problem. \\
The last chapter scratches the surface of complexity of the Tutte polynomial and its applications. In fact Francois Jaeger, Dominic Vertigan and Dominic Welsh proved in their paper "On the computational complexity of the Jones and Tutte polynomials" \cite{JaVeWe1990} that the problem of evaluating the Tutte Polynomial at a point in the $(x,y)$-plane is $\#$-P hard, except at the hyperbola $(x - 1)(y - 1) = 1$ and for 8 specific points in the plane. We will also discuss what graph invariant needs to be bounded such that this problem is in P. We finish the thesis with connections between topological knot theory and the Tutte polynomial and coding theory and the Tutte polynomial. A more detailed overview of all applications of the Tutte Polynomial surely gives "The Handbook of the Tutte Polynomial and Related Topics" edited by Joanna Ellis-Monaghan and Ian Moffatt \cite{ElMo2022}. The interested reader may also find an overview of approximation results for the Tutte Polynomial in \cite{ElMo2022}. 
\newpage
%     \chead{}
%     \ohead{}
%     \ihead{}
%    \rehead{\rightmark}
%    \lohead{\leftmark}
%    \ohead*{\pagemark}
\section{Graphs}
Even though graph theory is a very interesting part of mathematics, it is not part of the undergraduate studies of every mathematician. Thus we are going to introduce in Section 2.1 the definitions used throughout this thesis in as little detail as needed. We mostly follow \cite{GoRo2001}. We introduce the notions of \textit{spanning forests}, \textit{bridges} and \textit{loops} with regard to the definition of \textit{bases}, \textit{coloops} and \textit{loops} for matroids in Chapter 3 and Chapter 4. In section 2.2 we will discuss \textit{planar graphs} and explain the construction of the \textit{geometric dual} of a planar graph. We also define the oparations of \textit{deleting} and \textit{contracting} an edge in Section 2.1, so that we can define the \textit{deletion-contraction algorithm} in Section 2.3. We use the deletion-contraction algorithm to compute the number of \textit{spanning trees} and the number of \textit{acyclic orientations} of a graph. Moreover, this algorithm can also be used to compute specific \textit{graph polynomials} belonging to a graph. In this thesis, we focus on the \textit{chromatic polynomial}, the \textit{flow polynomial} and the \textit{reliability polynomial}. Subsections 2.4.1 - 2.4.3 give a detailed introduction into each problem statement and show how each polynomial can be computed using the algorithm. We illustrate with different small examples throughout Section 2.4.
\subsection{Preliminaries in Graph Theory} 
This section focuses on the introduction into graph theory. We start by defining a \textit{graph} through an ordered tuple of \textit{vertices} and \textit{edges} and characterize relationships between those. The goal of this chapter is to get the reader familiarized with graphs and different graph theoretic definitions. To achieve this, we give different figurative examples.
\begin{definition}
A \textit{graph} $G = (V(G), E(G))$ consists of a \textit{vertex set} $V(G)$ and an \textit{edge set} $E(G)$, where an edge $e \in E(G)$ is an unordered pair $e = (u,v)$ of, not necessarily distinct, vertices $u,v \in V(G)$. We call $u$ and $v$ the \textit{end-vertices} of $e$. We call two edges $e_1, e_2$ \textit{multiple} or \textit{parallel}, if the end-vertices of $e_1$ are also the end-vertices of $e_2$.
\end{definition}
We will usually use $V,E$ for the vertex- and edgeset if the graph follows from the context.
\begin{definition} If $e = (u,v) \in E$, then $u$ and $v$ are called \textit{adjacent} or \textit{neighbours} and $u$ and $v$ are called \textit{incident} to the edge $e$. Two edges $e_1,e_2$ are called \textit{incident} if $e_1$ is incident to an end-vertex of $e_2$.
\end{definition}
\begin{definition}
Let $G = (V,E)$ be a graph and $e \in E$ an edge. Then the graph $G - e = (V, E - e)$ is obtained by deleting the edge $e$ from $E$. Let $v \in V$ be a vertex, then the graph $G - v = (V - v, \tilde{E})$ with $\tilde{E} = \{e \in E | \ e \  \text{not incident to } v\}$ is obtained by deleting $v$ and all edges incident to $v$. 
\end{definition}
\begin{beispiel}
One way to represent graphs are diagrams. Consider the graph $G = (V,E)$ with $V = \{u,v,w\}$ and $E = \{e_1 = (u,v), e_2 = (u,w)\}$. Figure 1 shows one representation of the graphs $G$, $G - e_1$ and $G - u$. 
\begin{center}
\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!10, 		thick, inner sep=0pt, minimum size=4.5mm}, baseline=-0.5ex]
	
	\node at (0,0) [knoten](1) {$v$};
	\node at (2,0) [knoten](2) {$w$};
	\node at (1, 1)[knoten](3) {$u$}
		edge[-] node[auto]{$e_2$}(2)
		edge[-] node[auto, swap]{$e_1$}(1); 
	\node at (5,0)[knoten](4) {$v$};
	\node at (7,0)[knoten](5){$w$};
	\node at (6,1)[knoten](6){$u$}
		edge[-] node[auto]{$e_2$}(5);
	\node at (10,0)[knoten](7){$v$};
	\node at (12,0)[knoten](8){$w$};
\end{tikzpicture}
\captionof{figure}{Representation of the graphs $G$, $G - e_1$ and $G - u$.}
\label{fig:label}
\end{center}
\end{beispiel}
\begin{definition}
A graph $G$ is called \textit{complete} if there exists an edge $e = (u,v) \in E(G)$ for every distinct pair $u,v \in V(G)$. For some $n \in \mathbb{N}$, we denote the complete graph on $n$ vertices by $K_n$. A graph with at least one vertex but no edges is called \textit{empty}. We call a graph $G$ \textit{bipartite}, if there exists a bipartition $A,B$ of the vertexset, such the vertices in $A$, $B$ respectively,  are pairwise non-adjacent. We denote such graphs by $K_{|A|,|B|}$.
\end{definition}
\begin{definition}
Let $G$ be a graph, we call $H$ a \textit{subgraph} of $G$ if 
\[
V(H) \subseteq V(G), \ \ \ \ E(H) \subseteq E(G).
\]
If $V(H) = V(G)$, we call $H$ a \textit{spanning subgraph} of $G$. We call $H$ an \textit{induced subgraph} of $G$ if the following holds for all vertices $u,v \in V(H)$: 
\[
(u,v) \in E(H) \Longleftrightarrow (u,v) \in E(G).
\]
\end{definition}
\begin{beispiel}
The following figure shows some spanning subgraphs of a graph $G$.
\begin{center}
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm}]

\node at (0,0)[knoten](1){};
\node at (1.5,0)[knoten](2){};
\node at (-0.75, 0.75)[knoten](3){};
\node at (0,1.5)[knoten](4){};
\node at (2.25, 0.75)[knoten](5){};
\node at (1.5,1.5)[knoten](6){};
\draw[ultra thick,blue!70] (1) -- (2);
\draw[thick, black](1) -- (6);
\draw[thick, black](3) -- (4);
\draw[thick, black](2) -- (6);
\draw[thick, black](2) -- (5);
\draw[thick, black](2) -- (4);
\draw[ultra thick,blue!70] (1) -- (3);
\draw[ultra thick,blue!70] (1) -- (4);
\draw[ultra thick,blue!70] (4) -- (6);
\draw[ultra thick,blue!70] (5) -- (6);


\node at (5,0)[knoten](7){};
\node at (6.5,0)[knoten](8){};
\node at (4.25, 0.75)[knoten](9){};
\node at (5,1.5)[knoten](10){};
\node at (7.25, 0.75)[knoten](11){};
\node at (6.5,1.5)[knoten](12){};
\draw[ultra thick,blue!70] (7) -- (8);
\draw[ultra thick, blue!70](7) -- (12);
\draw[ultra thick, blue!70](9) -- (10);
\draw[thick, black](8) -- (12);
\draw[thick, black](8) -- (11);
\draw[thick, black](8) -- (10);
\draw[ultra thick,blue!70] (7) -- (9);
\draw[ultra thick,blue!70] (7) -- (10);
\draw[ultra thick,blue!70] (10) -- (12);
\draw[ultra thick,blue!70] (11) -- (12);

\node at (10,0)[knoten](13){};
\node at (11.5,0)[knoten](14){};
\node at (9.25, 0.75)[knoten](15){};
\node at (10,1.5)[knoten](16){};
\node at (12.25, 0.75)[knoten](17){};
\node at (11.5,1.5)[knoten](18){};
\draw[ultra thick,blue!70] (13) -- (14);
\draw[thick,black](13) -- (18);
\draw[ultra thick, blue!70](15) -- (16);
\draw[thick, black](14) -- (18);
\draw[thick, black](14) -- (17);
\draw[thick, black](14) -- (16);
\draw[thick,black] (13) -- (15);
\draw[thick,black] (13) -- (16);
\draw[ultra thick,blue!70] (16) -- (18);
\draw[ultra thick,blue!70] (17) -- (18);
\end{tikzpicture}
\captionof{figure}{Three spanning subgraphs (in blue) of $G$.}
\end{center}
The graph has the complete graphs $K_3$ and $K_4$ as induced subgraphs. 
\begin{center}
\label{fig:label}
\end{center}
\begin{center}
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm}]

\node at (0,0)[knoten](1){};
\node at (1.5,0)[knoten](2){};
\node at (-0.75, 0.75)[knoten](3){};
\node at (0,1.5)[knoten](4){};
\node at (2.25, 0.75)[knoten](5){};
\node at (1.5,1.5)[knoten](6){};
\draw[thick,black] (1) -- (2);
\draw[thick, black](1) -- (6);
\draw[ultra thick, blue!70](3) -- (4);
\draw[thick, black](2) -- (6);
\draw[thick, black](2) -- (5);
\draw[thick, black](2) -- (4);
\draw[ultra thick,blue!70] (1) -- (3);
\draw[ultra thick,blue!70] (1) -- (4);
\draw[thick,black] (4) -- (6);
\draw[thick,black] (5) -- (6);


\node at (5,0)[knoten](7){};
\node at (6.5,0)[knoten](8){};
\node at (4.25, 0.75)[knoten](9){};
\node at (5,1.5)[knoten](10){};
\node at (7.25, 0.75)[knoten](11){};
\node at (6.5,1.5)[knoten](12){};
\draw[ultra thick,blue!70] (7) -- (8);
\draw[ultra thick, blue!70](7) -- (12);
\draw[thick, black](9) -- (10);
\draw[ultra thick, blue!70](8) -- (12);
\draw[thick, black](8) -- (11);
\draw[ultra thick, blue!70](8) -- (10);
\draw[thick,black] (7) -- (9);
\draw[ultra thick,blue!70] (7) -- (10);
\draw[ultra thick,blue!70] (10) -- (12);
\draw[thick,black] (11) -- (12);
\end{tikzpicture}
\captionof{figure}{$K_3$ and $K_4$ (in blue) as induced subgraphs.}
\label{fig:label}
\end{center}
\end{beispiel}
\begin{definition}
Let $G$ be a graph and consider a sequence $W = v_0e_1v_1\dots v_{k-1}e_kv_k$ of vertices and edges $e_i \in E$ such that $e_i = (v_{i-1}, v_i)$ for each $i$. This sequence is called a \textit{$v_0v_k$-walk}. If $W$ is a sequence of distinct vertices and edges, we call $W$ a \textit{path}. If $W$ is a sequence of distinct vertices and edges, except $v_0 = v_k$, we call $W$ a \textit{cycle}. A graph that doesn't contain any cycles is called \textit{acyclic}.
\end{definition}
\begin{definition}
A graph $G$ is called \textit{connected} if it contains a path between any two vertices, otherwise it is \textit{disconnected}. An induced and connected subgraph $H$, where for every $v \in V(H)$ there does not exist a path to any $u \not \in V(H)$, is called a \textit{connected component}. The \textit{number of connected components} of a graph $H$ is denoted by $c(H)$ and often referred to as the \textit{number of components}.
\end{definition}
\begin{definition}
An acyclic graph is called a \textit{forest}. If it is also connected, it is called a \textit{tree}. A spanning subgraph that is acyclic and connected is called a \textit{spanning tree}.
\end{definition}
\begin{theorem}
Let $G = (V(G), E(G))$ be a connected graph. Then 
\[
|E(G)| = |V(G)| - 1
\]
holds if and only if $G$ is a tree.
\end{theorem}
\begin{proof}
Let $G$ be an arbitrary connected graph on $n$ vertices and $m = n - 1$ edges. For a graph on $n$ vertices to be connected, it has to have at least $n - 1$ edges. Hence deleting an edge will result in a disconnected graph, such that $G$ is acyclic, thus a tree. \\
\indent Now let $G$ be a tree. We are going to use induction on the number of vertices. First let $V(G) = 1$. Then for $G$ to be a tree it needs $m = 0 = 1 - 1$ edges. Now suppose the statement holds for any tree on $n$ vertices and consider a graph $G$ with $V(G) = n + 1$. Deleting any egde from $G$ will result in a disconnected graph with connected components $G_1$ and $G_2$ which are acyclic because $G$ was acyclic. Therefore $G_1$ and $G_2$ are trees. Since $V(G_1) \leq n$ and $V(G_2) \leq n$ the induction hypothesis holds for these trees and we get $E(G_1) = V(G_1) - 1$, $E(G_2) = V(G_2) - 1$. But from $E(G) = E(G_1) + E(G_2) + 1$ it follows that 
\[
E(G) = V(G_1) + V(G_2) - 1 = V(G) - 1. \qedhere
\]
\end{proof}
\begin{definition} Let $G$ be a graph. An edge $e = (v,v)$ from a vertex $v$ to itself is called a \textit{loop}. If for some edge $f$ we have $c(G) < c(G - f)$, then $f$ is called a \textit{bridge}. An edge that is neither a loop nor a bridge is called \textit{ordinary}.
\end{definition}
\begin{center}
\begin{tikzpicture}
	[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto]	

\node at (0,0)[knoten](1){};
\node at (3,0) [knoten] (2) {}
		edge[-] node[auto,swap]{$g$} (1);
\node at (4, 1)[knoten] (3){} 
		edge[-] node[auto,swap]{$h_1$} (2);
\node at (4, -1) [knoten] (4){}
		edge[-] node[auto,swap] {$h_2$}(3)
		edge[-] node[auto] {$h_3$}(2);
\path  (1)   edge[my loop] node[above]  {$f$} (1);
\end{tikzpicture}
\captionof{figure}{Graph with loop $f$, bridge $g$ and ordinary edges $h_1$,$h_2$, $h_3$.}
\label{fig:label}
\end{center}  
Two representations of a graph can look very differently. Therefore we need to quantify if two representations come from the same graph.
\begin{definition}
Two graphs $G$, $H$ are called \textit{isomorphic}, if there exists a bijection 
\[
\varphi: V(G) \to V(H) 
\]
such that $(x,y) \in E(G)$ if and only if $(\varphi(u), \varphi(v)) \in E(H)$. We call $\varphi$ an \textit{isomorphism} from $G$ to $H$, and write $G \cong H$ if such a $\varphi$ exists.
\end{definition}
\begin{beispiel}
Figure 5 shows the graphs $G$ and $H$, whose chosen representations look quite different, but $G$ and $H$ are actually isomorphic.
\begin{center}
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm}]
\node at (0,0) [knoten](1){};
\node at (-0.33,1.33) [knoten](2){};
\node at (1.33,0)[knoten](3){};
\node at (1.66,1.33)[knoten](4){};
\node at (0.66,2)[knoten](5){}; 		
\draw (1) -- (2); 
\draw (1) -- (3); 
\draw (1) -- (5); 
\draw (2) -- (5); 
\draw (2) -- (3); 
\draw (3) -- (4); 
\draw (3) -- (5);
\draw (4) -- (5);

\node at (3.33,0)[knoten](6){};
\node at (5.33,0)[knoten](7){};
\node at (4.33, 0.66)[knoten](8){};
\node at (4.33, 2)[knoten](9){};
\node at (4.33, 1.33)[knoten](10){};
\draw (6) -- (7); 
\draw (6) -- (8); 
\draw (6) -- (9); 
\draw (6) -- (10); 
\draw (7) -- (8); 
\draw (7) -- (9); 
\draw (7) -- (10); 
\draw (9) -- (10);
\end{tikzpicture}
\captionof{figure}{Two isomorphic graphs on five vertices.}
\label{fig:label}
\end{center}
\end{beispiel}
\subsection{The Geometric  Dual of a Planar Graph}
So far we have been using the convenient representation of graphs through diagrams, where vertices are represented by points and edges by lines or curves. Now we are interested in drawing graphs in such a way, that no two edges intersect. Such a drawing is not always possible in the plane. If there exists such a drawing, the graph is called \textit{planar}. We will look at planar graphs following the definitions in chapter 4 of \cite{GoRo2001}. We are then going to give a detailed description of the construction of a dual graph. The concept of duality plays an important role in defining the Tutte Polynomial in Section 3.4. Later we are going to generalize duality to arbitrary graphs, when we introduce the dual to the cycle matroid in Section 4.2. \\ \indent To define planar graphs, we need to formalize the prozess of drawing a graph on the plane. To do this, we recall that a \textit{Jordan curve} in the plane is a continuous curve which does not intersect itself.  
\begin{definition}
Consider a function $\vartheta: V \to \mathbb{R}^2$ that maps each vertex $v$ of a graph $G$ to a distinct point $\vartheta(v)$ of the plane and each edge $e$ of $G$ to a Jordan curve $\gamma_e$ mapping $[0,1]$ to the plane joining its endpoints. Thus for an edge $e = (u,v)$, the corresponding curve satisfies $\gamma_{e}(0) = \vartheta(u)$ and $\gamma_{e}(1) = \vartheta(v)$. We call such a function a \textit{planar embedding} if the following two conditions are satisfied 
\begin{itemize}
\item[i)] for two nonincident edges $e_1$ and $e_2$ and their corresponding curves $\gamma_{e_1}$, $\gamma_{e_2}$: 
\[
\gamma_{e_1}(x) \neq \gamma_{e_2}(y) \ \forall x,y \in [0,1].
\]
\item[ii)] for two incident edges $f_1 = (u,v)$ and $f_2 = (v,w)$ and their corresponding curves $\gamma_{f_1}$, $\gamma_{f_2}$: 
\begin{center}
$\gamma_{f_1}(1) = \gamma_{f_2}(0)$ and $\gamma_{f_1}(x) \neq \gamma_{f_2}(y) \ \forall x \in \left[0, 1\right[ $ and $ \forall y \in \left]0,1\right].$
\end{center}
\end{itemize}
\end{definition}
\begin{definition}
A graph is called \textit{planar} if it has a planar embedding. We call a planar graph together with its planar embedding a \textit{plane} graph.
\end{definition}
\begin{beispiel}
The complete graph on $4$ vertices $K_4$ is planar, Figure 5 shows a planar embedding of $K_4$ and two nonplanar graphs.
\begin{center}
    \begin{tikzpicture}[bend angle=90,
        knoten/.style={circle, draw=black!100, thick, fill=black!20 ,
                inner sep=0pt, minimum size=2.5mm}]



        \node[knoten] (A) at (0,0) {};
        \node[knoten] (B) at (0,1) {};
        \node[knoten] (C) at (1,0) {};
        \node[knoten] (D) at (1,1) {};
        \draw (A) edge[-] node[auto,swap]{} (B);
        \draw (A) edge[-] node[auto,swap]{} (C);
        \draw (A) edge[-] node[auto,swap]{} (D);
        \draw (B) edge[-] node[auto,swap]{} (D);
        \draw (C) edge[-] node[auto,swap]{} (D);
        \draw (C) to [bend right = 100, looseness= 2.2] (B);
        
        \node[knoten] (E) at (3,0) {};
        \node[knoten] (F) at (4,0) {};
        \node[knoten] (G) at (2.75, 1) {};
        \node[knoten] (H) at (4.25, 1) {};
        \node[knoten] (I) at (3.5, 1.5) {};
        \draw (E) edge[-] node[auto,swap]{} (F);
        \draw (E) edge[-] node[auto,swap]{} (G);
        \draw (E) edge[-] node[auto,swap]{} (H);
        \draw (E) edge[-] node[auto,swap]{} (I);
        \draw (F) edge[-] node[auto,swap]{} (G);
        \draw (F) edge[-] node[auto,swap]{} (H);
        \draw (F) edge[-] node[auto,swap]{} (I);
        \draw (G) edge[-] node[auto,swap]{} (H);
        \draw (G) edge[-] node[auto,swap]{} (I);
        \draw (H) edge[-] node[auto,swap]{} (I);
        
        \node[knoten] (J) at (6,0) {};
        \node[knoten] (K) at (6,0.5) {};
        \node[knoten] (L) at (6,1) {};
        \node[knoten] (M) at (7,0) {};
        \node[knoten] (N) at (7,0.5) {};
        \node[knoten] (O) at (7,1) {};
        \draw (J) edge[-] node[auto,swap]{} (M);
        \draw (J) edge[-] node[auto,swap]{} (N); 
        \draw (J) edge[-] node[auto,swap]{} (O);
        \draw (K) edge[-] node[auto,swap]{} (M);
        \draw (K) edge[-] node[auto,swap]{} (N); 
        \draw (K) edge[-] node[auto,swap]{} (O);
        \draw (L) edge[-] node[auto,swap]{} (M);
        \draw (L) edge[-] node[auto,swap]{} (N); 
        \draw (L) edge[-] node[auto,swap]{} (O);
     \end{tikzpicture}
    \captionof{figure}{The plane graph $K_4$ and the nonplanar graphs $K_5$ and $K_{3,3}$.}
        \label{fig:label}
\end{center}
The graphs $K_5$ and $K_{3,3}$ are quite interesting for the studies of planar graphs. There is a well-known theorem due to Kuratowski, which states that a graph is planar if and only if it does not contain $K_5$ or $K_{3,3}$ as subgraphs. More discussions on this can be found in \cite{Wel1976}.
\end{beispiel}
To be able to construct the geometric dual of a plane graph, we need to define the area in the plane enclosed by the edges of the plane graph.
The edges of a planar graph together with a fixed embedding divide the plane into regions, which we call the \textit{faces} of the graph. For a given connected graph $G$, we can now construct a new graph. Firstly, the vertices of the new graph correspond to the faces of $G$, where each vertex is being placed in the planar embedding of the corresponding face. Secondly, every edge $e$ of $G$ gives rise to an edge of the new graph connecting the two faces of $G$, whose boundaries both contain $e$. 
\begin{definition} 
Let $G$ and $H$ be two graphs, their \textit{disjoint union} is  denoted by $G \sqcup H$ with vertex set $V(G \sqcup H) = V(G) \sqcup V(H)$ and edge set $E(G \sqcup H) = E(G) \sqcup E(H)$. 
\end{definition}
If $G$ is disconnected and has connected components $G_1, \dots, G_k$, then $G^\star$ is the disjoint union of the dual graphs for each connected component: $G^\star = G_1^\star \sqcup \dots \sqcup G_k^\star$.   
\begin{definition}
We call the resulting graph from this construction the dual graph and denote it by $G^\star$. 
\end{definition}
We are going to use the following example to describe the construction of a dual graph.  
\begin{beispiel}
Let us consider the following graph:
\begin{center}
    \begin{tikzpicture}[bend angle=90,
        knoten/.style={circle, draw=black!100, thick, fill=black!20 ,
                inner sep=0pt, minimum size=3.5mm}]

        \node[knoten] (A) at (0,0) {};
        \node[knoten] (B) at (0,2) {};
        \node[knoten] (C) at (2,0) {};
        \node[knoten] (D) at (2,2) {};
        \node[knoten] (E) at (3,1) {};
        \node[knoten] (K) at (5, 1.5) {};
        \node[knoten] (L) at (6, 0.5) {};
        \node[knoten] (M) at (4, -1) {};
        \draw (A) edge[-] node[auto,swap]{} (B);
        \draw (A) edge[-] node[auto,swap]{} (C);
        \draw (A) edge[-] node[auto,swap]{} (D);
        \draw (B) edge[-] node[auto,swap]{} (D);
        \draw (C) edge[-] node[auto,swap]{} (D);
        \draw (C) edge[-] node[auto,swap]{} (E);
        \draw (D) edge[-] node[auto,swap]{} (E);
        \draw (K) edge[-] node[auto,swap]{} (L);
        \path (B) edge [my loop] (B);
    \end{tikzpicture}
    \captionof{figure}{Graph $G$.}
        \label{fig:label}
\end{center}
To construct the dual graph $G^\star$ of $G$, place a blue vertex on each face of $G$ and connect each of them with a dashed edge $\hat{e}$, whenever the corresponding faces touch the same edge $e$ of $G$. We say the edges $\hat{e} \in G^\star$ and $e \in G$ are corresponding. This results in the graph shown in Figure 8.
\begin{center}
    \begin{tikzpicture}[bend angle=90,
        knoten/.style={circle, draw=black!100, thick, fill=black!20 ,
                inner sep=0pt, minimum size=3.5mm}]

        \node[knoten] (A) at (0,0) {};
        \node[knoten] (B) at (0,2) {};
        \node[knoten] (C) at (2,0) {};
        \node[knoten] (D) at (2,2) {};
        \node[knoten] (E) at (3,1) {};
        \node[knoten] (K) at (5, 1.5) {};
        \node[knoten] (L) at (6, 0.5) {};
        \node[knoten] (M) at (4, -1) {};
        \begin{scope}[knoten/.append style={fill=blue!30, minimum size =2.5mm}]
            \node[knoten] (F) at (1.4,0.8) {};
            \node[knoten] (G) at (0.5,1.5) {};
            \node[knoten] (H) at (0,2.4) {};
            \node[knoten] (I) at (-1.8, 1) {};
            \node[knoten] (J) at (2.4, 1) {};
            \node[knoten] (O) at (3.5, -1.25){};
            \node[knoten] (P) at (6, 1.5){};
        \end{scope}
        \draw (A) edge[-] node[auto,swap]{} (B);
        \draw (A) edge[-] node[auto,swap]{} (C);
        \draw (A) edge[-] node[auto,swap]{} (D);
        \draw (B) edge[-] node[auto,swap]{} (D);
        \draw (C) edge[-] node[auto,swap]{} (D);
        \draw (C) edge[-] node[auto,swap]{} (E);
        \draw (D) edge[-] node[auto,swap]{} (E);
        \draw (K) edge[-] node[auto,swap]{} (L);
        \path (B) edge [my loop] (B);
        \draw[dashed]
        		(G) to [] (F)
        		(G) to [bend left = 40] (I)
        		(F) to [] (J)
        		(J) to [out=60 , in=120, looseness = 2.5 ] (I)
        		(J) to [out = -60, in= 250, looseness= 2.2] (I)
        		(F) to [ bend left = 100, looseness = 1.6] (I)
        		(G) to [out= 60 , in=100 , looseness = 2.8] (I)
        		(H) to [out=170 , in =90 , looseness= 1.2] (I)
        		(P) to [out = 300, in = 240 , looseness= 50] (P);
    \end{tikzpicture}
    \captionof{figure}{Graph $G$ with dual graph $G^\star$.}
        \label{fig:label}
\end{center}
\end{beispiel}
In the previous example, the constructed dual graph is a planar graph. Indeed, the geometric dual of any plane graph is planar again. Moreover, constructing the dual graph ${G^\star}^\star$ of some dual graph $G^\star$ will result in $G$ again. For a detailed discussion on these concepts see \cite{Oxl2011}.
\subsection{The Deletion-Contraction Algorithm for Graphs}
In this section we will consider graph invariants which can be computed through a recursive algorithm, called the \textit{deletion-contraction algorithm}. The delete operation is defined in Definition 2.3. We start by defining the operation of contraction of an edge $e \in G$. We are going to follow the results from chapter 15 of \cite{GoRo2001}.
\begin{definition}
A \textit{graph invariant} is a function $f$ on a specified class of graphs such that for all $G$ and $H$ in the class the following holds:
\[
G \cong H \Longrightarrow f(G) = f(H).
\] 
A graph invariant whose image lies in some polynomial ring is called a \textit{graph polynomial}.
\end{definition}
\begin{definition}
Let $G$ be a graph and for $e = (u,v) \in E(G)$ consider the set 
\[
E_1 \coloneqq \{(x,y) | \ y  \ \text{is adjacent to} \ u\} \cup \{(x,y) | \ y  \ \text{is adjacent to} \ v\}.
\] We construct 
\[
G / e = ((V(G) - \{u,v\}) \cup \{x\} , \hat{E}),
\] with 
\[ \hat{E} = \left(E - \{e \in E | \ e \ \text{incident to} \ u \  \text{or} \ v\}\right) \cup E_1, \]
by deleting the edge $e$ from the edgeset and identifying the vertices $u,v$ as the vertex $x$. We say $G / e$ is obtained by \textit{contracting} $e$. 
\end{definition}

It is possible that the contracting action results in $G$ having loops or multiple edges, which is illustrated in Figure 9. For the computation of the number of spanning trees or the number of acyclic orientations for example, these can not just be ignored. 
\begin{center}
\begin{tikzpicture}
	[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto]	
	\node at (0,0) [knoten](1) {};
	\node at (2,0) [knoten](2) {}
		edge[-] node[auto]{$h$}(1);
	\node at (1,2) [knoten] (3) {}
		edge[-] node[auto]{$g$} (2)
		edge[-] node[auto]{$f$}(1)
		edge[- , bend right] node[auto,swap]{$e$} (1);
	\node at (4,0) [knoten](4) {}; 
	\node at (6,0) [knoten](5) {}
		edge[-] node[auto]{$h$}(4); 
	\node at (5,2) [knoten] (6) {}
		edge[-]node[auto,swap]{$f$}(4)
		edge[-]node[auto]{$g$}(5);
	\node at (8,0)[knoten](7) {};
	\node at (10,0) [knoten] (8) {}
		edge[-] node[auto]{$h$} (7)
		edge[-, bend right] node[auto,swap]{$g$} (7);
	\path  (7)   edge[my loop] node[above]  {$f$} (7);
%	\draw 	(7) edge[-] [ in=220,out=-220,loop] node [auto,swap] {$f$}();
\end{tikzpicture}
\captionof{figure}{Graph $G$, deletion $G - e$, and contraction $G / e$.}
\label{fig:label}
\end{center}
The operations of deleting and contracting edges are dual to each other, which the following theorem illustrates.
\begin{theorem}
Let $G$ be a plane graph and $e \in E(G)$ an ordinary edge. Let $G^\star$ be the geometric dual of $G$ and denote by $\hat{e}$ the edge in $G^\star$ corresponding to $e$. Then 
\begin{center}
$(G - e)^* = G^* / \hat{e}$ \ and \ $(G / e)^* = G^* - \hat{e}$.
\end{center}
\end{theorem}
\begin{proof}
Let $e = (u,v) \in G$ and $\hat{e} = (x,y) \in G^\star$ be the corresponding edge in the dual graph induced by $e$. Firstly, the connected component of $G - e$ containing $e$ has exactly one face less than $G$, hence the corresponding connected component of $(G - e)^\star$ has one vertex less than $G^\star$. The missing vertex was incident to the corresponding edge $\hat{e}$, so without loss of generality $x \not \in V((G - e)^\star)$. Since $e \not \in G - e$, the corresponding edge $\hat{e}$ is missing in the corresponding connected component of $(G - e)^\star$. Deleting $e$ from $G$ does not change the other faces of the planar embedding or the edges of $G$. Thus, the only differences are the missing vertex $x$ and edge $\hat{e}$, so that $(G - e)^\star = G^\star / \hat{e}$ holds. \\ 
\indent Now for the other equality we consider again $e = (u,v) \in G$ and $\hat{e} = (x,y) \in G^\star$. The action of contracting $e$ will result in the same number of faces, but one edge less. Hence the dual graph $(G / e)^\star$ has the same number of vertices as $G^\star$, but the corresponding edge $\hat{e}$ is missing, so that $(G / e)^\star = G^\star - \hat{e}$ holds.
\end{proof}
\begin{definition}
Let $G$ and $H$ be graphs. We call $H$ a \textit{minor} of $G$ if it results from deleting edges, deleting vertices, or contracting edges of $G$. We call a class $\mathcal{G}$ of graphs \textit{minor-closed} if, whenever $G$ is in $\mathcal{G}$, then every minor of $G$ is also in $\mathcal{G}$. 
\end{definition}
\begin{definition}
Let $\mathcal{G}$ be a minor-closed class of graphs and 
\[
f : \mathcal{G} \to \mathbb{R}, G \mapsto f(G)
\]
a function. We call a recursive algorithm for $f$ a \textit{deletion-contraction algorithm} if there are numbers $a_1, a_2, a_3, b_1, b_2, b_3, c \in \mathbb{R}$, such that the following equality holds for every edge $e \in E$.
\[
f(G) = \begin{cases}
a_1f(G - e) + b_1 f(G / e), & \text{if} \ e \ \text{is a loop} ; \\
a_2f(G - e) + b_2 f(G / e), &  \text{if} \ e \ \text{is a bridge}; \\
a_3f(G - e) + b_3 f(G / e), & \text{if} \ e \ \text{is ordinary}; \\
c, & \text{if} \ E(G) = \emptyset .
\end{cases}
\]
\end{definition}
One example of a graph parameter, which can be computed through a deletion-contraction algorithm is the number of spanning trees of a graph $G$.   
\begin{theorem}
Let $\tau(G)$ denote the number of spanning trees of a graph $G$, then 
\[
\tau(G) = \begin{cases}
\tau(G - e), & \text{if} \  e \ \text{is a loop}; \\
\tau(G / e), & \text{if} \ e \ \text{is a bridge}; \\
\tau(G -  e) + \tau(G/e), & \text{otherwise.}
\end{cases}
\]
\end{theorem}
\begin{proof} 
Let $G$ be a graph, $e \in E(G)$. First, if $e$ is a loop in $G$, then no spanning tree $T$ of $G$ contains $e$, thus we can delete $e$ and the spanning trees of $G - e$ are exactly the ones of $G$. Now, if $e$ is not a loop, then every spanning tree $T$ either contains $e$ or not, thus we can count them according to this distinction. The spanning trees that do not contain $e$ are exactly the spanning trees of $G - e$. Moreover if $e \in T$, then the trees $T / e$ are exactly the spanning trees of $G / e$. Therefore, 
\[
\tau(G) = \tau(G - e) + \tau(G/ e)
\]
However, if $e$ is a bridge in $G$, then $\tau(G - e) = 0$, since the graph $G - e$ is not connected, leaving us with $\tau(G) = \tau(G / e)$. 
\end{proof}
This in fact yields a recursive algorithm, since $G - e$ and $G / e$ are smaller graphs than $G$ compared to their number of edges, by applying these equations until there are only trees left. Deletion-contraction algorithms play a quite important role in the study of graph parameters. We now want to introduce another graph parameter that can be computed with such an algorithm.
\begin{definition}
We call a graph $G = (V,E)$ a \textit{directed graph} if $E$ is the set of ordered pairs of vertices. Each edge $e \in E$ is directed by the order $(\mathrm{head},\mathrm{tail})$ of its end-vertices, we write $\mathrm{head} \to \mathrm{tail}$.
 An \textit{orientation} $\omega$ is an assignment of a direction to each edge $e = (u,v) \in E$, either $ u \overset{\omega}{\to} v $ or $ u \overset{\omega}{\leftarrow} v$. We denote $G^\omega$ for a graph $G$ with a fixed orientation $\omega$.
\end{definition}
\begin{definition}
For a directed graph $G$, we call a walk a \textit{directed walk}, if consecutive edges $e = (u,v), f = (v, w)$ are directed as $u \to v$, $v \to w$. A cycle that is directed in this way, is called a \textit{directed cycle}. If $\omega$ is an orientation on a graph $G$ such that no directed cycles exist, we call $\omega$ an \textit{acyclic orientation}.
\end{definition}
Since we can assign one of two possible directions to each edge, there are $2^{|E(G)|}$ possible orientations. However, some of them might include oriented cycles. But the number of acyclic orientations can be computed similarly to the number of spanning trees by a deletion-contraction algorithm.
\begin{theorem}
Let $G$ be a graph, and let $\kappa(G)$ denote the number of it's acyclic orientations. Then 
\[
\kappa(G) = \begin{cases}
0, & \text{if} \ G \ \text{contains a loop}; \\
2 \kappa(G / e), & \text{if} \ e \ \text{is a bridge}; \\
\kappa(G - e) + \kappa(G / e), & \text{if} \ e \ \text{is ordinary}.
\end{cases}
\]
\end{theorem}
\begin{proof}
Any loop of the graph $G$ forms a cycle by itself, thus there are no acyclic orientations if $G$ contains a loop. Let $e = (u,v) \in G$ be a bridge. Then any acyclic orientation of $G$ can be formed by taking an orientation of $G / e$ and orienting $e$ either $ u \to v$ or $u \leftarrow v$. Now let $e = (u,v)$ be ordinary. An orientation of $G$ is acyclic if and only if the orientation restricted to $G - e$ is acyclic. Or similarly, the acyclic orientations of $G - e$ with $e$ oriented such that no cycle emerges, are exactly the acyclic orientations of $G$. If there is a path from $u$ to $v$ respecting the orientation, then clearly there can not be one from $v$ to $u$. Any acyclic orientation of $G - e$ either has such a path, or not, thus we can partition them in this way. \\
\indent If there is no path joining the end-vertices of $e$, then these orientations are exactly the ones from $G / e$, so there are $\kappa(G / e)$ such orientations. Adding $e$ oriented in either way will not make the orientation cyclic, thus we have $2 \kappa(G / e)$ acyclic orientations of $G$ where there is no path in $G - e$ joining the end-vertices of $e$. \\
Now we have already considered the number of acyclic orientations of $G - e$ having no path joining $u$ and $v$, leaving us with $\kappa(G - e) - \kappa (G / e)$ for the number of acyclic orientations of $G - e$ with a path joining $u$ and $v$. In this case, there is only one way the edge $e$ can be oriented, such that $G$ is still acyclic with this orientation: $u \rightarrow v$ if there is a path from $u$ to $v$ and $u \leftarrow v$ if there is a path from $v$ to $u$. \\ 
Hence,
\[
\kappa(G) = 2 \kappa(G / e) + \kappa(G - e) - \kappa(G / e) = \kappa (G / e) + \kappa (G - e). \qedhere
\]
\end{proof}
\subsection{Graph Polynomials}
William Thomas Tutte developed the Tutte polynomial for graphs by looking at two specific graph polynomials which are computable through a deletion-contraction recursion: the chromatic polynomial and the flow polynomial. Chris Godsil and Gordon Royle used the chromatic polynomial and the reliability polynomial in Chapter 15 of \cite{GoRo2001} to give examples of graph polynomials that are computable through a deletion-contraction algorithm. The goal of this chapter is to give a short overview of the basic concepts in vertex coloring, network flows and network reliability. We will be able to prove the deletion-contraction recursion formulas for each polynomial. In Section 4.4 we will show the connection between these polynomials and the Tutte polynomial. But for now we will only consider them as graph invariants. However, we will refrain from proving that each polynomial is indeed an invariant, which is going to follow immediately from the recursive formulas.
\subsubsection{Colorings and the Chromatic Polynomial}
This subsection gives a detailed overview of the most important concepts in vertex coloring. We are going to start by defining a proper $\lambda$-coloring and the chromatic number $\chi(G)$ for an arbitrary graph $G$. We will then use combinatorial techinques to compute the chromatic number for complete graphs and trees, before finally proving the computation of the chromatic polynomial through a deletion-contraction algorithm. We will follow the definitions of Chapters 1 and 15 in \cite{GoRo2001} and fill in some details from Chapter 11 in \cite{ElMo2022}.
%\begin{definition}
%\textcolor{orange}{nicht nötig, wenn lemma draußen}
%Let $G,H$ be two graphs and $f$ be a map 
%\[
%f: V(G) \to V(H)
%\]
%such that 
%\[
%(u,v) \in E(G) \Longrightarrow (f(u),f(y)) \in E(H)
%\]
%We call the map $f$ a \textit{homomorphism}.
%\end{definition}
\begin{definition}
Let $G$ be a graph. Given a positive integer $\lambda$ we call a map \[
\varphi: V(G) \to \{1, 2, \dots, \lambda\}
\] such that 
\[
(u,v) \in E(G) \Longrightarrow \varphi(u) \neq \varphi(v)
\]
a \textit{proper $\lambda$-coloring} of $G$. Two proper $\lambda$-colorings $\varphi, \varphi'$ of $G$ are \textit{distinct} if $\varphi(v) \neq \varphi'(v)$ for some $v \in V(G)$. 
\end{definition}
\begin{definition}
We call 
\[
\chi(G) \coloneqq \min\{\lambda |\  \text{G has a proper}\  \lambda \ \text{-coloring}\}
\]
the \textit{chromatic number} of $G$.
\end{definition}
%\begin{lemma}
%Let $G$ be a graph. The chromatic number of a graph $G$ is the least %integer $r$ such that there is a homomorphism $\varphi: V(G) \to V(K_r)$. 
%\end{lemma}
%\begin{proof}
%This is a proof.
%\end{proof}
%\begin{beispiel}
%Hier Beispiele mit verschiedenen vollständigen Graphen als Subgraphen.
%\end{beispiel}
In combinatorics it is of interest to deduce the number of proper $\lambda$-colorings of a graph $G$, which we will denote by $P(G,\lambda)$. For some graphs it is quite easy to determine this number using combinatorial techniques.
\begin{proposition} 
Let $G = K_n$ be the complete graph on $n$ vertices, then 
\[
P(K_n, \lambda) = \lambda(\lambda - 1) \cdots (\lambda - n + 1).
\]
\end{proposition}
\begin{proof}
We start with an arbitrary vertex $v_1$ and choose one of the $\lambda$ colors and assign this color to the vertex. Since our graph is complete, any other vertex $v_2$ is adjacent to $v_1$. Thus we are left with $(\lambda - 1)$ colors to choose from and we assign $v_2$ any of those. We continue until we are at the last uncolored vertex $v_n$, which is adjacent to all vertices that are already colored. Thus we are left with $(\lambda - (n - 1))$ colors to choose from. By the rule of product from combinatorial theory, the number of choices we have to color the whole graph is the product of the choices for each single vertex.
\end{proof}
\begin{proposition}
Let $T$ be a tree with $V(T) = n$. Then 
\[
P(T, \lambda) = \lambda (\lambda - 1)^{n - 1}.
\]
\end{proposition}
\begin{proof}We start by coloring an arbitrary vertex $v_1$ of the tree, for which we can choose any of the $\lambda$ colors. For every vertex connected to $v_1$, we are left with $(\lambda - 1)$ colors to choose from. We choose a vertex $v_2$ and assign a color to $v_2$. If we continue choosing a vertex that is adjacent to a colored vertex, it will always be adjacent to exactly one colored vertex, otherwise $T$ would contain a cycle. For each such vertex there are $(\lambda - 1)$ colors to choose from. By the rule of product, we get $ P(T, \lambda) = \lambda (\lambda - 1)^{n - 1}$. 
\end{proof}
In the last two propositions we used combinatorics to give a formula on how to compute the number of proper $\lambda$-colorings for complete graphs and trees. The following theorem provides a recursive formula for the computation of the number of proper $\lambda$-colorings of an arbitrary graph $G$. It also shows that $P(G, \lambda)$ is actually a polynomial in $\lambda$ and can be computed through a deletion-contraction algorithm.
\begin{theorem}
Let $G$ be a graph and $P(G, \lambda)$ the number of its proper $\lambda$-colorings, then 
\[
P(G,\lambda) = \begin{cases}
\lambda^{|V|}, & \text{if} \  E = \emptyset; \\
0, & \text{if G contains a loop;} \\
P(G -  e, \lambda) - P(G/e,\lambda), & \text{if e is not a loop.}
\end{cases}
\]
Thus, it is actually a polynomial in $\lambda$. 
\end{theorem}
\begin{proof}
If the graph $G$ does not have any edges, we have $\lambda$ colors to choose from for each vertex, so by the rule of product we get $\lambda^{|V|}$. Now let $e \in E$ be an edge. Obviously, if $e$ is a loop, the graph does not admit any proper colorings, so suppose $e$ is not a loop. We want to show 
\[
P(G - e, \lambda) = P(G, \lambda) + P(G/e, \lambda).
\]
Now let $\varphi$ be a proper $\lambda$-coloring of $G - e$. Then $\varphi$ either satisfies $\varphi(u) \neq \varphi(v)$ or $\varphi(u) = \varphi(v)$. There is a bijection between the proper colorings of $G$ and those of $G - e$ satisfying $\varphi(u) \neq \varphi(v)$. Similarly, the proper colorings of $G / e$ correspond bijectively with those of $G - e$ satisfying $\varphi(u) = \varphi(v)$.
\end{proof}
\begin{definition} Let $G$ be a graph. We call $P(G, \lambda)$ the \textit{chromatic polynomial} of $G$. 
\end{definition}
From the definition of the chromatic polynomial it is clear that it is monotonically increasing, $P(G; \lambda) = 0$ if $\lambda < \chi(G)$ and $P(G;\lambda) > 0$ else. 
\begin{beispiel}
We want to use Theorem 2.34. to compute the chromatic polynomial for the graph in Figure 10.
\begin{center}
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=3.5mm}]
\node at (0,0)[knoten](1){};
\node at (0,2)[knoten](2){};
\node at (2,2)[knoten](3){};
\node at(2,0)[knoten](4){};
\node at (1, 3.5)[knoten](5){};
\draw (1) -- (2);
\draw (2) -- (3);
\draw (3) -- (4); 
\draw (3) -- (5);
\draw (5) -- (2);
\draw (1) -- (3);
\draw (1) -- (4);
\draw (4) -- (2);
\end{tikzpicture}
\captionof{figure}{Graph from Example 2.36.}
\label{fig:label}
\end{center}
We can start with the graph itself and apply Theorem 2.34 until we are left with either complete graphs, graphs with loops or trees. But we choose to start with $K_5$ and delete two edges from one vertex:
\[
P 
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
	\matrix[left delimiter=(, right delimiter=)] 
	{\node at (0,0) [knoten](1){};
	\node at (1,0) [knoten](2){}
		edge[-] node {} (1) ; 
	\node at (-0.25, 1) [knoten] (3) {}
		edge[-] node {}(1) 
		edge[-] node {}(2); 
	\node at (1.25, 1)[knoten] (4) {}
		edge[-] node {}(1) 
		edge[-] node {}(2)
		edge[-] node {}(3); 
	\node at(0.5,1.75) [knoten](5){}
		edge[-] node {}(1)
		edge[-] node {}(2)
		edge[-] node {}(3)
		edge[-] node {}(4); 
	\\};
\end{tikzpicture} = P \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
\node at (0,0)[knoten](1){};
\node at (0,1)[knoten](2){};
\node at (1,1)[knoten](3){};
\node at(1,0)[knoten](4){};
\node at (0.5, 1.75)[knoten](5){};
\draw (1) -- (2);
\draw (2) -- (3);
\draw (3) -- (4); 
\draw (3) -- (5);
\draw (5) -- (2);
\draw (1) -- (3);
\draw (1) -- (4);
\draw (4) -- (2);
\draw (1) -- (5);
\\};
\end{tikzpicture} - P 
\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0)[knoten](1) {};
	\node at (0,1)[knoten](2) {}
		edge[-] node {}(1); 
	\node at (1,0)[knoten](3) {}
		edge[-] node {}(1)
		edge[-] node {} (2);
	\node at (1,1) [knoten] (4) {}
		edge[-] node {}(1)
		edge[-] node {}(2)
		edge[-] node {}(3);
\\ };
\end{tikzpicture} 
= P \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
\node at (0,0)[knoten](1){};
\node at (0,1)[knoten](2){};
\node at (1,1)[knoten](3){};
\node at(1,0)[knoten](4){};
\node at (0.5, 1.75)[knoten](5){};
\draw (1) -- (2);
\draw (2) -- (3);
\draw (3) -- (4); 
\draw (3) -- (5);
\draw (5) -- (2);
\draw (1) -- (3);
\draw (1) -- (4);
\draw (4) -- (2); 
\\};
\end{tikzpicture} - 2 \cdot P \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0)[knoten](1) {};
	\node at (0,1)[knoten](2) {}
		edge[-] node {}(1); 
	\node at (1,0)[knoten](3) {}
		edge[-] node {}(1)
		edge[-] node {} (2);
	\node at (1,1) [knoten] (4) {}
		edge[-] node {}(1)
		edge[-] node {}(2)
		edge[-] node {}(3);
\\ };
\end{tikzpicture} .
\]
With
\begin{align*}
P(K_5, \lambda) &= \lambda (\lambda - 1)(\lambda - 2)(\lambda - 3)(\lambda - 4), \\ 
P(K_4, \lambda) &= \lambda (\lambda - 1)(\lambda - 2)(\lambda - 3),
\end{align*} we get 
\begin{align*}
P \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
\node at (0,0)[knoten](1){};
\node at (0,1)[knoten](2){};
\node at (1,1)[knoten](3){};
\node at(1,0)[knoten](4){};
\node at (0.5, 1.75)[knoten](5){};
\draw (1) -- (2);
\draw (2) -- (3);
\draw (3) -- (4); 
\draw (3) -- (5);
\draw (5) -- (2);
\draw (1) -- (3);
\draw (1) -- (4);
\draw (4) -- (2); 
\\};
\end{tikzpicture} &= P \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
	\matrix[left delimiter=(, right delimiter=)] 
	{\node at (0,0) [knoten](1){};
	\node at (1,0) [knoten](2){}
		edge[-] node {} (1) ; 
	\node at (-0.25, 1) [knoten] (3) {}
		edge[-] node {}(1) 
		edge[-] node {}(2); 
	\node at (1.25, 1)[knoten] (4) {}
		edge[-] node {}(1) 
		edge[-] node {}(2)
		edge[-] node {}(3); 
	\node at(0.5,1.75) [knoten](5){}
		edge[-] node {}(1)
		edge[-] node {}(2)
		edge[-] node {}(3)
		edge[-] node {}(4); 
	\\};
\end{tikzpicture} + 2 \cdot P \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm},baseline=-0.5ex]]
				\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0)[knoten](1) {};
	\node at (0,1)[knoten](2) {}
		edge[-] node {}(1); 
	\node at (1,0)[knoten](3) {}
		edge[-] node {}(1)
		edge[-] node {} (2);
	\node at (1,1) [knoten] (4) {}
		edge[-] node {}(1)
		edge[-] node {}(2)
		edge[-] node {}(3);
\\ };
\end{tikzpicture}  \\ 
&= \lambda(\lambda - 1)(\lambda - 2)(\lambda - 3)(\lambda - 4) + 2 \cdot \lambda(\lambda - 1)(\lambda - 2)(\lambda - 3) \\
&= \lambda(\lambda - 1)(\lambda - 2)^2(\lambda - 3).
\end{align*}
Just from one look at the chromatic polynomial of our graph, we see that there are at least $4$ colors needed to color the graph properly. Indeed $P(G, 4) = 48$, so we have 48 different assignments of the 4 colors. The attentive reader might have noticed that while contracting an edge, we dismissed an edge that would form a parallel edge. We did this because we only needed to know whether two vertices are connected, not by how many edges.
\end{beispiel}
Theorem 2.34 is the frequently used deletion-contraction algorithm for the chromatic polynomial. But it is possible to differentiate a bridge from an ordinary edge and give a more detailed form of the deletion-contraction algorithm. We will use it in the next section to compare the flow polynomial to the chromatic polynomial. 
\begin{theorem}
Let $G$ be a graph and $P(G,\lambda)$ its chormatic polynomial. Then 
\[
P(G, \lambda) = \begin{cases}
\frac{\lambda - 1}{\lambda} P(G - e, \lambda), & \text{if } \ e \ \text{is a bridge;} \\
0, & \text{if} \ e \ \text{is a loop;} \\
P(G - e, \lambda) - P(G / e, \lambda), & \text{if} \ e \ \text{is ordinary;} \\
\lambda^{|V|}, & \text{if} \ E = \emptyset.
\end{cases}
\]
\end{theorem}
\begin{proof}
We only need to prove the first case, which we will do by induction on the number of edges. For the base case let $|E(G)| = 1$ and $|V(G)| = n$ and $e \in E(G)$ a bridge. Since $G - e$ and $G / e$ are empty graphs on $n$ and $n - 1$ vertices respectively, we have
\[
P(G, \lambda) = P(G - e, \lambda) - P(G / e, \lambda) = \lambda^{n}  - \lambda^{n - 1} = \lambda^n \left(1 - \frac{1}{\lambda}\right) = P(G - e) \cdot \frac{\lambda - 1}{\lambda}.
\]
Suppose the statement holds for all graphs with $m$ edges and let $G$ be a graph on $m + 1$ edges. If $G$ does not contain a bridge, there is nothing to show. So let $e \in G$ be a bridge. Then, for any ordinary edge $f$, we know 
\[
P(G, \lambda) = P(G - f, \lambda) - P(G / f, \lambda)
\]
from Theorem 2.34. Both graphs on the right hand side of this equation have exactly $m$ edges. Hence we can use the induction hypothesis on these to get
\[
P(G - f, \lambda) - P(G / f, \lambda) = \frac{\lambda - 1}{\lambda} P((G - f) - e, \lambda) - \frac{\lambda - 1}{\lambda} P((G / f) - e,\lambda).
\]
But the resulting graph does not depend on the order of the operations delete and contract, thus the right hand side of this equation is equal to
\[
 \frac{\lambda - 1}{\lambda } (P((G - e)- f, \lambda) - P((G - e) /f, \lambda)).
\]
Using Theorem 2.34 once more will end the proof:
\[
P(G, \lambda) = \frac{\lambda - 1}{\lambda} P(G - e, \lambda). \qedhere
\]
\end{proof}
\begin{remark}
The chromatic polynomial of a graph $G$ has a subgraph expansion. If $c(A)$ denotes the number of connected components of the spanning subgraph $(V,A)$, then 
\[
P(G,\lambda) = \sum_{A \subseteq E(G)} (-1)^{|A|} \lambda^{c(A)}.
\] For further context see Chapter 11 of \cite{ElMo2022}. 
\end{remark}
George David Birkhoff introduced the chromatic polynomial for planar graphs in 1912 in order to prove the long-standing four color conjecture, stating that a loopfree planar graph $G$ has chromatic number $\chi(G) \leq 4$. Thus $P(G;4) > 0$ for any loopfree planar graph $G$. The chromatic polynomial was later extended to general graphs by Whitney in 1932. The four color problem was proven in 2002, but many mathematicians still seek to prove it using the chromatic polynomial.

\subsubsection{Flows and the Flow Polynomial}
In the previous section we have already introduced the chromatic polynomial and proved some important properties. In this section we are going to introduce $A$-flows for an abelian group $A$ and the flow polynomial for graphs. We are going to prove its deletion-contraction formula and give a connection to the chromatic polynomial. In particular, the four color problem is equivalent to the problem of every bridgeless planar graph having a nowhere-zero $\mathbb{Z}/k\mathbb{Z}$-flow. \\
\indent At first we have to define an important matrix, whose entries are determined by the characterstics of the graph it belongs to. 
\begin{definition}
Let $G^\omega$ be a graph with a fixed orientation $\omega$ of its edges. The \textit{incidence matrix} of the oriented graph $G^\omega$ is the matrix $D \in \{0, \pm 1\}^{V \times E}$ whose $(v,e)-$entry is defined by \[
D_{v,e} = \begin{cases}
\ \ 1, & \text{if} \ e \ \text{is directed out of} \ v \ \text{by} \ \omega \\ 
-1, & \text{if} \ e \ \text{is directed into} \ v \ \text{by} \ \omega \\ 
\ \ 0, & \text{if } \ e \ \text{is not incident with} \ v, \ \text{or} \ e \ \text{is a loop on} \ v. 
\end{cases}
\]
\end{definition}
\begin{definition}
Let $G^\omega$ be a graph with a fixed orientation $\omega$, $A$ be an additive abelian group and $D$ be the incidence matrix of $G^\omega$. We call an element of the kernel of $D$ an $A$\textit{-flow}.
\end{definition}
This definition can be expressed in a more graphic way: For a vertex $v \in V$ the set $\omega^+(v)$ consists of those edges directed out of $v$ by the orientation $\omega$ and $\omega^-(v)$ is the set of edges directed into $v$. Thus an $A$-flow of $G^\omega$ can be viewed as a mapping $\phi: E(G) \to A$ such that Kirchhoff's current law is satisfied at each vertex of $G$: 
\[
\sum_{e \in \omega^+(v)} \phi(e) - \sum_{e \in \omega^-(v)}\phi(e) = 0, \ \ \ \ \ \text{for each } \ v \in V.
\]
\begin{definition}
A \textit{nowhere-zero} $A$-flow of $G^\omega$ is an $A$-flow $\phi: E(G) \to A$ with the additional property that $\phi(e) \neq 0$ for every $e \in E(G)$.
\end{definition}
\begin{beispiel}
Figure 11 shows the Petersen graph with a nowhere-zero $\mathbb{Z}/5\mathbb{Z}$-flow.
\begin{center}
\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!20, thick, 
				inner sep=0pt, minimum size=2.5mm}]
				
\node at (0,0.25)[knoten](A){};
\node at (0.5, 1) [knoten](B){}
	edge[->, line width= 1.15pt]node[scale=0.5][auto, swap]{$1$}(A);
\node at (1.5,1)[knoten](C){};
\node at (2,0.25)[knoten](D){}
	edge[->, line width= 1.15pt]node[scale=0.5][auto,swap]{$2$}(C)
	edge[->, line width= 1.15pt]node[scale=0.5][auto,swap]{$1$}(A);
\node at (0.25, 2)[knoten](E){}
	edge[->, line width= 1.15pt]node[scale=0.5, pos = 0.9][auto,swap]{$1$}(C);
\node at (1.75, 2)[knoten](F){}
	edge[->, line width= 1.15pt]node[scale=0.5, pos = 0.95][auto,swap]{$2$}(E)
	edge[<-, line width= 1.15pt]node[scale=0.5, pos=0.1][auto]{$1$}(B);
\node at (2.5, 2.5)[knoten](G){}
	edge[->, line width= 1.15pt]node[scale=0.5][auto,swap]{$1$}(F)
	edge[<-, line width= 1.15pt]node[scale=0.5][auto]{$2$}(D);
\node at (-0.5, 2.5)[knoten](H){}
	edge[<-, line width= 1.15pt]node[scale=0.5][auto,swap]{$2$}(A)
	edge[<-, line width= 1.15pt]node[scale=0.5][auto]{$1$}(E);
\node at (1,2.5)[knoten](I){}
	edge[->, line width= 1.15pt]node[scale=0.5, pos=0.9][auto,swap]{$2$}(B)
	edge[->, line width= 1.15pt]node[scale=0.5,pos=0.98][auto]{$2$}(C);	
\node at (1, 3.5)[knoten](J){}
	edge[->, line width= 1.15pt]node[scale=0.5][auto,swap]{$2$}(H)
	edge[<-, line width= 1.15pt]node[scale=0.5][auto]{$1$}(G)
	edge[<-, line width= 1.15pt]node[scale=0.5][auto,swap]{$1$}(I);
\end{tikzpicture}
\captionof{figure}{The Petersen graph with a nowhere-zero $\mathbb{Z}/5\mathbb{Z}$-flow.}
\label{fig:label}
\end{center}
\end{beispiel}
If we are interested in counting the different nowhere-zero $A$-flows for an abelian group $A$ an interesting phenomenon arises: The number of nowhere-zero $A$-flows of $G^\omega$ depends only on the order of $A$ and not on its structure. To see this, we will define the flow polynomial and show that it has a recursive deletion-contraction relation.
\begin{definition}
The \textit{flow polynomial} of $G^\omega$ is defined by its evaluations at a positive integer $k$ by 
\[
F(G^\omega;k) = \# \{ \phi: E(G) \to A: \phi \ \text{is a nowhere zero} \ A\text{-flow of} \ G, \text{with} \ |A| = k \}.
\]
\end{definition}
\begin{beispiel}
Let us consider the graph $G$ in Figure 12, and find the number of nowhere-zero $\mathbb{Z}/k\mathbb{Z}$-flows for $G$. 
\begin{center}
\begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto]	
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[-]node[auto]{$f$}(A);
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
\path (C) edge [my loop] (C);

\node at (4,0)[knoten](D){};
\node at (6,0)[knoten](E){}
	edge[->, line width= 1.25pt]node[auto]{$f$}(D);
\node at (5,1)[knoten](F){}
	edge[-]node[auto,swap]{}(D)
	edge[-]node[auto,swap]{}(E);

\path (F) edge [my loop] (F);	

\end{tikzpicture}
\captionof{figure}{Graph $G$ and Graph $G$ with oriented edge $f$. }
\label{fig:label}
\end{center} 
For that we need to consider possible orientations of $G$. Orienting the loop in either way will result in the same flow polynomial, hence we have $2^3$ different orientations, giving us $8$ different oriented graphs. Let us first consider the four graphs, where $f$ is oriented as in Figure 12. The flow on the edges incident to the end-vertices of $f$ is uniquely determined.
\begin{center}
\begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto]	
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(A);
\node at (1,1)[knoten](C){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto,swap]{$k-\phi(f)$}(A)
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(B);
	
\Loop[dist=1cm,dir=NO,label = $z$,labelstyle=above](C);

\node at (4,0)[knoten](D){};
\node at (6,0)[knoten](E){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(D);
\node at (5,1)[knoten](F){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto,swap]{$k - \phi(f)$}(D)
	edge[<-, line width= 0.9pt]node[scale=0.7][auto]{$k - \phi(f)$}(E);
	
\Loop[dist=1cm,dir=NO,label = $z$,labelstyle=above](F);

\node at (8,0)[knoten](G){};
\node at (10,0)[knoten](H){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(G);
\node at (9,1)[knoten](I){}
	edge[<-, line width= 0.9pt]node[scale=0.7][auto,swap]{$\phi(f)$}(G)
	edge[<-, line width= 0.9pt]node[scale=0.7][auto]{$k - \phi(f)$}(H);
	
\Loop[dist=1cm,dir=NO,label = $z$,labelstyle=above](I);

\node at (12,0)[knoten](J){};
\node at (14,0)[knoten](K){}
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(J);
\node at (13,1)[scale=0.7][knoten](L){}
	edge[<-, line width= 0.9pt]node[scale=0.7][auto,swap]{$\phi(f)$}(J)
	edge[->, line width= 0.9pt]node[scale=0.7][auto]{$\phi(f)$}(K);
	
\Loop[dist=1cm,dir=NO,label = $z$,labelstyle=above](L);

\end{tikzpicture}
\captionof{figure}{Four different orientations of $G$ with flows.}
\label{fig:label}
\end{center} 
Any flow on some loop can be neglected in the formula of Kirchhoff's current law, since it flows into and out of the vertex. Hence the flow on the loop can be any nonzero element $z \in \mathbb{Z}/k\mathbb{Z}$. Thus there are $(k - 1)$ possibilities to choose $\phi(f)$ and $(k - 1)$ possibilities to choose $z$. From this we obtain $(k - 1)^2$ different flows for $G$ with $f$ oriented as in Figure 12. Orienting $f$ the other way will result in flows that were already considered. Hence $F(G^\omega; k) = (k - 1)^2$ for any orientation of $G$. For example, if $k = 3$, there are exactly $4$ different flows the graph $G^\omega$ with fixed orientation $\omega$ can have. 
\end{beispiel}
The last example suggests that the number of nowhere-zero $A$-flows only depends on the order of the group $A$. Similar to the chromatic polynomial, we can prove that the number of nowhere-zero $\mathbb{Z}_k$-flows is indeed a polynomial in $k$ by using the following recurrence relation: 
\begin{theorem}
The flow polynomial of a graph $G^\omega$ satisfies 
\[
F(G^\omega;k) = \begin{cases}
0, & \text{if} \ G \ \text{contains a bridge;} \\
(k - 1)F(G^\omega - e; k), & \text{if } \ e \ \text{is a loop;} \\
F(G^\omega / e;k) - F(G^\omega - e;k), & \text{if} \ e \ \text{is ordinary;} \\
1, & \text{if} \ E(G) = \emptyset.
\end{cases}
\]
\end{theorem}
\begin{proof}
Firstly, if $E(G) = \emptyset$, there is exactly one map from the empty set to $A$, namely the empty map, hence $F(G;k) = 1$. Secondly, if $G^\omega$ has a bridge $e$, it does not have any nowhere-zero $A$-flow. Indeed, suppose $e$ is the only edge from $V_1$ to $V_2 = V(G) - V_1$. An $A$-flow must satisfy for a disjoint partition of the vertex set of a graph, that the total flow into $V_1$ must equal the total flow into $V_2$. Since $e$ is a bridge between $V_1$ and $V_2$, there is no nowhere-zero $A$-flow. If $e$ is a loop, then we can freely assign any of the non-zero values of $A$. Then any nowhere-zero $A$-flow of $G^\omega - e$ together with any of the $(k-1)$ assignments of $e$ is a nowhere-zero $A$-flow of $G^\omega$. \\ 
\indent Now let $e$ be an edge in $G^\omega$ that is ordinary. Consider a nowhere-zero $A$-flow $\phi$ of $G^\omega / e$. For an edge incident to $e$ consider its corresponding edge in $G / e$ after contracting $e$. Then we have a bijection between $E(G^\omega - e)$ and $E(G^\omega / e)$ that maps each edge to its correspong edge in the contraction. Therefore $\phi$ can be regarded as a flow $\phi'$ on $G^\omega - e$. Now $\phi'$ is either a nowhere-zero $A$-flow on $G^\omega - e$, or Kirchhoffs current law is failed at both end-vertices of $e$ and nowhere else. If the latter case is true, there is a unique extension of $\phi'$ to a nowhere-zero $A$-flow $\phi''$ on $G^\omega$. Let $u,v$ denote the end-vertices of $e$. If
\[
\sum\limits_{f \in \omega^+(u)} \phi'(f) - \sum\limits_{f \in \omega^-(u)} \phi'(f) = c,
\]
then 
\[
\sum\limits_{f \in \omega^+(v)} \phi'(f) - \sum\limits_{f \in \omega^-(v)} \phi'(f) = c
\]
must also hold. Thus $\phi''(e) = c$. Consequently, 
\[
F(G^\omega / e ;k) = F(G^\omega - e;k) + F(G^\omega; k). \qedhere
\]
\end{proof}
As an easy consequence of this theorem, we see that the flow polynomial depends only on the order of $A$ and not on its structure. Furthermore, it is indeed a polynomial in $k$.
\begin{remark}
Similarly to the chromatic polynomial, the flow polynomial has a subgraph expansion, see \cite{ElMo2022}: For a finite Abelian group $A$ with order $k$ the graph $G^\omega = (V,E)$ with orientation $\omega$ has flow polynomial 
\[
F(G^\omega; k) = \sum_{F \subseteq E(G)}(-1)^{|E(G)|- |F|} k^{|F| - |V| + c(F)}.
\]
\end{remark}
\begin{beispiel}
Let us compute the flow polynomial of the graph in Example 2.43 through the recursive algorithm: 
\begin{align*}
F\begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[-]node[auto,swap]{}(A);
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
\path (C) edge [my loop] (C);
\\};
\end{tikzpicture} &= ( k - 1) \cdot F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[-]node[auto,swap]{}(A);
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
	\\};
\end{tikzpicture} \\
&= (k - 1) \cdot \left[F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (0,1)[knoten](B){}
	edge[-, bend right] node[auto,swap]{} (A)
	edge[-, bend left] node[auto,swap]{} (A);
	\\};
\end{tikzpicture} - F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){};
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
	\\};
\end{tikzpicture}\right] \\ 
&= (k - 1) \cdot F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (0,1)[knoten](B){}
	edge[-, bend right] node[auto,swap]{} (A)
	edge[-, bend left] node[auto,swap]{} (A);
	\\};
\end{tikzpicture} \\ &= (k - 1) \cdot \left[ F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\path (A) edge [my loop] (A); 
	\\};
\end{tikzpicture} - F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (1,0)[knoten](B){}
edge[-]node[auto]{}(A);
	\\};
\end{tikzpicture} \right] \\ 
&= (k - 1) \cdot F \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\path (A) edge [my loop] (A); 
	\\};
\end{tikzpicture} = (k - 1)^2. 
\end{align*}
This matches with our earlier result from Example 2.44.
\end{beispiel}
It is natural to consider the flow polynomial for a graph $G$, as the dual of the chromatic polynomial for $G$, as the following theorem shows.
\begin{theorem}
The chromatic polynomial and the flow polynomial are related by duality: 
\[
P(G;k) = F(G^\star; k) k^{c(G)}
\]
whenever $G$ is a plane graph with dual $G^\star$.
\end{theorem}
\begin{proof}
We will mainly use the deletion-contraction recursion of the polynomials from Theorem 2.37 and Theorem 2.45. The flow polynomial is defined for a graph $G$ with given orientation $\omega$. Since the orientation is negligible, we write $G$ for the oriented as well as the unoriented graph. Firstly, let $E(G) = \emptyset$, then $c(G) = |V|$ and $E(G^\star) = \emptyset$. Hence 
\[
P(G; k) = 1 \cdot k^{|V|} = F(G^\star; k) k^{c(G)}.
\]
Secondly, let $e$ be a loop in $G$. Then the corresponding edge $\hat{e}$ in $G^\star$ is a bridge. Hence 
\[
P(G; k) = 0 = F(G^\star;k) k^{c(G)}.
\]
We are using an induction on the number of edges in $G$. We have already covered the base case of $E(G) = \emptyset$. Suppose the statement holds for all graphs with $m$ edges and consider a graph $G$ with $m + 1$ edges. Now let $e \in G$ be a bridge, then with the induction hypothesis it follows that 
\[
P(G; k) = \frac{k - 1}{k} P(G - e; k) \overset{IH}{=} \frac{k - 1}{k} \cdot k^{c(G - e)} F((G - e)^\star;k).
\]
We can now use that $c(G - e) = c(G) + 1$ and Theorem 2.23 with $\hat{e}$ being a loop in $G^\star$, which results in
\[
\frac{k - 1}{k} \cdot k^{c(G - e)} F(G^\star - \hat{e};k) = k^{c(G)} F(G^\star;k).
\]
Lastly, let $e \in G$ be an ordinary edge, then $\hat{e} \in G^\star$ is also ordinary. We start by using the induction hypothesis
\[
P(G;k) = P(G - e; \lambda) - P(G / e; \lambda) \overset{IH}{=} k^{c(G - e)} F((G - e)^\star;k) - k^{c(G / e)}F((G / e)^\star;k).
\]
In Theorem 2.23 we proved that $(G - e)^\star = G^\star / \hat{e}$ and $(G / e)^\star = G^\star - \hat{e}$ if $e$ is ordinary in $G$. Using that $c(G - e) = c(G) = c(G / e)$ we get
\[
P(G;k) = k^{c(G)}\left(F(G^\star / e;k) - F(G^\star - e;k)\right) = k^{c(G)}F(G^\star; k).\qedhere
\]
\end{proof}
\subsubsection{Network-Reliability and the Reliability Polynomial}
Our next example comes from network-reliability theory. It is based on the idea of using a graph to represent a computer network where the edges represent links. These links are possibly unreliable and may fail with some probability. \\
Let $G$ be a graph representing some network. Then each edge is operating with some probability $p$, where $0 \leq p \leq 1$, hence it is failing with probability $(1 - p)$. We can think of deleting the edges of $G$ with fixed probability $(1 - p)$. Now let $C(G,p)$ denote the probability that no connected component of $G$ is disconnected as a result. Thus $C(G;p)$ is basically the probability that the network survives. Obviously, if $T$ is a tree on $n$ vertices, then it remains connected if and only if every edge of $G$ survives. Hence $C(T;p) =  p^{n - 1}$.
\begin{definition}
We call the function $C(G;p)$ the \textit{reliability polynomial} of $G$. 
\end{definition}
As with the chromatic polynomial and the flow polynomial, we will show that the reliability polynomial is computable through a deletion-contraction algorithm and justify the name by showing that it is actually a polynomial. 
\begin{theorem}
Let $C(G,p)$ denote the probability that no component of $G$ is disconnected when each edge of $G$ is deleted independently with probability $(1-p)$. Then 
\[
C(G;p) = 
\begin{cases}
C(G - e; p), &  \text{if} \ e \ \text{is a loop}; \\
p \cdot C(G / e; p),&  \text{if} \ e \ \text{is a bridge}; \\
(1 - p)\cdot C(G - e; p) + p \cdot C(G / e; p),&  \text{if} \ e \ \text{is ordinary}; \\
1, & \text{if} \ E(G) = \emptyset.
\end{cases}
\]
\end{theorem}
\begin{proof}
First, let $E(G) = \emptyset$. Then there are no edges that could be deleted. Hence the probability that the network survives is $1$. Next, let $e \in E(G)$ be a loop. Deleting $e$ will not increase the number of connected components of $G$, so we can freely delete $e$ which results in $C(G;p) = C(G - e;p)$. Next, let $e \in E(G)$ be a bridge. Deleting $e$ will always result in an increase of connected components of $G$. Thus, the network survives if and only if $e$ is not deleted and $G/e$ survives, hence $C(G;p) = p \cdot C(G/e;p)$. Lastly, let $e \in E(G)$ be ordinary. If $e$ is deleted, then the network $G$ survives if and only if $G - e$ survives. If $e$ is not deleted, then the network survives if and only if $G / e$ survives. Together this results in
\[
C(G;p) = (1-p)C(G - e;p) + pC(G/e;p). \qedhere
\]
\end{proof}
\begin{beispiel}
Let us compute the reliability polynomial for the graph from example 2.47. 
\begin{align*}
C\begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[-]node[auto,swap]{}(A);
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
\path (C) edge [my loop] (C);
\\};
\end{tikzpicture} &= C \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){}
	edge[-]node[auto,swap]{}(A);
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
	\\};
\end{tikzpicture} \\
&= (1 - p) \cdot C \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (2,0)[knoten](B){};
\node at (1,1)[knoten](C){}
	edge[-]node[auto,swap]{}(A)
	edge[-]node[auto,swap]{}(B);
	\\};
\end{tikzpicture} + p \cdot C\begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (0,1)[knoten](B){}
	edge[-, bend right] node[auto,swap]{} (A)
	edge[-, bend left] node[auto,swap]{} (A);
	\\};
\end{tikzpicture} \\ 
&= (1 - p) \cdot p \cdot C \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (1,0)[knoten](B){}
edge[-]node[auto]{}(A);
	\\};
\end{tikzpicture} \\  & \ \ \ + p \cdot \left[ (1 - p) \cdot C \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\node at (1,0)[knoten](B){}
edge[-]node[auto]{}(A);
	\\};
\end{tikzpicture} + p \cdot C \begin{tikzpicture}
[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto, baseline=-0.5ex]	
		\matrix[left delimiter=(, right delimiter=)]{
\node at (0,0)[knoten](A){};
\path (A) edge [my loop] (A); 
	\\};
\end{tikzpicture}\right] \\ 
&= p \cdot (1 - p) \cdot p + p \cdot [(1 - p) \cdot p + p \cdot 1] \\
&= p^2 - p^3 + p^2 - p^3 + p^2 \\
&= -2p^3 + 3p^2
\end{align*}
If $p = 0.5$, then $C(G, 0.5) = 0.5$. Hence deleting each edge with a probability of $0.5$ results in a $0.5$ propability that the network survives. This result is not surprising. If we consider the graph without the loop, then we are left with an edgeset which has cardinality $3$. The power set of the edgeset has cardinality $2^3 = 8$. For the graph to stay connected, at least 2 edges need to survive. We have \[
\begin{pmatrix}
3 \\ 
2
\end{pmatrix} + \begin{pmatrix}
3 \\ 
3
\end{pmatrix} = 4\] possibilities, such that the graph survives. Since each subset has equal propability, the propability that the graph survives is $\frac{4}{8} = 0.5$.  
\end{beispiel}
\newpage
\section{Matroids}
Matroids were first introduced to give a framework for the notions of dependence, that was found both in graphs and linear algebra. Some undergraduate students may have encountered matroids in a course on computer science when studying greedy algorithms on graphs. A problem for which greedy algorithms are used, is to find a minimal spanning tree on a weighted graph. A greedy algorithm starts by sorting the values to be compared by size. It is a fascinating fact that a greedy algorithm returns an optimal solution if the underlying problem has a matroid structure. The proof for this statement can be found in \cite{Oxl2011}. However, we are going to focus on the structure of matroids. The goal of this chapter is to introduce the \textit{Tutte Polynomial} for matroids and prove the \textit{Recipe Theorem} from Dominic Welsh. We use the definition of a \textit{Tutte-Grothendieck Invariant} for matroids, which are functions on classes of matroids, that satisfy a deletion-contraction relation on ordinary elements and are multiplicative on direct sums. The recipe theorem states that all Tutte-Grothendieck invariants are in fact specializations of the Tutte polynomial. \\
\indent Section 3.1 is fully dedicated to give a detailed introduction into matroid theory. We will start by defining a matroid as a finite ground set together with a collection of subsets of the ground set, which we call \textit{independent sets}. Later we are going to show that a matroid can also be defined through its groundset and a so-called rank function. Our main examples are matrices, vector spaces and uniform matroids. Just like in Chapter 2, we will then define the dual matroid in Section 3.2 before we continue with the deletion and contraction actions in Section 3.3. In Section 3.4 we define the Tutte polynomial through its subset expansion, which uses the rank functions of the matroid and the dual matroid. Theorem 3.50 gives the formulas of the recursive deletion-contraction computation of the Tutte polynomial for a matroid. In Section 3.5 we introduce \textit{matroid isomorphism invariants}, show that the Tutte Polynomial itself is a Tutte-Grothendieck invariant and finally prove the recipe theorem. As an example of a matroid isomorphism invariant, that specializes to the Tutte polynomial, we will use the \textit{characteristic polynomial} of a matroid. \\ 
\indent Chris Godsil and Gordon Royle chose in \cite{GoRo2001} to directly introduce matroids through their rank function. However, we want to point out the many anologies to concepts from linear algebra, which is why we chose the introduction through independent sets. For this we mainly use the two works of James Oxley \cite{Oxl2011} and Dominic Welsh \cite{Wel1976}, which both had a big impact on the research in matroid theory. As in Chapter 2, we will use "Handbook of the Tutte Polynomial and Related Topics" \cite{ElMo2022} as an overview of the most important concepts needed for a complete discussion of the Tutte polynomial on matroids.
\subsection{Preliminaries in Matroid Theory}
There are many different but equivalent ways to define matroids. We choose to start with the definition through a groundset and a collection of subsets, called \textit{independent sets}. As in linear algebra, we call the inclusion-maximal independent sets the \textit{bases}. It is also possible to define a matroid through its groundset and collection of bases. We are going to show how any matrix gives rise to a matroid and prove that any two bases of a matroid have the same cardinality. But most importantly we are going to prove that we can define any matroid through its groundset and rank function. 
\begin{definition}
Let $\Omega$ be a finite set and $\mathcal{I}$ be a collection of subsets of $\Omega$ having the following three properties:
\begin{itemize}
\item[(I1)] $\emptyset \in \mathcal{I}$.
\item[(I2)] If $I \in \mathcal{I}$ and $J \subseteq I$, then $J \in \mathcal{I}$.
\item[(I3)] If $I_1$ and $I_2$ are in $\mathcal{I}$ and $|I_1| < |I_2|$, then there is an element $e$ of $I_2 - I_1$ such that $I_1 \cup e \in \mathcal{I}$.
\end{itemize}
We call the ordered pair $(\Omega, \mathcal{I})$ a \textit{matroid} $\M$, $\Omega$ the \textit{ground set} of $\M$ and the members of $\mathcal{I}$ the \textit{independent sets} of $\M$. A subset of $\Omega$ that is not in $\mathcal{I}$ is called \textit{dependent}.
\end{definition}
\begin{lemma}
Let $\M = (\Omega, \mathcal{I})$ be a matroid and $T \subseteq \Omega$ a subset. Consider the set $\mathcal{I}|T \coloneqq \{I \subseteq T: I \in \mathcal{I}\}$, then $(T, \mathcal{I}|T)$ is a matroid. 
\end{lemma}
\begin{proof}
We need to prove whether $(T, \mathcal{I}|T)$ satisfies (I1),(I2) and (I3). Since $\emptyset \subseteq T$ and $\emptyset \in \mathcal{I}$ the empty set is also contained in $\mathcal{I}|T$. \\
\indent Now let $I \in \mathcal{I}|T$ and $J \subseteq I$. Then by the definition of $\mathcal{I}|T$ we have $I \subseteq T$ and $I \in \mathcal{I}$. Since $\mathcal{I}$ satisfies (I2) itself, $J \in \mathcal{I}$, with $J \subseteq I \subseteq T$ the set $J$ is also contained in $\mathcal{I}|T$. \\ \indent
Now consider $I_1, I_2 \in \mathcal{I}|T$ with $|I_1| < |I_2|$. By the definition of $\mathcal{I}|T$, $I_1,I_2 \in \mathcal{I}$ and since $\mathcal{I}$ satisfies (I3), there is an element $e \in I_2 - I_1$, such that $I_1 \cup e \in \mathcal{I}$. Since $I_2, I_1 \subseteq T$, $I_1 \cup e \subseteq T$ and therefore $I_1 \cup e \in \mathcal{
I}|T$.
\end{proof}
\begin{definition}
Let $\M = (\Omega, \mathcal{I})$ be a matroid and $T \subseteq \Omega$ a subset. We call the matroid $(T, \mathcal{I}|T)$ with 
\[
\mathcal{I}|T = \{I \in \mathcal{I}: I \subseteq T\}
\]
the \textit{restriction} of $\M$ to $T$. We denote the matroid by $M|T$. If we want to emphasize which set is deleted from the ground set, we write $\M - \overline{T}$ for $M |T$ and call it the \textit{deletion} of $\overline{T}$ from $\M$. 
\end{definition}
\begin{proposition}
Let $\Omega$ be the set of column labels of an $n \times m$-matrix $A$ over a field $\mathbb{F}$. Let $\mathcal{I}$ be the set of subsets $E$ of $\Omega$ for which the multiset of columns labelled by $E$ is a set and is linearly independent in the vector space $V(n, \mathbb{F})$. Then $(\Omega, \mathcal{I})$ is a matroid.
\end{proposition}
\begin{proof}
It is clear, that $\mathcal{I}$ satisfies (I1) and (I2). For property (I3), let $I, J \in \mathcal{I}$ with $|I| < |J|$. Now consider the span of the union $\mathrm{span}(I \cup J)$, then $\dim(\mathrm{span}(I \cup J))\geq |J|$. Suppose there is no element $e \in J - I$ such that $I \cup e \in \mathcal{I}$, then $I \cup e$ is linearly dependent for every element $e \in J - I$. Therefore $\mathrm{span}(I \cup J) \subseteq \mathrm{span}(I)$ and for their dimensions the following inequality must hold: 
\[
|J| \leq \dim(\mathrm{span}(I \cup J)) \leq |I|.
\]
But this is a contradiction to $|J| > |I|$, hence (I3) holds.
\end{proof}
\begin{beispiel}Consider the following matrix over the field $\mathbb{R}$
\[ A = 
\begin{blockarray}{ccccc}
\mathbf{1} & \mathbf{2} & \mathbf{3} & \mathbf{4} & \mathbf{5} \\ 
\begin{block}{(ccccc)}
  1 & 0 & 0 & 1 & 1 \\
  0 & 1 & 0 & 0 & 1 \\
\end{block}
\end{blockarray}
 \]
Then with the previous proposition $\Omega = \{1,2,3,4,5\}$ and
\[\mathcal{I} = \{\emptyset, \{1\}, \{2\},\{4\}, \{5\}, \{1,2\}, \{1,5\}, \{2,4\}, \{2,5\}, \{4,5\}\}. \]
\end{beispiel}
In linear algebra, an inclusion maximal subset $U$ of a vector space $V$ is called a basis if $U$ consists of linearly independent vectors. Adding any vector to $U$ from $V - U$ returns linearly dependent vectors. Similarly to vector spaces, we can define the \textit{bases} of a matroid. 
\begin{definition}
Let $\M = (\Omega, \mathcal{I})$ be a finite set, we call an inclusion-maximal independent set of $\M$ a \textit{basis} and an inclusion-minimal dependent set of $\M$ a \textit{circuit}.
\end{definition}
In Chapter 4 we are going to show how the spanning forests, cycles respectively, of a graph correspond to the bases, curcuits respectively, of the matroid belonging to the graph.
\begin{lemma}
All bases of a matroid $\M = (\Omega, \mathcal{I})$ have the same size. 
\end{lemma}
\begin{proof}
Let $B_1$ and $B_2$ be inclusion-maximal independent sets, and assume $|B_1| > |B_2|$. Then by (I3) there must be an element $e \in B_1$ such that $B_2 \cup B_1$ is itself independent. But $B_2 \subset B_2 \cup e$, thus $B_2$ was not an inclusion-maximal independent set, hence not a basis. 
\end{proof}
\begin{definition}
Let $\Omega$ be a finite set, and let $\mathrm{rkf}: \mathcal{P}(\Omega) \to \mathbb{Z}^+ \cup \{0\}$ be a function that satisfies the following properties.
\begin{itemize}
\item[(R1)] If $A \subseteq B \subseteq \Omega$, then $\mathrm{rkf}(A) \leq \mathrm{rkf}(B)$.
\item[(R2)] If $A,B \subseteq \Omega$, then $\mathrm{rkf}(A \cup B) + \mathrm{rkf}(A \cap B) \leq \mathrm{rkf}(A) + \mathrm{rkf}(B)$.
\item[(R3)] If $A \subseteq \Omega$, then $0 \leq \mathrm{rkf}(A) \leq |A|$. 
\end{itemize}
We call such a function a \textit{rank function}. 
\end{definition}
(R3) is reminiscent of the identity 
\[
\dim( U + W) + \dim(U \cap W) = \dim(U) + \dim(W),
\]
where $U$ and $W$ are subspaces of a finite-dimensional vector space $V$ and \begin{center} $U + W = \{v \in V | v = u + w $ for $u \in U$ and $w \in W\}$.\end{center}
The most obvious example for a rank function, is the one that maps each set to its cardinality, the following example is more interesting.
\begin{beispiel}
Let $G$ be a graph with some orientation $\sigma$ and $D$ be the $m \times n$ incidence matrix of the oriented graph $G^\sigma$. Let $\Omega$ be the set of the columns of $D$ and for $A \subseteq \Omega$ let 
\[
\mathrm{rank}(A) = \dim(\spn(A)).
\]
Then $\mathrm{rank}$ is a rank function, where (R1), (R2), (R3) follow directly from linear algebra. Moreover, it is independent of the orientation, since reversing the orientation of an edge is only multiplying the corresponding column in the matrix by $(-1)$.
\end{beispiel}
\begin{definition}
Let $\M = (\Omega, \mathcal{I})$ be a matroid and $A \subseteq \Omega$. We call the cardinality of a basis $\mathcal{B}$ of the restriction $\M|A$ the \textit{rank} of $A$ and denote it by $\rk(A)$. 
\end{definition}
The following lemma, shows that $\rk$ is indeed a rank function, so that it deserves its name.
\begin{lemma}
Let $\M = (\Omega, \mathcal{I})$ ba a matroid, then $\rk$, as defined in Definition 3.10, maps $\mathcal{P}(\Omega)$ to nonnegative integers and is a rank function.
\end{lemma}
\begin{proof}
Let $\M = (\Omega, \mathcal{I})$ and $A,B \subseteq \Omega$ be subsets such that $A \subseteq B$. Let $\mathcal{B}$ be a basis of $\M|B$. Then $\mathcal{B} \cap A$ is a basis of $\M|A$. Therefore $\rk(A) \leq \rk(B)$. Moreover, for a subset $A$ its rank $\rk(A)$ equals the cardinality of a basis $\mathcal{B}$ of $\M|A$. From $|\mathcal{B}| \leq |A|$, it follows that $0 \leq \rk(A) \leq |A|$. 
\noindent
Now let $A,B \subseteq \Omega$ be arbitrary subsets. Let $\mathcal{B}^{A \cap B}$ be a basis of the matroid $\M{|{(A \cap B)}} = (A \cup B, \mathcal{I}|(A \cap B))$ with $\mathcal{I}|{(A \cap B)} = \{I \in \mathcal{I}: I \subseteq A \cap B\}$ and consider the matroid $\M{|{(A \cup B)}} = (A \cup B, \mathcal{I}|{(A \cup B)})$ with $\mathcal{I}|{(A \cup B)} = \{ I \in \mathcal{I}: I \subseteq A \cup B\}$. In addition let $\mathcal{B}^{A \cap B}$ be a basis of $\M{|{(A \cap B)}}$. Then $\mathcal{B}^{A \cap B} \in \mathcal{I}|{(A \cup B)}$, hence $\mathcal{B}^{A \cap B} \subseteq \mathcal{B}^{A \cup B}$ for some basis $\mathcal{B}^{A \cup B}$ of $\M{|{(A \cup B)}}$. Now since $\mathcal{B}^{A \cup B} \cap A \subseteq \mathcal{B}^{A \cup B}$ and $\mathcal{B}^{A \cup B} \cap B \subseteq \mathcal{B}^{A \cup B}$ are independent in $\M$ and fully contained in $A,B$ respectively, they are also independent in $\M{|{A}}, \M{|{B}}$ respectively. Therefore \begin{center} $\rk(A) \geq \rk(\mathcal{B}^{A \cup B}\cap A) =  |\mathcal{B}^{A \cup B} \cap A|$ and $\rk(B) \geq \rk(\mathcal{B}^{A \cup B} \cap B) = |\mathcal{B}^{A \cup B}\cap B|$,\end{center}which shows
\[
\rk(A) + \rk(B) \geq |\mathcal{B}^{A \cup B} \cap A| + |\mathcal{B}^{A \cup B} \cap B|.
\]
For two arbitrary finite sets $X$ and $Y$ the sum of their cardinalities equals the sum of the cardinalities of their union and intersection, hence 
\[
|\mathcal{B}^{A \cup B} \cap A| + |\mathcal{B}^{A \cup B} \cap B| = |(\mathcal{B}^{A \cup B} \cap A) \cup (\mathcal{B}^{A \cup B} \cap B)| + |(\mathcal{B}^{A \cup B} \cap A) \cap (\mathcal{B}^{A \cup B} \cap B)|.
\]
Together we can conclude 
\[
\rk(A) + \rk(B) \geq |\mathcal{B}^{A \cup B} \cap (A \cup B)| + |\mathcal{B}^{A \cup B} \cap A \cap B|,
\] 
and with $\mathcal{B}^{A \cup B} \cap (A \cup B) = \mathcal{B}^{A \cup B}$ and $\mathcal{B}^{A \cup B } \cap A \cap B = \mathcal{B}^{A \cap B}$, we finish the proof
\[
\rk(A) + \rk(B) \geq |\mathcal{B}^{A \cup B}| + |\mathcal{B}^{A \cap B}| = \rk(A \cup B) + \rk(A \cap B). \qedhere
\] 
%Let $\M = (\Omega, \mathcal{I})$ be a matroid and $A,B \subseteq \Omega$. We will use the definition of a rank function. Let $\mathcal{B}^\cap$ be a basis of $\M_{|_{A \cap B}} = (A \cap B, \mathcal{I}^\cap)$ with $\mathcal{I}^\cap = \{I \in \mathcal{I}: I \subseteq A \cap B\}$ and consider the matroid $\M_{|_{A \cup B}} = (A \cup B, \mathcal{I}^\cap)$ with collection of independent sets \textcolor{red}{schlecht!!!}

%Let $\M = (\Omega, \mathcal{I})$ be a matroid and $A,B \subseteq \Omega$. We will use the definition of the rank function: Let $\mathcal{B}^\cap$ be a basis of $\M_{|_{A \cap B}}= (A \cap B, \mathcal{I}^\cap)$ with $\mathcal{I}^\cap = \{I \in \mathcal{I}: I \subseteq A \cap B\}$. Since $\M_{|_{A \cup B}} = (A \cup B, \mathcal{I}^\cup)$ with $\mathcal{I}^\cup = \{I \in \mathcal{I} | I \subseteq A \cup B\}$, $\mathcal{I}^\cap \subseteq \mathcal{I}^\cup$ and $\mathcal{B}^\cap \in \mathcal{I}^\cup$. Hence, it exists a basis $\mathcal{B}^\cup$ of $\M_{|_{A \cup B}}$ such that $\mathcal{B}^\cap \subseteq \mathcal{B}^\cup$. Now the intersections $\mathcal{B}^\cup \cap A \subseteq A$ and $\mathcal{B}^\cup \cap B \subseteq B$ are themselves independent in $\M$ as they are subsets of independent sets. Since they are contained in $A$,$B$ respectively they are independent in $\M_{|_A}$, $\M_{|_B}$ respectively. Therefore with the definition of the rank function, and R3 we get $\rk(A) \geq |\mathcal{B}^\cup \cap A|$ and $\rk(B) \geq |\mathcal{B}^\cup \cap B|$. With this information we can prove the inequality: 
%\begin{align*}
%\rk(A) + \rk(B) &\geq |B^\cup \cap A| + |B^\cup \cap B| \\
%&= |(B^\cup \cap A) \cup (B^\cup \cap B)| + |(B^\cup \cap A)\cap (B^\cup \cap B)| \\
%&= |B^\cup \cap (A \cup B)| + |B^\cup \cap A \cap B| \\
%&= |B^\cup| + |B^\cap| \\
%&= \rk(A \cup B) + \rk(A \cap B). \qedhere
%\end{align*}
\end{proof}
We chose to introduce a matroid through its set of independent sets, but \cite{GoRo2001} characterize a matroid through its rank function.
Theorem 3.13 shows the equivalence of these two approaches. We will need the following lemma for its proof.
\begin{lemma}
Let $\Omega$ be a set and $\mathrm{rk}$ be a function on $\mathcal{P}(\Omega)$ satisfying (R2) and (R3). If $A$ and $B$ are subsets of $\Omega$ such that $\mathrm{rk}(A \cup e) = \mathrm{rk}(A)$ for all $b \in B - A$, then $\mathrm{rk}(A \cup B) = \mathrm{rk}(A)$. 
\end{lemma}
\begin{proof}
We will argue by induction on $|B - A| = |\{e_1, \dots, e_k\}| = k$. If $k = 1$ and $\mathrm{rk}(A \cup e_1) = \mathrm{rk}(A)$, then $\mathrm{rk}(A) = \mathrm{rk}(A \cup e_1) = \mathrm{rk}(A \cup B)$. Assume the statement holds for all sets $A$ and $B$ where $|B - A| = m$ and let $k = m + 1$. Then by the induction assumption
\[
\mathrm{rk}(A) + \mathrm{rk}(A) = \mathrm{rk}(A \cup \{e_1, e_2, \dots, e_m\}) + \mathrm{rk}(A \cup e_{m + 1}),
\]
and with (R2) we have
\begin{align*}
\mathrm{rk}(A) + \mathrm{rk}(A) &\geq \mathrm{rk}((A \cup \{e_1, e_2, \dots, e_m\}) \cup (A \cup e_{m + 1})) \\ & \ \ + \mathrm{rk}((A \cup \{e_1, e_2, \dots, e_m\}) \cap (A \cup e_{m + 1})) \\
&= \mathrm{rk}(A \cup \{e_1, \dots, e_{m + 1}\}) + \mathrm{rk}(A) \\
&\geq \mathrm{rk}(A) + \mathrm{rk}(\emptyset) + \mathrm{rk}(A).
\end{align*}
Equality must hold throughout, therefore 
\[
\mathrm{rk}(A \cup \{e_1, \dots, e_{m + 1}\}) = \mathrm{rk}(A). \qedhere
\]
\end{proof} 
\begin{theorem}
Let $\Omega$ be a set and $\mathrm{rkf}$ a function that maps $\mathcal{P}(\Omega)$ into the set of non-negative integers and satisfies (R1) - (R3). Let $\mathcal{I}$ be the collection of subsets $I$ such that $\mathrm{rkf}(I) = |I|$. Then $(\Omega, \mathcal{I})$ is a matroid with rank function $\mathrm{rkf}$.
\end{theorem}
\begin{proof}
We will prove that $\mathcal{I}$ satisfies (I1) - (I3) and that the rank function $\rk$ on $\M$ determined by $\mathcal{I}$ is indeed the rank function $\mathrm{rkf}$. First let us prove (I1). From the definition of $\mathrm{rkf}$, it satisfies $0 \leq \mathrm{rkf}(\emptyset) \leq |\emptyset| = 0$. Thus equality must hold throughout and $\mathrm{rkf}(\emptyset) = |\emptyset|$, hence $\emptyset \in \mathcal{I}$ and $\mathcal{I} \neq \emptyset$. For (I2) suppose that $I \in \mathcal{I}$ and $J \subseteq I$. Now consider the complement of $J$ in $I$, with (R2) we receive
\begin{align}\label{test4}
\begin{split}
\mathrm{rkf}(J \cup (I - J)) + \mathrm{rkf}(J \cap (I - J)) &\leq \mathrm{rkf}(J) + \mathrm{rkf}(I - J) \\ \Longleftrightarrow \mathrm{rkf}(I) + \mathrm{rkf}(\emptyset) &\leq \mathrm{rkf}(J) + \mathrm{rkf}(I - J)
\end{split}
\end{align}
But since $I \in \mathcal{I}$, $\mathrm{rkf}(I) = |I|$ and with (R3) $\mathrm{rkf}(J) \leq |J|$ and $\mathrm{rkf}(I - J) \leq |I - J|$ hold. Thus by Equation \eqref{test4} we have
\[
|I| \leq \mathrm{rkf}(J) + \mathrm{rkf}(I - J) \leq |J| + |I - J| = |I|,
\]
where equality must hold throughout. Hence $\mathrm{rkf}(J) = |J|$ and by the definition $J \in \mathcal{I}$ follows. Now assume that $I_1, I_2 \in \mathcal{I}$, such that $|I_2| > |I_1|$ but for all elements $e \in I_2 - I_1$ the union $I_1 \cup e$ is not an element of $\mathcal{I}$. If $I_1 \cup e \not \in \mathcal{I}$, then $\mathrm{rkf}(I_1 \cup e) \neq |I_1 \cup e| = |I_1| + 1$. By (R3) we also know that $\mathrm{rkf}(I_1 \cup e) \leq |I_1 \cup e|$. Furthermore, since $I_1 \subset (I_1 \cup e)$, $\mathrm{rkf}(I_1) \leq \mathrm{rkf}(I_1 \cup e)$ follows by (R1). Hence 
\[
|I_1| = \mathrm{rkf}(I_1) \leq \mathrm{rkf}(I_1 \cup e) < |I_1| + 1 \Longrightarrow \mathrm{rkf}(I_1 \cup e) = |I_1|.
\] 
Now by applying Lemma 3.12 on $I_1$ and $I_2$ this tells us 
\[
|I_1| = \mathrm{rkf}(I_1) = \mathrm{rkf}(I_1 \cup I_2) \overset{R1}{\geq} \mathrm{rkf}(I_2) = |I_2|,
\]
which is a contradiction to $|I_2| > |I_1|$. So $\mathcal{I}$ satisfies (I3). Since $\mathcal{I}$ satisfies (I1) - (I3), $\M = (\Omega, \mathcal{I})$ is a matroid. It is left to prove that $\mathrm{rkf}(A) = \rk(A)$ for all $A \subseteq \Omega$.  First, let $A \in \mathcal{I}$, then $\mathrm{rkf}(A) = |A|$ and $\rk(A) = |A|$, since $A$ is a basis of $\M |A$. Now let $A \not \in \mathcal{I}$ and let $\mathcal{B}$ be a basis for $\M |A$, then $\rk(A) = |\mathcal{B}|$. Additionally, $\mathcal{B} \cup x \not \in \mathcal{I}$ for all $x \in A - \mathcal{B}$. Hence, 
\[
|\mathcal{B}| = \mathrm{rkf}(\mathcal{B}) \leq \mathrm{rkf}(\mathcal{B} \cup x) < |\mathcal{B} \cup x|,
\]
so $\mathrm{rkf}(\mathcal{B} \cup x) = \mathrm{rkf}(\mathcal{B})$. By Lemma 3.12, we conclude 
\[
\mathrm{rkf}(A) = \mathrm{rkf}(\mathcal{B} \cup A) = \mathrm{rkf}(\mathcal{B}) = |\mathcal{B}| = \rk(A). \qedhere
\]
\end{proof}
\begin{korollar}
Let $\Omega$ be a finite set. A function $\mathrm{rkf} :  \mathcal{P}(\Omega) \to \mathbb{Z}^+ \cup \{0\}$ is the rank function of a matroid in $\Omega$ if and only if $\mathrm{rkf}$ satisfies properties (R1), (R2) and (R3). 
\end{korollar}
\begin{remark}
The last corollary follows from the preceeding theorem and lemma. With this corollary, we can now define a matroid through its ground set $\Omega$ and a rank function on $\Omega$ satisfying (R1) - (R3). We write $\M = (\Omega, \rk)$. If we want to emphasize that a rank function $\rk$ belongs to a matroid $\M$ we write $\rk_\M$. 
\end{remark}
\begin{definition}
For a matroid $\M$ we call $\rk(\Omega)$ the \textit{rank} of $\M$ and denote it by $\rk(\M)$. 
\end{definition}	
\begin{beispiel} 
Let $\Omega$ be an $n$-element set and $r$ be an integer with $0 \leq r \leq n$. We define the Matroid $\mathcal{U}_{n}^r$ with ground set $\Omega$ through the rank function $\rk(A) \coloneqq \min\{|A|, r\}$ for a subset $A \subseteq \Omega$. This matroid is called the \textit{uniform matroid} of rank $r$ on an $n$-element set. It is easy to see that the independent sets of a uniform matroid $\mathcal{U}_n^r$ are the subsets of $\Omega$ with cardinality at most $r$ and a subset is a basis if and only if its cardinality is exactly $r$. The rank of the uniform Matroid is 
\[
\rk(\mathcal{U}_n^r) = r.
\]
\end{beispiel} 
\begin{definition}
Let $\M = (\Omega, \rk)$ be a matroid. We call a subset $A \subseteq \Omega$ that satisfies $\rk(A) = \rk(\Omega)$ a \textit{spanning} set of $\M$. 
\end{definition}
\begin{remark} 
With Lemma 3.7 we can easily see that a subset $A \subseteq \Omega$ is a basis of a matroid if and only if it is an inclusion-minimal spanning set.  
\end{remark}
\subsection{The Dual Matroid}
In this section, we will introduce the dual matroid $\M^\perp$ by defining a dual rank function for a given matroid $\M$. We will show that the bases of $\M^\perp$ are the set theoretic complements of the bases of $\M$. We will also point out anologies to linear algebra, concerning the concept of orthogonality of vector spaces.\\ 
\indent We denote for a subset $A \subseteq \Omega$, the set theoretic complement $\Omega - A$ by $\overline{A}$.
\begin{definition}
Let $f$ be a function on the subsets of $\Omega$. We define
\[
f^\perp(A) \coloneqq |A| + f(\overline{A}) - f(\Omega)
\]
to be the dual of $f$ on the subsets $A \subseteq \Omega$.
\end{definition}
\begin{remark}
We want to justify the notation above. Let $\M = (\Omega,\mathcal{I})$ be a matroid and $f$ be a function on the subsets of $\Omega$ that satisfies $f(\emptyset) = 0$. For a subset $A \subseteq \Omega$, using the definition of the dual rank function once returns
\[
{f^\perp}^\perp(A) = |A| + f^\perp(\overline{A}) - f^\perp(\Omega) + f^\perp(\Omega) - f^\perp(\Omega). 
\] 
Substituting the definition of the dual rank function a second time returns 
\[
{f^\perp}^\perp(A) = |A| - (|\overline{A}| + f(A) - f(\Omega)) - (|\Omega| + f(\emptyset) - f(\Omega)) = f(A).
\]
\end{remark}
\begin{lemma}
If $\rk$ is a rank function on $\Omega$, then $\rk^\perp$ is also a rank function on $\Omega$. 
\end{lemma}
\begin{proof}
We will start by proving the condition (R2) for $\rk^\perp$. For this we have to remember that the cardinality function satisfies (R2) itself. Now since 
\begin{align*}
\rk^\perp(A \cup B) &= |A \cup B| + \rk(\overline{A \cup B}) - \rk(\Omega) \\ \text{and } \rk^\perp(A \cap B) &= |A \cap B| + \rk(\overline{A \cap B}) - \rk(\Omega),
\end{align*}
the right side of (R2) for $\rk^\perp$ equals
\[
\rk^\perp(A \cup B) + \rk^\perp(A \cap B) = |A \cup B| + |A \cap B| + \rk(\overline{A} \cap \overline{B}) + \rk(\overline{A} \cup \overline{B}) - 2\rk(\Omega).
\]
Whereas with 
\begin{align*}
\rk^\perp(A) &= |A| + \rk(\overline{A}) - \rk(\Omega)\\
\rk^\perp(B) &= |B| + \rk(\overline{B}) - \rk(\Omega)
\end{align*}
the left side of the inequality equals 
\[
\rk^\perp(A) + \rk^\perp(B) = |A| + |B| + \rk(\overline{A}) + \rk(\overline{B}) - 2\rk(\Omega).
\]
Since $|A \cup B| + |A \cap B| = |A| + |B|$ for any two sets, we only need to show that 
\[
\rk(\overline{A} \cap \overline{B}) + \rk(\overline{A} \cup \overline{B}) \leq \rk(\overline{A}) + \rk(\overline{B}).
\]
But as we already noted before, $\rk$ is itself a function that satisfies (R2), hence this inequality is satisfied. \\
\indent
We will now show that $\rk^\perp$ is nonnegative and satisfies $\rk^\perp(A) \leq |A|$. First we rewrite $\rk^\perp$ as 
\[
\rk^\perp(A) = |A| - (\rk(\Omega) - \rk(\overline{A}))
\]
and remember that $|A| \geq 0$ holds.\\ 
For $\rk^\perp$ to be nonnegative, we only need to show that $\rk(\Omega) - \rk(\overline{A}) \leq |A|$. First, $\rk(\Omega) = \rk(\Omega) + \rk(\emptyset) = \rk(A \cup \overline{A}) + \rk(A \cap \overline{A})$. Applying (R2) for $\rk$ yields
\[
\rk(\Omega) \leq \rk(A) + \rk(\overline{A}).
\]
Now $\rk$ satisfies (R3), hence 
\[
\rk(\Omega) - \rk(\overline{A}) \leq |A|.
\]
For $\rk^\perp$ to satisfy (R3), we only need to show that $\rk(\Omega) - \rk(\overline{A}) \geq 0$. For this we use that $\rk$ satisfies (R1), and with $\overline{A} \subseteq \Omega$ this implies $\rk(\overline{A}) \leq \rk(\Omega)$. \\ 
We will now show that $\rk^\perp$ satisfies (R1). Let $A \subseteq B$. We can write $\overline{A} = \overline{B} \cup (B - A)$. Furthermore, since $A \subseteq B$ the intersection $\overline{B} \cap (B - A)$ is empty, hence $\rk(\overline{B} \cap (B - A)) = 0$. With this information we get 
\[
\rk^\perp(A) = |A| + \rk(\overline{A}) - \rk(\Omega) = |A| + \rk(\overline{B} \cup (B - A)) + \rk(\overline{B} \cap (B - A)) - \rk(\Omega).
\]
Now we can use (R2) and (R3) to get \[
\rk(\overline{B} \cup (B - A)) + \rk(\overline{B} \cap (B - A)) \leq \rk(\overline{B}) + \rk(B - A) \leq \rk(\overline{B}) + |B - A|. 
\]
Together this results in
\[
\rk^\perp(A) \leq |A| + \rk(\overline{B}) + |B - A| - \rk(\Omega) = |B| + \rk(\overline{B}) - \rk(\Omega) = \rk^\perp(B). \qedhere
\]
\end{proof}
\begin{remark}
With $\rk(\emptyset) \leq |\emptyset| = 0$ we get ${\rk^\perp}^\perp = \rk$. 
\end{remark}
\begin{definition}
If $\M = (\Omega, \rk)$ is a matroid, then $\M^\perp \coloneqq (\Omega, \rk^\perp)$ is called the \textit{dual} of $\M$. 
\end{definition}
\begin{lemma}
The rank of the dual Matroid is $\rk(\M^\perp) = |\Omega| - \rk(\Omega)$. 
\end{lemma}
\begin{proof}
Firstly, $\rk(\M^\perp) = \rk^\perp(\Omega)$ by definition of the rank of a matroid. Secondly, \[ \rk^\perp(\Omega) = |\Omega| + \rk(\emptyset) - \rk(\Omega) = |\Omega| - \rk(\Omega). \qedhere \] 
\end{proof}
\begin{theorem}
The bases of $\M^\perp$ are the complements of the bases of $\M$. 
\end{theorem}
\begin{proof}
Let $A \subset \Omega$ be independent in $\M$, then 
\[
\rk^\perp(\overline{A}) = |\overline{A}| + \rk(A) - \rk(\Omega) = |\overline{A}| + |A| - \rk(\Omega) = |\Omega| - \rk(\Omega)
\]
and 
\[
\rk^\perp(\Omega) = |\Omega| + \rk(\emptyset) - \rk(\Omega) = |\Omega| - \rk(\Omega).  
\]
Thus $\rk^\perp(\Omega) = \rk^\perp(\overline{A})$ holds if and only if $A$ is independent in $\M$, and $\rk^\perp(\Omega) = \rk^\perp(\overline{A})$ means that $\overline{A}$ is spanning in $\M^\perp$. Consequently $A$ is independent in $\M$ if and only if $\overline{A}$ is spanning in $\M^\perp$. By duality, $A$ is spanning in $\M$ if and only if $\overline{A}$ is independent in $\M^\perp$. \\ 
\indent Now let $B$ be a basis, hence for all $A \in \Omega$ with $B \subset A$, $\rk(A) < |A|$ holds. Their complements satisfy $\overline{A} \subset \overline{B}$ and since $B$ is independent in $\M$, it is spanning in $\M^\perp$, thus $\rk^\perp(\overline{B}) = \rk(\Omega)$. However $A$ is dependent in $\M$, so its complement is spanning in $\M^\perp$, thus $\rk^\perp(\overline{A}) < \rk(\Omega)$. Leaving us with $B$ being an inclusion minimal spanning set in $\M^\perp$, therefore a basis in $\M^\perp$. 
\end{proof}
We are now going to introduce the notions of \textit{loops} and \textit{coloops} of a matroid. In Chapter 4, we are going to explain the connection between these and the notions \textit{loops}, \textit{bridges} for graphs.
\begin{definition}
Let $\M$ be a matroid. We call an element $e \in \Omega $ a \textit{loop} if $\rk(\{e\}) = 0$. If an element $e$ of the matroid $\M$ is a loop in $\M^\perp$, then we call $e$ a \textit{coloop} in $\M$.
\end{definition}
\begin{lemma}
Let $\M = (\Omega, \rk)$ be a matroid and $\M^\perp$ be it's dual and let $e$ be an element in $\M$. Then $e$ is a coloop in $\M$ if and only if $\rk(\Omega - \{e\}) = \rk(\Omega) - 1$.
\end{lemma}
\begin{proof}
We only need to look at the definition of the dual rank function: 
\begin{align*}
\rk^\perp(e) = |e| + \rk(\Omega - e) - \rk(\Omega) &\Longleftrightarrow \ \rk^\perp(e) = 1 + \rk(\Omega - e) - \rk(\Omega)\\ 
&\Longleftrightarrow \ \rk(\Omega - e) - \rk^\perp(e) = \rk(\Omega) - 1
\end{align*}
Thus, $\rk(\Omega - e) = \rk(\Omega) - 1$ if and only if $\rk^\perp(e) = 0$. 
\end{proof}
In linear algebra the bidual space of a finite dimensional vector space $V$ is isomorphic to $V$. The analogous result for matroids, is that taking the dual of a matroid twice results in the original matroid.
\begin{korollar}
If $\M$ is a matroid, then ${\M^\perp}^\perp = \M$.
\end{korollar}
\begin{proof}
Let $\M = (\Omega, \rk)$ be a matroid. We've already showed that ${f^\perp}^\perp = f$ for any function $f$. Thus with ${\rk^\perp}^\perp = \rk$ and $\M^\perp = (\Omega, \rk^\perp)$, we get 
\[
{\M^\perp}^\perp = (\Omega, {\rk^\perp}^\perp) = (\Omega, \rk) = \M. \qedhere
\]
\end{proof}
\begin{beispiel}
We have already noted that the bases of the rank-$r$ uniform matroid $\mathcal{U}_n^r$ are the $r$-element subsets of an $n$-element set $\Omega$. Thus the bases of the dual matroid are the $(n-r)$-element subsets of $\Omega$. Hence,
\[
\left(\mathcal{U}_n^r\right)^\perp = \mathcal{U}_n^{n -r}.
\]
\end{beispiel}

\subsection{The Deletion-Contraction Algorithm for Matroids}
We have introduced the operations of deletion and contraction in the context of graph theory. We will now introduce these operations for matroids and prove that they are dual actions. Then we will consider a way of glueing two matroids. \\
\indent Let $\M = (\Omega, \rk)$ be a matroid. In Definition 3.3 we defined the restriction $M|T$. We already noted that restricting a matroid to a subset $T$ can also be called the deletion of a subset $\overline{T}$. \\ \indent We begin by noting that for a subset $T \subseteq \Omega$ and $A \subseteq \overline{T}$ the function 
\begin{align*}
\rk_{\M - T} : \mathcal{P}(\Omega - T) &\to \mathbb{Z}^+ \cup \{0\} \\ 
A &\mapsto \rk(A)
\end{align*}
is the rank function on $\Omega - T$ of the matroid $ \M - T$. Now consider the function 
\begin{align*}
\rk_{\M / T}: \mathcal{P}(\Omega - T) &\to \mathbb{Z}^+ \cup \{0\} \\ 
A &\mapsto \rk(A \cup T) - \rk(T)
\end{align*}
defined on the subsets of $\Omega - T$ .
\begin{lemma} 
Let $\M = (\Omega, \rk)$ be a matroid. Then $\rk_{\M / T}$ defines a rank function on $\Omega - T$ for any subset $T \subseteq \Omega$. 
\end{lemma}
\begin{proof}
We need to prove (R1), (R2) and (R3). For (R1), let $A \subseteq B$ be subsets of $\Omega - T$. Then $\rk_{\M / T} (A) = \rk(A \cup T) - \rk(T)$ and $\rk_{\M / T} (B) = \rk(B \cup T) - \rk(T)$, such that 
\[ \rk_{\M / T} (A) \leq  \rk_{\M / T} (B) 
\Longleftrightarrow  \rk(A \cup T) \leq \rk(B \cup T),
\]
which is always true, since from $A \subseteq B$ follows $A \cup T \subseteq B \cup T$. \\ \indent Next we will show (R2), let $A,B$ be arbitrary subsets of $\Omega - T$. Then, 
\[
\rk_{\M / T} (A \cup B) + \rk_{\M / T}( A \cap B) = \rk(A \cup B \cup T) - 2 \rk(T) + \rk((A \cap B) \cup T),
\]
but $A \cup B \cup T = (A \cup T) \cup (B \cup T)$ and $(A \cap B) \cup T) = (A \cup T) \cap (B \cup T)$, hence 
\[
\rk_{\M / T} (A \cup B) + \rk_{\M / T}(A \cap B) = \rk((A \cup T) \cup (B \cup T)) - 2 \rk(T) + \rk((A \cup T) \cap (B \cup T).
\]
Now we can use that $\rk$ satisfies (R2), thus 
\[
\rk_{\M / T} (A \cup B) + \rk_{\M / T}(A \cap B) \leq \rk(A \cup T) + \rk(B \cup T) - 2 \rk(T) = \rk_{\M / T}(A) + \rk_{\M / T}(B).
\]
\indent Now let's prove the last condition (R3).
We can use (R2) and (R3) for $\rk$ and that $\rk$ maps into the natural numbers, then
\begin{align*}
\rk_{\M /  T} (A) = \rk(A \cup T) - \rk(T) &\leq \rk(A) + \rk(T) - \rk(A \cap T) - \rk(T) \\ 
&= \rk(A) - \rk(A \cap T) \leq |A| - \rk(A \cap T) \leq |A|.\qedhere
\end{align*}
\end{proof}
\begin{definition}
For a matroid $\M = (\Omega, \rk)$ and a subset $T \subseteq \Omega$ we call the matroid $\M / T = (\Omega - T, \rk_{\M / T})$ the \textit{contraction} of $T$.   
\end{definition}
\begin{remark}
Let $\M = (\Omega, \rk)$ be a matroid. If $e$ is a loop in $\M$ then for any subset $A \subseteq \Omega$ we have
\[
\rk_{\M / e}(A) = \rk(A \cup \{e\}).
\]
\end{remark}
\begin{proposition}
Let $M = (\Omega, \mathcal{I})$ be a matroid and for some $T \subseteq \Omega$ let $\M / T$ be the contraction of $T$. Then $\M / T = (\Omega - T, \hat{\mathcal{I}})$ where 
\[
\hat{\mathcal{I}} = \{ I \subseteq \Omega - T : \M | \ T \ \text{has a basis} \ B \ \text{such that} \ B \cup I \in \mathcal{I}\}.
\]
\end{proposition}
\begin{proof}
Denote by $\mathcal{I}_{M / T}$ the set of subsets $I \subseteq \mathcal{I}$, which satisfy $\rk_{M/T}(I) = |I|$. Let $\mathcal{B}_T$ be a basis of $\M|T$. We will prove the following equalities:
\begin{align*}
\hat{\mathcal{I}} &= \{ I \subseteq \Omega - T: I \cup \mathcal{B}_T \in \mathcal{I}\} \\
&= \{I \subseteq \Omega - T: \M|T \ \text{has a basis} \ \mathcal{B} \ \text{such that } \mathcal{B} \cup I \in \mathcal{I}\}.
\end{align*}
By definition of the two sets $\{I \subseteq \Omega - T: \M|T \ \text{has a basis} \ \mathcal{B} \ \text{such that } \mathcal{B} \cup I \in \mathcal{I}\}$ contains $\{ I \subseteq \Omega - T: I \cup \mathcal{B}_T \in \mathcal{I}\}$. Now let $I \subseteq \Omega - T$ and $\mathcal{B} \cup I \in \mathcal{I}$ for some basis $\mathcal{B}$ of $\M|T$, we will show that $I \in \hat{\mathcal{I}}$. Since $\mathcal{B}$ is an inclusion-maximal independent set in $T$, the set $I \cup \mathcal{B}$ is an inclusion-maximal independent set in $I \cup T$, hence $I \cup \mathcal{B}$ is a basis of $I \cup T$. Thus $\rk_\M (I \cup \mathcal{B}) = \rk_\M (I \cup T)$ and with $\rk_{\M / T}(I) = \rk_{\M}( I \cup T) - \rk_{\M}(T)$, we get 
\[
\rk_{\M / T}(I) = \rk_{\M}(I \cup \mathcal{B}) - \rk_{\M}(T).
\]
Now since $I \cup \mathcal{B} \in \mathcal{I}$ and $B$ is a basis of $T$, 
\[
\rk_{\M /T}(I) = |I \cup \mathcal{B}| - |\mathcal{B}| = |I|, 
\]
thus, $I \in \mathcal{I}_{\M / T}$. \\ 
\indent To complete the proof, we now have to show that $\hat{\mathcal{I}} \subseteq \{ I \subseteq \Omega - T: I \cup \mathcal{B}_T \in \mathcal{I}\}$. Assume $A \subseteq \hat{\mathcal{I}}$, then 
\[
|A| = \rk_{\M / T}(A) = \rk_{\M}(A \cup T) - \rk_{\M}(T).
\]
Since $\mathcal{B}_T$ is a basis of $T$ in $\M$, $A \cup \mathcal{B}_T$ contains a basis of $A \cup T$, hence $\rk_\M (A \cup T) = \rk_\M (A \cup \mathcal{B}_T)$. With $\mathcal{B}_T$ being a basis of $\M|T$, this returns 
\[
|A| = \rk_{\M}(A \cup \mathcal{B}_T) - |\mathcal{B}_T| \Longrightarrow |A + \mathcal{B}_T| = \rk_{\M}(A \cup \mathcal{B}_T).
\] 
This shows $A \cup \mathcal{B}_T \in \mathcal{I}$, completing the proof.
\end{proof}
\begin{lemma}
Let $\rk$ be a rank function of a matroid $\M$ on a finite set $\Omega$, and let $\rk^\perp$ be the rank function of it's dual $\M^\perp$. Then for any subset $T \subseteq \Omega$ and $A \subseteq \Omega - T$ we have
\[
(\rk_{\M / T})^\perp(A) = \rk^\perp(A).
\]
\end{lemma}
\begin{proof} 
We compute \[
(\rk_{\M / T})^\perp(A) = |A| + \rk_{\M / T}(\overline{T} - A) - \rk_{\M / T}(\overline{T}), 
\]
where $\rk_{\M / T}(\overline{T} - A) = \rk((\overline{T} - A) \cup T) - \rk(T)$ and $\rk_{\M / T}(\overline{T}) = \rk(\overline{T} \cup T) - \rk(T)$, hence 
\[
(\rk_{\M / T})^\perp(A) = |A| + \rk(\Omega - A) - \rk(\Omega) = \rk^\perp(A). \qedhere
\]
\end{proof}
The next lemma shows, how contraction combines the operations of deletion and taking duals for matroids.
\begin{theorem}For a matroid $\M = (\Omega, \rk)$ and a subset $T \subseteq \Omega$, the following holds
\[
{(\M / T)}^\perp = \M^\perp - T \ \ \ \ \text{and}  \ \ \ \ \ \M ^\perp / T = {(\M - T)}^\perp.
\]
\end{theorem}
\begin{proof}
We can directly use the previous lemma. For the rank function of the matroid \[
(\M / T)^\perp = (\Omega, \rk_{\M / T})^\perp = (\Omega - T, (\rk_{\M / T})^\perp)
\] we have $\rk_{\M/T}^\perp(A) = \rk^\perp(A)$ for subsets $A \subseteq \Omega - T$. However, for subsets $ A \subseteq \Omega - T$, the restriction of any rank function to $\Omega - T$ stays the same. Hence, $\rk^\perp(A) = (\rk^\perp)_{\M - T}(A)$ for all subsets $A \subseteq \Omega - T$. But the matroid $\M^\perp - T = (\Omega, \rk^\perp) - T = (\Omega - T, (\rk^\perp)_{\M - T})$ has the same rank funtion $(\rk^\perp)_{\M - T}$ on subsets $A \subseteq \Omega - T$. Therefore, 
\[
(\M/T)^\perp = \M^\perp - T. \]
By duality, 
\[
(\M^\perp / T)^\perp = {\M^\perp}^\perp - T = \M - T. \qedhere
\] 
\end{proof}
\begin{remark}
If  $e,f$ are distinct elements of a matroid $\M$, then 
\[
(M - e) / f = (M / f) - e. 
\]
This shows that the resulting matroid is independent of the order of the operations. By induction for any subsets $A$ and $B \subseteq \Omega$, we have 
\[
(\M - A) / B = (\M / B) - A. 
\]
\end{remark}
The actions of deleting and contracting an element $e \in \M$ are in fact the same if and only if $e$ is a loop or a coloop of $\M$.
\begin{lemma}
Let $e$ be an element of a matroid $\M$. Then $\M - e = M / e$ if and only if $e$ is a loop or a coloop of $\M$. 
\end{lemma}
\begin{proof}
Let $e$ be a loop in $\M$. Then $\rk(e) = 0$, thus for a subset $A \subseteq \Omega - e$, 
\[
\rk_{\M / e}(A) = \rk(A \cup e) - rk(e) = \rk(A \cup e).
\]
We now show that, $\rk(A) = \rk(A \cup e)$ for a loop $e$: 
\[
\rk(A) \leq \rk(A \cup e) \leq \rk(A) + \rk(e) - \rk(A \cap e) = \rk(A) + 0 - \rk(\emptyset) = \rk(A)
\]
Now let $e$ be a coloop of a matroid $\M$, then it is a loop of the dual matroid $M^\perp$. With part one of this Theorem we get 
\[
M^\perp - e = M^\perp / e.
\]
We use the duality in Theorem 3.36 and get 
\[
(M / e)^\perp = M^\perp - e = M^\perp / e = (M - e)^\perp,
\]
where we can use Corollary 3.29 and end with 
\[
M / e = {(M / e)^\perp}^\perp = {(M - e)^\perp}^\perp = M - e . \qedhere
\]
\end{proof}
We will now introduce the glueing of two matroids. 
\begin{theorem}
Let $\M_1$ and $\M_2$ be matroids with disjoint ground sets $\Omega_1$ and $\Omega_2$ respectively and set of independent sets $\mathcal{I}_1$ and $\mathcal{I}_2$ respectively. Then $(\Omega_1 \cup \Omega_2, \mathcal{I})$ such that $\mathcal{I} = \{ I_1 \cup I_2 | I_1 \in \mathcal{I}_1, I_2 \in \mathcal{I}_2\}$ is a matroid.
\end{theorem}
\begin{proof}
Since $\M_1$ and $\M_2$ are matroids, $\mathcal{I}$ can not be empty. Now let $I \in \mathcal{I}$. Then $I = I_1 \cup I_2$ and any subset $J \subseteq I$ is of the form $J = J_1 \cup J_2$ with $J_1 \subseteq I_1$ and $J_2 \subseteq I_2$, thus $J \in \mathcal{I}$. Therefore, properties (I1) and (I2) are satisfied. For property (I3) let $I'$ and $I''$ be in $\mathcal{I}$ with $|I''| > |I'|$ then $I' = I_1' \cup I_2'$ and $I'' = I_1'' + I_2''$. Hence at least one of the following must be true: $|I_1''| > |I_1'|$ or $|I_2''| > |I_2'|$. Without loss of generality let the first case be true, then since $\mathcal{I}_1$ is a set of independent sets,with (I3) we can find an element $e \in I_1''$ such that $I_1' \cup \{e\} \in \mathcal{I}_1$. Therefore $I' \cup \{e\} = I_1' \cup \{e\} \cup I_2' \in \mathcal{I}$.
\end{proof}
\begin{definition}
We call the matroid, whose existence was established in the previous theorem, the \textit{direct sum} of $\M_1$ and $\M_2$ and denote it by 
\[
\M = \M_1 \oplus \M_2.
\]
\end{definition}
The following theorem shows how the rank function on a direct sum of two matroids corresponds to the sum of the rank functions of those matroids, such that we can define the direct sum of two matroids as the union of the groundsets and the rank function defined as follows.
\begin{theorem}
Let $\M = \M_1 \oplus \M_2$ be the direct sum of $(\M_1, \rk_{\M_1})$ and $(\M_2, \rk_{\M_2})$, then the rank function $\rk_{\M}$ of $\M$ satisfies
\[
\rk_{\M}(A) = \rk_{\M_1}(A \cap \Omega_1) + \rk_{\M_2}(A \cap \Omega_2).
\]
\end{theorem}
\begin{proof}
By the definition of the rank function, $\rk_{\M}(A)$ is the cardinality of a basis of $\M | A$. By the definition of the direct sum, it is easy to see that $\mathcal{B}$ is a basis in $\M |A$ if and only if $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$ with $B_1$ a basis in $\M_1 | A_1$ and $\mathcal{B}_2$ a basis in $\M_2 |A_2$. Then 
\[
\rk_{\M}(A) = |\mathcal{B}| = |\mathcal{B}_1| + |\mathcal{B}_2| = \rk_{\M_1}(A_1) + \rk_{\M_2}(A_2). \qedhere
\]
\end{proof}
\begin{beispiel}
Let us deepen our understanding of this definition by looking at the two matroids on an one-element set $\mathcal{U}_1^0$ and $\mathcal{U}_1^1$. Then 
$\mathcal{U}_1^0$ has groundset $\{a\}$ and collection of independent sets $\{\{\emptyset\}\}$, and $\mathcal{U}_1^1$ has groundset $\{b\}$ and collection of independent sets $\{\emptyset, \{b\}\}$. Specifically,
\begin{center}
$\mathcal{U}_1^0 = (\{a\}, \{\emptyset\})$, $\mathcal{U}_1^1 = (\{b\}, \{\emptyset, \{b\}\})$ and $\mathcal{U}_1^0 \oplus \mathcal{U}_1^1 = (\{a,b\}, \{\emptyset, \{b\}\})$.
\end{center}
With the previous theorem we get
\[
\rk_{\mathcal{U}_1^0 \oplus \mathcal{U}_1^1}(A) = \min\{0, |A \cap \{a\}|\} + \min\{1, |A \cap \{b\}|\} = \min\{1, |A \cap \{b\}|\} 
\]
for any subset $A \subseteq \{a,b\}$.
\end{beispiel}
\begin{lemma}
Let $\M$ be a matroid. If $e \in \M$ is a loop or coloop in $\M$, then 
\[
\M = \left(\M|e\right) \oplus \left(\M - e\right)
\]
\end{lemma}
\begin{proof}
We want to show that the following statement holds for the rank function on any subset of the matroid $\M$: 
\[
\rk_{\M}(A) = \rk_{\M|e}(A \cap \{e\}) + \rk_{\M - e}(A \cap (\Omega - e)).
\]
Let $A$ be an arbitrary set of the matroid $\M$. If $e \not \in A$ then by definition $\rk_\M(A) = |\mathcal{B}_1|$ for some basis $\mathcal{B}_1$ of $\M|A$. More specifically, $\mathcal{B}_1 \subseteq A$ inclusion maximal and $\mathcal{B}_1 \in \mathcal{I}$. Moreover $\rk_{{M - e}}(A) = |\mathcal{B}_2|$ with $\mathcal{B}_2$ being a basis of $(\M - e)|A$. More specifically, $\mathcal{B}_2 \subseteq A$ inclusion maximal and $\mathcal{B}_2 \in \mathcal{I}|(M - e).$ Together, $|\mathcal{B}_2| = |\mathcal{B}_1|$, hence $\rk_{\M}(A) = \rk_{\M - e}(A)$. With $A \cap \{e \} = \emptyset$ we get that the following holds:
\[
\rk_{\M - e}(A) = \rk_{M|e}(\emptyset) + \rk_{\M-e}(A - e) = \rk_{\M}(A) .
\]
Now if $e \in A$ we need to differ between loops and coloops. Let $e$ be a loop, then by definition $\rk(e) = 0$. A loop can not be contained in any basis of a matroid, since with (I2) it would be independent itself, thus $\rk(e) = 1$. Hence, if $\mathcal{B}$ is a basis of $\M$, then $e \not \in \mathcal{B}$ and the cardinality of a basis in $\M$ contained in $A$ equals the cardinality of a basis in $\M - e$ contained in $A - e$. Therefore,
\[
\rk_{\M - e}(A - e) = \rk_{\M|e}(e) + \rk_{\M - e}(A - e) = \rk_{\M}(A) 
\]
is true. Lastly let $e \in A$ be a coloop, then by definition $\rk^\perp(e) = 0$, hence no basis of $\M^\perp$ contains $e$. By duality every basis of $\M$ has to contain $e$, thus the cardinality of a basis in $\M$ contained in $A$ is the cardinality of a basis in $\M - e$ contained in $A - e$ increased by one. Thus 
\[
\rk_{\M}(A)= \rk_{\M|e}(e) + \rk_{\M - e}(A - e) = 1 + \rk_{\M - e}(A - e)
\]
holds. 
\end{proof}
\subsection{The Tutte Polynomial for Matroids}
After introducing matroids and their dual, we can finally define the \textit{Tutte Polynomial}. We start by defining this two-variable polynomial through its subset expansion and compute it for some uniform matroids. Theorem 3.48 proves that the Tutte Polynomial on the the dual matroid $\M^\perp$ is obtained by switching the two variables of the Tutte polynomial of $\M$. Theorem 3.50 states the deletion-contraction algorithm for the Tutte polynomial, which we use to compute the Tutte polynomial for some uniform matroids. We finish this section by proving that the Tutte polynomial is multiplicative on direct sums.
\begin{definition}
Let $\M$ be a Matroid on $\Omega$ with rank function $\rk$, we call
\[
T(\M; x,y) = \sum_{A \subseteq \Omega} (x - 1)^{\rk(\Omega) - \rk(A)} (y - 1)^{\rk^\perp(\Omega) - \rk^\perp(\bar{A})}
\]
the \textit{Tutte Polynomial} of $\M$. 
\end{definition}
\begin{remark}
We can get rid of the dual rank function by substituting it with
\begin{align*}
\rk^\perp(\Omega) - \rk^\perp(\overline{A}) &= |\Omega| + \rk(\emptyset) - \rk(\Omega) - (|\overline{A}| + \rk(A) - \rk(\Omega)) \\ 
&= |A| - \rk(A). 
\end{align*}
We define the nullity of a subset $A$ by $\n(A) = |A| - \rk(A)$. Now we can define the Tutte polynomial by 
\[
T(\M; x,y) = \sum_{A \subseteq \Omega}(x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)}.
\]
\end{remark} 
If in this definition $\rk(\Omega) - \rk(A)= 0$ or $|A| - \rk(A) = 0$, is satisfied, we interpret $(x - 1)^0$ or $(y - 1)^0$ respectively, to have value $1$ even if $x = 1$ or $y = 1$ respectively. Therefore, the empty matroid $\mathcal{U}_0^0$ we get $T(\mathcal{U}_0^0; x,y) = 1$.
\begin{beispiel} We apply this definition to the two matroids of an one element set $\mathcal{U}_1^0$ and $\mathcal{U}_1^1$ from Example 3.42 and get 
\[
T(\mathcal{U}_1^0;x,y) = 1 + (y - 1) = y \hspace*{0,5cm} \text{and} \hspace*{0,5cm} T(\mathcal{U}_1^1; x,y) = (x - 1) + 1 = x.
\]
\end{beispiel}
\begin{beispiel}
We can also use our combinatorial knowledge to determine the Tutte polynomial of a uniform matroid more easily. For the rank-$2$ matroid on a $4$-element set $\Omega$ we can divide up the set of all subsets $A \subseteq \Omega$ using their cardinality $k \coloneqq |A|$. There are $ \begin{pmatrix}
n \\
k
\end{pmatrix} $ -many subsets of size $k$. Using the rank definition for uniform matroids $\rk(A) = \min\{|A|, r\}$,  we get 
\begin{align*}
\begin{pmatrix}
4 \\
0
\end{pmatrix} (x - 1)^{2 - 0} (y - 1)^{0 - 0} &= \begin{pmatrix}
4 \\
0
\end{pmatrix}(x - 1)^2 = (x - 1)^2; \\
\begin{pmatrix}
4 \\
1
\end{pmatrix}(x - 1)^{2 - 1} (y - 1)^{1 - 1} &= \begin{pmatrix}
4 \\
1
\end{pmatrix}(x - 1); \\ 
\begin{pmatrix}
4 \\
2
\end{pmatrix}(x - 1)^{2 - 2} (y - 1)^{2 - 2} &= \begin{pmatrix}
4 \\
2
\end{pmatrix};\\
\begin{pmatrix}
4 \\
3
\end{pmatrix}(x - 1)^{2 - 2}(y - 1)^{3 - 2} &= \begin{pmatrix}
4 \\
3
\end{pmatrix}(y - 1); \\ 
\begin{pmatrix}
4 \\
4
\end{pmatrix}(x - 1)^{2 - 2} (y - 1)^{4 - 2} &= (y - 1)^2 . 
\end{align*}
Thus, 
\begin{align*}
T(U_4^2; x,y) &= (x - 1)^2 + \begin{pmatrix}
4 \\
1
\end{pmatrix}(x - 1) + \begin{pmatrix}
4 \\
2
\end{pmatrix} + \begin{pmatrix}
4 \\
3
\end{pmatrix}(y - 1) + (y - 1)^2 \\ 
&= x^2 + 2x + 2y + y^2.
\end{align*}
\end{beispiel}
In the previous example, the Tutte polynomial of the uniform matroid did not have summands containg the product $xy$. In fact, this is not surprising. Let $\mathcal{U}_n^r$ be a rank-$r$ uniform matroid and $A \subseteq \Omega$. Either $r > |A|$ or $r \leq |A|$ is satisfied, thus we can bipartite $\Omega$ and get 
\[
T(U_{n}^r;x,y) = \sum_{\substack{A \subseteq \Omega \\ 
|A| < r}} (x - 1)^{\rk(\Omega) - \rk(A)} (y - 1)^{\n(A)} + \sum_{\substack{A \subseteq \Omega \\
|A| \geq r}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)}.
\]
If $r > |A|$, then 
\[
\rk(\Omega) - \rk(A) = \min\{|\Omega|, r\} - \min\{|A|, r\} = r - |A|
\]
and 
\[
|A| - \rk(A) = |A| - \min\{|A|,r\} = |A| - |A| = 0.
\]
If $r \leq |A|$, then 
\[
\rk(\Omega) - \rk(A) =  \min\{|\Omega|, r\} - \min\{|A|, r\} = r - r = 0
\]
and 
\[
|A| - \rk(A) = |A| - r. 
\]
Together this results in
\[
T(\mathcal{U}_{n}^r;x,y) = \sum_{\substack{A \subseteq \Omega \\ 
|A| < r}} (x - 1)^{r - |A|} + \sum_{\substack{A \subseteq \Omega \\
|A| \geq r}}(y - 1)^{|A| - r}.
\]
Using the binomial theorem and other combinatorial identities for the binomial coefficient, it is possible to show the following formula from \cite{ElMo2022}:
\[T(\mathcal{U}_n^r; x,y) =\begin{cases}
x^n & \text{if } r = n;\\
y^n& \text{if } r = 0;
\end{cases}\]
and otherwise, 
\[
T(\mathcal{U}_n^r; x,y) = \sum_{i = 0}^{r - 1} \biggl(\begin{matrix}
n - r - 1 + i \\
i
\end{matrix}\biggr)x^{r - i} + \sum_{j = 0}^{n - r - 1} \biggl(\begin{matrix}
r - 1 + j \\
j
\end{matrix}\biggr) y^{n - r - j}.
\]
\indent The next theorem shows how the Tutte polynomial of a matroid corresponds to the Tutte polynomial of its dual. 
\begin{theorem}
Let $\M$ be a matroid, and $\M^\perp$ be its dual, then 
\[
T(\M^\perp;x,y) = T(\M;y,x).
\]
\end{theorem}
\begin{proof}
We will show that $\rk^\perp(\Omega) - \rk^\perp(A) = \n(\overline{A})$ and $\n^\perp(A) = \rk(\Omega) - \rk(\overline{A})$. This suffices because the summation includes every subset $A \subseteq \Omega$. Using the definition of the dual rank function and the dual nullity function, we get 
\[
\rk^\perp(\Omega) - \rk^\perp(A) = |\Omega| - \rk(\Omega) - |A| - \rk(\overline{A}) + \rk(\Omega) = |\overline{A}| - \rk(\overline{A}) = \n(\overline{A})
\]
and 
\[
\n^\perp(A) = |A| - \rk^\perp(A) = |A| - |A| - \rk(\overline{A}) + \rk(\Omega) = \rk(\Omega) - \rk(\overline{A}). \qedhere
\]
\end{proof}
\begin{lemma}
Let $M = (\Omega, \rk)$ be a matroid. Then 
\begin{equation} \label{(2)}
\rk(\Omega) = 
\begin{cases}
\rk(\Omega - e) + 1, & \text{if} \ e \ \text{is a coloop}; \\
\rk(\Omega - e), & \text{otherwise}.
\end{cases}
\end{equation}
Let $\rk_{\M / e}$ and $\n_{\M / e}$ denote the rank and nullity functions of $\M / e$, then for all subsets $A \subseteq \Omega - e$ we have
\begin{equation}\label{(3)}
\rk_{\M / e }(A) = \begin{cases}
\rk(A \cup e), & \text{if } \ e \ \text{is a loop}; \\ 
\rk(A \cup e) - 1, & \text{otherwise}; 
\end{cases}
\end{equation}
and 
\begin{equation} \label{(4)}
\n_{\M / e}(A) = \begin{cases}
\n(A \cup e) - 1, & \text{if} \ e \ \text{is a loop}; \\
\n(A \cup e), & \text{otherwise}.
\end{cases}
\end{equation}
\end{lemma}
\begin{proof}
It was already proven that $\rk(\Omega - e) = \rk(\Omega) - 1$ if and only if $e$ is a coloop. If $e$ is not a coloop, then 
\begin{align*}
1 &= rk^\perp(e) = |e| + \rk(\Omega - e) - \rk(\Omega) = 1 + \rk (\Omega - e) - \rk(\Omega) \\ 
\Longleftrightarrow \rk(\Omega - e) &= \rk(\Omega)
\end{align*}
Now for the rank and nullity functions of $\M /e $ we use their definitions: 
\[
\rk_{\M / e}(A) = \rk(A \cup e) - \rk(e). 
\]
 If $e$ is a loop $\rk(e) = 0$. Otherwise $0 < \rk(e) \leq |\{e\}| = 1$. Moreover,
\[
\n_{\M / e}(A) = |A| - \rk_{\M / e} = |A| - \rk(A \cup e) + \rk(e).
\] If $e$ is a loop we get \[
\n_{\M / e}(A) = |A \cup e| - 1 - \rk(A \cup e) = \n(A \cup e) - 1
\]
and otherwise 
\[
\n_{\M / e}(A) = |A| - \rk(A \cup e) + 1 = |A \cup e| - \rk(A \cup e) = \n(A \cup e).
\]
\end{proof}
With this lemma we can now formulate the deletion-contraction algorithm of the Tutte polynomial. 
\begin{theorem}
Let $e$ be an element of a matroid $\M$. Then 
\[
T(\M; x,y) = \begin{cases}
 1, & \text{if} \ \Omega = \emptyset; \\
 yT(\M - e; x,y), & \text{if} \ e \ \text{is a loop}; \\  xT(\M / e; x,y), & \text{if} \ e \ \text{is a coloop}; \\ 
 T(\M - e; x,y) + T(\M / e; x,y), & \text{otherwise}.
\end{cases}
\]
\end{theorem}
\begin{proof}
Let $e$ be an element of the matroid $M = (\Omega, \rk)$. Clearly 
\begin{equation} \label{(7)}
T(M;x,y) = \sum_{\substack{A \subseteq \Omega \\ e \not \in A}} (x - 1)^{\rk(\Omega) - \rk(A)} (y - 1)^{\n(A)} + \sum_{\substack{A \subseteq \Omega \\ e \in A}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)}.
\end{equation}
Let us look at the first term on the right hand side, where
\[
\sum_{\substack{A \subseteq \Omega \\ e \not \in A}} (x - 1)^{\rk(\Omega) - \rk(A)} (y - 1)^{\n(A)} = \sum_{A \subseteq \Omega - e} (x - 1)^{\rk(\Omega) - \rk(A)} (y - 1)^{\n(A)}.
\]
Now using \eqref{(2)} from the previous lemma we get 
\[
\sum_{\substack{A \subseteq \Omega \\ e \not \in A}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)} = \begin{cases} 
(x - 1) \sum\limits_{A \subseteq \Omega - e} x^{\rk(\Omega - e) - \rk(A)} y^{\n(A)}, & \text{if} \ e \ \text{is a coloop}; \\ 
& \\
\sum\limits_{A \subseteq \Omega - e} x^{\rk(\Omega - e) - \rk(A)}y^{\n(A)}, & \text{otherwise}.
\end{cases}
\]
Hence 
\begin{equation} \label{(5)}
\sum_{\substack{A \subseteq \Omega \\ e \not \in A}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)} = \begin{cases}
(x - 1) T(\M - e; x,y), & \text{if} \ e \ \text{is a coloop}; \\ 
T(\M - e; x,y), & \text{otherwise}. 
\end{cases}
\end{equation}
Now consider the second term on the right-hand side of \eqref{(7)}. With 
\[
\sum_{\substack{A \subseteq \Omega \\ e \in A}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)} = \sum_{A \subseteq \Omega - e} (x - 1)^{\rk((\Omega - e) \cup e) - \rk(A \cup e)}(y - 1)^{\n(A \cup e)} 
\]
and \eqref{(3)} and \eqref{(4)} we get 
\begin{align*}
& \sum_{\substack{A \subseteq \Omega \\ e \in A}}(x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)}  \\
&=  \begin{cases}
(y - 1) \sum\limits_{A \subseteq \Omega - e} (x - 1)^{\rk_{\M / e}(\Omega - e) - \rk_{\M / e}(A)} (y - 1)^{\n_{\M / e}(A)}, & \text{if} \ e \ \text{is a loop}; \\
& \\ 
\sum\limits_{A \subseteq \Omega - e} (x - 1)^{\rk_{\M / e }(\Omega - e) - \rk_{\M / e}(A)} (y - 1)^{\n_{\M / e}(A)}, & \text{otherwise}.
\end{cases}
\end{align*}
Hence 
\begin{equation} \label{(6)} 
\sum_{\substack{A \subseteq \Omega \\ e \in \Omega}} (x - 1)^{\rk(\Omega) - \rk(A)}(y - 1)^{\n(A)} = \begin{cases}
(y - 1)T(\M / e; x,y), & \text{if} \ e \ \text{is a loop}; \\
T(\M / e; x,y,) & \text{otherwise}.
\end{cases}
\end{equation}
Now by substituting \eqref{(5)} and \eqref{(6)} into \eqref{(7)}, we obtain 
\[
T(M; x,y) = \begin{cases}
y T(\M / e; x,y) & \text{if} \ e \ \text{is a loop}, \\
x T(\M - e; x,y) & \text{if } \ e \ \text{is a coloop}, \\
T(\M - e; x,y) + T(\M / e;x,y) & \text{otherwise}.
\end{cases}
\]
The result now follows with Lemma 3.38, which states that $\M - e = \M / e$ if and only if $e$ is a loop or a coloop of $\M$.
\end{proof}
\begin{remark}
From the previous theorem it is obvious, that if $\M$ is a matroid with $k$ bridges and $l$ loops and no other edges, then its Tutte polynomial is $T(\M;x,y) = x^ky^l$. 
\end{remark}
\begin{beispiel}
The Tutte polynomial for the two matroids on an one-element set are also easily determined with this equivalent definition. 
For the rank-$0$ uniform matroid we see that $e = \{1\}$ is a loop, since $\rk(\{1\}) = 0$. Therefore
\[
T(\mathcal{U}_1^0; x,y) = y \cdot T(\mathcal{U}_1^0 - \{1\}; x,y) 
= y \cdot T(\mathcal{U}_0^0; x,y) = y \cdot 1 = y.
\]
The dual matroid $(\mathcal{U}_1^1)^\perp)$ has rank function $\rk^\perp(A) = |A| - \min(|\overline{A}|, 1) - 0$. Thus for $A = \{1\}$ we get $\rk^\perp(\{1\}) = 1 - 1 = 0$, which means that $\{1\}$ is a coloop in $\mathcal{U}_1^1$. Therefore
\[
T(\mathcal{U}_1^1; x,y) = x \cdot T(\mathcal{U}_1^1 / \{1\}; x,y) 
= x \cdot T((\emptyset, \rk_{\mathcal{U}_1^1/ \{1\}});x,y) = x \cdot T((\emptyset,1);x,y)
= x \cdot 1 = x.
\]
\end{beispiel}
The following theorem proves that the Tutte polynomial is multiplicative on direct sums. We will use this in the next section to argue that the Tutte polynomial is a Tutte-Grothendieck invariant. 
\begin{theorem}
Let $\M_1$ and $\M_2$ be two matroids. Then 
\[
T(\M_1 \oplus \M_2; x,y) = T(\M_1; x,y) \cdot T(\M_2; x,y).
\]
\end{theorem}
\begin{proof}
Let $\M \coloneqq \M_1 \oplus \M_2$ and $A$ be a subset of $\Omega = \Omega_1 \cup \Omega_2$. We can write $A = A_1 \cup A_2$ such that $A_1 \subseteq \Omega_1$ and $A_2 \subseteq \Omega_2$. Therefore
\begin{equation}\label{test20}
T(\M_1 \oplus \M_2; x,y) = \sum_{A \subseteq \Omega_1 \cup \Omega_2} (x - 1)^{\rk_{\M}(\Omega_1 \cup \Omega_2)- \rk_{\M}(A_1 \cup A_2)} (y - 1)^{|A_1 \cup A_2| - \rk_{\M}(A_1 \cup A_2)}.
\end{equation}
Now we can use Theorem 3.41, such that the right hand side of equation \eqref{test20} equals 
\[
\sum_{A_1 \subseteq \Omega_1}\sum_{A_2 \subseteq \Omega_2} (x - 1)^{\rk_{\M_1}(\Omega_1) + \rk_{M_2}(\Omega_2) - \rk_{\M_1}(A_1) - \rk_{\M_2}(A_2)} (y - 1)^{|A_1| + |A_2| - \rk_{\M_1}(A_1) - \rk_{M_2}(A_2)}. 
\]
Using that exponents are either dependent of subsets of $\Omega_1$ or $\Omega_2$ we get 
\begin{align*}
\sum_{A_1 \subseteq \Omega_1} (x - 1)^{\rk_{\M_1}(\Omega_1) - \rk_{\M_1}(A_1)} & (y - 1)^{|A_1| - \rk_{\M_1}(A_1)}  \\ & \cdot \sum_{A_2 \subseteq \Omega_2}(x - 1)^{\rk_{\M_2}(\Omega_2) - \rk_{\M_2}(A_2)} (y - 1)^{|A_2| - \rk_{\M_2}(A_2)}.
\end{align*}
But this is exactly the product ot the Tutte Polynomials 
\[
T(\M_1 \oplus \M_2;x,y) = T(\M_1; x,y) \cdot T(\M_2;x,y). \qedhere
\]
\end{proof}
\begin{beispiel}
Continuing our example of the two matroids on an one-element set and considering their direct sum from Example 3.42 again, this theorem tells us 
\[
T(\mathcal{U}_1^0 \oplus \mathcal{U}_1^1;x,y) = x \cdot y.
\]
\end{beispiel}
\subsection{The Tutte Polynomial as a Matroid Invariant}
In this section, we define \textit{matroid isomorphisms} and \textit{matroid isomorphism invariants}, specifically the \textit{Tutte-Grothendieck invariants}. We also talk about the \textit{chracteristic polynomial} of a matroid and use its characteristics to argue that it is in fact a Tutte-Grothendieck invariant. We prove the \textit{recipe theorem} of Dominic Welsh in Theorem 3.61 and show that the characteristic polynomial of a matroid is in fact just a specialization of the Tutte polynomial.
\begin{definition}
Let $\M_1$ and $\M_2$ be two two matroids and $\psi: \Omega_1 \to \Omega_2$ be a bijection such that for all $A \subseteq \Omega_1$ the set $\psi(A)$ is independent in $\M_2$ if and only if $A$ is independent in $\M_1$. We call such a bijection $\psi$ an \textit{isomorphism} from $\M_1$ to $\M_2$, say $\M_1$ and $\M_2$ are \textit{isomorphic} and denote it by $\M_1 \cong \M_2$.
\end{definition}
\begin{definition}
A matroid \textit{isomorphism invariant} is a function $f$ on the class of all matroids, such that if $\M_1 \cong \M_2$ then $f(\M_1) = f(\M_2)$.
\end{definition}
\begin{theorem}
The Tutte polynomial is a matroid isomorphism invariant.
\end{theorem}
\begin{proof}
Let $\M_1 = (\Omega_1, \mathcal{I}_1)$ and $\M_2 = (\Omega_2, \mathcal{I}_2)$ be two matroids and let $\psi: \M_1 \to M_2$ be a matroid isomorphism. Then by definition of bijection, $|A| = |\psi(A)|$ for any subset $A \subseteq \Omega_1$, particularly $|I_1| = |\psi(I_1)|$ for any independent set $I_1 \in \mathcal{I}_1$. Since the rank function of a set $A$ is defined as the cardinality of any inclusion-maximal independent set contained in $A$, all values needed for the computation of the Tutte Polynomial are constant under the isomorphism. In particular, $\rk(\Omega_1) = \rk(\Omega_2), \rk(A) = \rk(\psi(A))$ and $|A| = |\psi(A)|$, for all $A \subseteq \Omega_1$. Together, 
\[
T(\M_1;x,y) = T(\M_2; x,y). \qedhere
\]
\end{proof}
We want to point out once more, that the rank function of a subset does not alter under matroid isomorphisms. Evaluating the Tutte polynomial for specific $x$ and $y$ values returns information about different attributes of the matroid.
\begin{theorem}
Let $\M = (\Omega, \rk)$ be a matroid. Then we have the following evaluations:
\begin{itemize}
\item[1.] $T(\M; 1,1)$ is the number of bases of $\M$, 
\item[2.] $T(\M;2,1)$ is the number of independent sets of $\M$, 
\item[3.] $T(\M;1,2)$ is the number of spanning sets of $\M$, 
\item[4.] $T(\M;2,2) = 2^{|\Omega|}$.
\end{itemize}
\end{theorem}
\begin{proof}
Firstly,\[
T(\M;1 ,1 ) = \sum_{A \subseteq \Omega} 0^{\rk(\Omega) - \rk(A)}\cdot 0^{|A| - \rk(A)}
\]
and 
\[
0^{\rk(\Omega) - \rk(A)}\cdot 0^{|A| - \rk(A)} \neq 0 \Longleftrightarrow \rk(\Omega) = \rk(A) \wedge |A| = \rk(A),\] 
therefore $A$ is an independent set and has size $\rk(\Omega)$, hence $A$ is a basis. 
Secondly, 
\[
T(\M; 2,1) = \sum_{A \subseteq \Omega} 1^{\rk(\Omega) - \rk(A)} 0^{|A| - \rk(A)} = \sum_{A \subseteq \Omega} 0^{|A| - \rk(A)}
\]
and
\[0^{|A| - \rk(A)} \neq 0 \Longleftrightarrow |A| = \rk(A)
,\] thus this counts the number of independent sets. 
Thirdly, \[
T(\M; 1,2) = \sum_{A \subseteq \Omega} 0^{\rk(\Omega) - \rk(A)}\cdot 1^{|A| - \rk(A)} = \sum_{A \subseteq \Omega}0^{\rk(\Omega) - \rk(A)} 
\]and 
\[
0^{\rk(\Omega) - \rk(A)} \neq 0 \Longleftrightarrow \rk(\Omega) = \rk(A)
\] which is true if and only if $A$ is a spanning set. 
Lastly, 
\[
T(\M; 2,2) = \sum_{A \subseteq \Omega} 1^{\rk(\Omega) - \rk(A)} \cdot 1^{|A| - \rk(A)} = \sum_{A \subseteq \Omega} 1 = |\mathcal{P}(\Omega)| = 2^{|\Omega|} \qedhere
\]
\end{proof}
In Chapter 2 we discussed different graph invariants. We will now introduce a matroid invariant that is computable trough a recursive deletion-contraction algorithm. 
\begin{definition}
The \textit{characteristic polynomial} $\chi(\M; \lambda)$ of a matroid $M$ is 
\[
\chi(\M; \lambda) = \sum_{A \subseteq \Omega} (-1)^{|A|} \lambda^{\rk(\M) - \rk(A)}.
\] 
This polynomial is also known as the \textit{chromatic polynomial} of $\M$.
\end{definition}
\begin{definition}
Let $\mathcal{C}$ be a class of matroids that is closed under isomorphism and the taking of minors. Let $\mathfrak{R}$ be a commutative ring with unity. An isomorphism invariant $f: \mathcal{C} \to \mathfrak{R}$ is called a \textit{Tutte-Grothendieck invariant} or \textit{T-G-invariant} if it satisfies the following conditions for every matroid $\M, \M_1, \M_2$ in $\mathcal{C}$ and every element $e$ of $\M$. 
\begin{itemize}
\item[1)] (Deletion-contraction) $f(\M) = f(\M - e) + f(\M / e)$ if $e$ is ordinary in $\M$;
\item[2)] (Direct sum) $f(\M_1 \oplus \M_2) = f(\M_1)f(\M_2)$.
\end{itemize} 
\end{definition} 
As discussed in \cite{Za1987} by Thomas Zaslavsky, it is possible to prove that the characteristic polynomial of a matroid is a T-G-invariant by showing that for arbitrary matroids $\M, \M_1, \M_2$, it satisfies 
\[
\chi(\M;\lambda) = \chi(\M - e;\lambda) - \chi(\M / e; \lambda),
\]
if $e$ is not a coloop, and 
\[
\chi(\M_1 \oplus \M_2) = \chi(\M_1) \cdot \chi(\M_2).
\] 
We will refrain from proving this, because we would need to introduce the so-called \textit{Möbius invariant} and discuss its characteristics. However, we only want to give an example of a matroid isomorphism invariant, that is a T-G-invariant for matroids. According to the following theorem, we will then be able to prove that the characteristic polynomial is just a specialization of the Tutte polynomial. \\
\indent By Theorems 3.50 and 3.53 the Tutte polynomial is a T-G-invariant, it is in fact the universal Tutte-Grothendieck invariant. Dominic Welsh \cite{We1999} called this result the \textit{Recipe Theorem} and that name has persisted. We will replace the deletion-contraction formula by a more general recursion. Thus we will not only prove that any T-G-invariant is an evaluation of the Tutte-polynomial, but also any function that satisfies the modified deletion-contraction formula.
\begin{theorem}[Recipe Theorem]
Let $\sigma$ and  $\tau$ be elements of a field $\mathbb{F}$. Let $\mathcal{C}$ be a class of matroids that is closed under direct sums and the taking of minors. Furthermore let $f$ be an isomorphism invariant mapping $\mathcal{C}$ into $\mathbb{F}$. Suppose $f$ satisfies the following recursions for all matroids $\M$ and all elements $e \in \M$:
\begin{itemize}
\item[1)] $f(\M) = \sigma f(\M - e) + \tau f(\M / e)$ if $e$ is neither a loop nor a coloop of $\M$; 
\item[2)] $f(\M_1 \oplus \M_2) = f(\M_1) f(\M_2)$ for any matroids $\M_1, \M_2 \in \mathcal{C}$.
\end{itemize}
Then
\[
f(\M) = \sigma^{|\Omega| - \rk(\Omega)}\tau^{\rk(\Omega)}T\left(\M;\frac{x_0}{\tau}, \frac{y_0}{\sigma}\right),
\]
where $x_0, y_0$ are the values $f$ takes on coloops and loops respectively. 
\end{theorem}
\begin{remark}
Condition 2) of a T-G-invariant gives information about what it does on an empty set. Namely let $\M = (\emptyset, \{\emptyset\})$, then $f(\M) = f(\M \oplus \M) = f(\M) f(\M)$, which can only be true if $f(\M) = 1$. After we have established this result, we can substitute condition 2 with the following conditions:
\begin{itemize}
\item[2.1)] $f(\M) = 1$, where $\M$ is the matroid on a empty set. 
\item[2.2)] $f(\M) = f(\M|e) f(\M - e)$, where $\M$ is any matroid and $e$ is either a loop or coloop.
\end{itemize}
Condition 2.2) follows from condition 2) by Lemma 3.45, since $\M = \M|e \oplus \M - e$ for any matroid $\M$ if $e$ is a loop or coloop of $\M$. Therefore condition 2) is equivalent to 2.1) and 2.2).
\end{remark}
\begin{proof}[Proof of Theorem 3.62.]
We will prove by induction on the cardinality of the ground set $\Omega$. First let $|\Omega| = 0$, this is possible if and only if the matroid on $\Omega$ is $\M = (\emptyset, \{\emptyset\})$. As established in the last remark $f(\M)= 1$ and with $\rk(\emptyset) = 0$ and $T((\emptyset, \{\emptyset\}); \frac{x_0}{\tau}, \frac{y_0}{\sigma}) = 1$ we get 
\[
1 = f(\M) = \sigma^0 \tau^0 \cdot 1 = 1. 
\]
Let $\M = (\Omega, \mathcal{I})$ be an arbitrary matroid with ground set $\Omega$ such that $|\Omega| = m + 1$ for some $m \in \mathbb{N}$. Suppose the statement holds for all matroids with ground set $\Omega - e$ for any element $e \in \Omega$. Then for the inductive step we want to show that the statement holds for $\M = (\Omega, \mathcal{I})$. First let $e$ be a loop in $\M$, then as noted before $f(\M) = f(\M|e)f(\M - e)$. With $f(\M|e) = y_0$, since $e$ is a loop, we get 
\[
f(\M) = f(\M |e) f(\M - e) = y_0 \cdot f(\M - e).
\]
Because $\M - e$ is a matroid on $\Omega - e$ the induction hypothesis holds for this matroid, hence it is a specialization of the Tutte polynomial and
\[
f(\M) = y_0 \cdot \sigma^{|\Omega - e| - \rk_{\M - e}(\Omega - e)}\tau^{\rk_{\M - e}(\Omega - e)}T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\]
We know $\M - e = \M / e$ for a loop and $\rk_{\M / e}(\Omega - e) = \rk_\M(\Omega - e \cup e) = \rk_\M(\Omega)$, hence we can conclude 
\begin{equation}\label{test}
f(\M) = y_0 \cdot \sigma^{|\Omega - e| - \rk_{\M}(\Omega)}\tau^{\rk_{\M}(\Omega)}T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\end{equation} Now with Theorem 3.50, since $e$ is a loop, we have
\[
\frac{y_0}{\sigma} \cdot T\left(M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) = T\left(\M; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\]
Thus, continuing equation \eqref{test}, we proved the statement: 
\[
f(\M)
= \sigma^{|\Omega| - \rk_{\M}(\Omega)}\tau^{\rk_{\M}(\Omega)}T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\]
Now let $e$ be a coloop in $\M$. Then $f(\M) = f(\M|e) f(\M - e)$ and $f(\M|e) = x_0$, since $e$ is a coloop. Therefore,
\[
f(\M) = f(\M|e) f(\M - e) = x_0 \cdot f(\M - e),
\]
and again $\M - e$ is a matroid on $\Omega - e$, hence the induction hypothesis holds, stating
\[
f(\M) = x_0 \cdot \sigma^{|\Omega - e| - \rk_{\M - e}(\Omega - e)}\tau^{\rk_{\M - e}(\Omega - e)}T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\]
Now we can use Lemma 3.49 for the coloop $e$, hence $\rk(\Omega) = \rk(\Omega - e) + 1$ and we get 
\begin{equation}\label{test2}
f(\M) = x_0 \cdot \sigma^{|\Omega| - \rk_{\M}(\Omega)} \tau^{\rk_{\M}(\Omega) - 1} T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right). 
\end{equation}
Because $e$ is a coloop, we again have $\M - e = \M / e$. Therefore Theorem 3.50 gives us 
\[
\frac{x_0}{\tau} T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) = \frac{x_0}{\tau}  T\left(\M / e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) = T\left(\M; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right)
\] 
Finally equation \eqref{test2} proves the statement for a coloop: 
\[
f(\M) = \sigma^{|\Omega| - \rk_{\M}(\Omega)} \tau^{\rk_{\M}(\Omega)} T\left(\M; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\]
Lastly, let $e$ be an element that is ordinary, then by condition 1) of a T-G-invariant we have
\[
f(\M) = \sigma f(\M - e) + \tau f(\M / e).
\] 
and we can use the induction hypothesis for $\M - e$ and $\M /e$, which returns
\begin{align*}
f(\M) = &\sigma( \sigma^{|\Omega - e| - \rk_{\M - e}(\Omega - e)} \tau^{\rk_{\M - e}(\Omega - e)} T\left(\M - e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) + \\ &\tau (\sigma^{|\Omega - e| - \rk_{\M / e}(\Omega - e)}\tau^{\rk_{\M / e}(\Omega - e)}T\left(\M / e; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right).
\end{align*}
We can use $\rk_{\M - e}(\Omega - e) = \rk_\M(\Omega -e)$, $\rk_{\M / e}(\Omega - e) = \rk_{\M}(\Omega) - 1$ from Lemma 3.49 for ordinary elements of a matroid. This will leave us with 
\begin{equation} \label{test3}
f(\M) = \sigma^{|\Omega| - \rk_{\M}(\Omega)}\tau^{\rk_{\M}(\Omega)} \left(T\left(\M - e;  \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) + T\left(\M / e;  \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right)\right).
\end{equation} We can again use Theorem 3.50 to obtain
\[
T\left(\M - e;  \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right) + T(\M / e;  \frac{x_0}{\tau}, \frac{y_0}{\sigma}) = T\left(\M; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right)
\]
and get with equation \eqref{test3} the final result
\[
f(\M) = \sigma^{|\Omega| - \rk_{\M}(\Omega)}\tau^{\rk_{\M}(\Omega)} T\left(\M; \frac{x_0}{\tau}, \frac{y_0}{\sigma}\right). \qedhere
\]
\end{proof}
We are closing this chapter by showing that the characteristic polynomial of a matroid is just a specialization of the Tutte polynomial. Let $\M = (\Omega, \rk)$ be a matroid. Then
\[
\chi(\M; \lambda) = (-1)^{\rk(\Omega)}T(\M; 1 - \lambda, 0).
\]
We have seen that $\chi$ is a Tutte-Grothendieck invariant. Hence we only need to insert the specific values into the recipe theorem, where $\sigma = 1$, $\tau =  -1$, $y_0 = 0$ and $x_0 = \lambda - 1$. Thus, 
\[
\chi(\M; \lambda) = (-1)^{\rk(\Omega)}T\left(\M; \frac{\lambda - 1}{-1}, 0\right). \qedhere
\]
\newpage
\section{Graphs as Matroids}
In the last two chapters we introduced graphs and matroids independently. We now want to give deteiled connections between the two notions. The goal of this chapter is to show that graph polynomials introduced in Chapter 2 are specializations of the Tutte polynomial for graphs. In Section 4.1 we start by defining the matroid for a given graph $G$, called the \textit{Cycle Matroid}, and discuss a convenient way to deduce the rank of a subset from the drawing of the graph $G$. We introduce the dual matroid to the cycle matroid, called the \textit{Bond Matroid} and shortly discuss so-called \textit{graphic} matroids. In Section 4.3 we use the cycle matroid of a graph to define the Tutte polynomial of a graph, which is also computable by a deletion-contraction algorithm. Lastly, in Section 4.4 we consider the Tutte polynomial as a graph invariant and define Tutte-Grothendieck invariants for graphs. This enables us to state and prove the recipe theorem for graphs. Unfortunately, the polynomials in Chapter 2 do not satisfy all conditions to be T-G-invariants for graphs, so that we need to modify the recipe theorem. Using the modified recipe theorem, we are then able to directly prove that the chromatic polynomial, the flow polynomial and the reliability polynomial are all specializations of the Tutte polynomial for graphs. 
\subsection{The Cycle Matroid}
This section provides a short overview of the most important properties of a matroid deduced from a graph $G$. The matroid is constructed by taking the set of edges $E(G)$ as ground set and defining a rank function on the subsets of $E(G)$. The most useful information of this section is Theorem 4.3, where we prove that the rank of a subset can be directly read off of the drawing of a graph. More specifically, we obtain the rank of a subset by subtracting the number of components of the underlying subgraph from the number of vertices of $G$. We finish this section by showing that deleting or contracting a set from the cycle matroid of $G$ is equal to deleting or contracting the set from $G$ and constructing the cycle matroid afterwards. With this information, everythinig that was proven for matroids in Chapter 3 holds for cycle matroids too. 
\begin{definition} 
Let $G = (V,E)$ be a graph with $|V| =  n$ and $I$ be the incidence matrix of an arbitrary orientation of $G$. 
Let $\Omega \coloneqq E(G)$ and for a subset $A \subseteq E$ we identify the elements of $A$ with the corresponding columns of $I$ by $e_i \in A $ only if $i \in S \subseteq \{1, \dots, n\}$. Now we define the rank function to be
\[
\grk(A) \coloneqq \ \text{rank}(I_S)
\]
where $I_S$ is the submatrix with the columns indexed by $S$ and $\text{rank}(I_S) = \dim(\mathrm{span}(A))$. We call $(E(G), \grk)$ the \textit{cycle matroid} of $G$ and denote it by $\M(G)$.  
\end{definition}
We are going to identify $A \subseteq E(G)$ with the spanning subgraph of $G$ on the edge set $A$ for the rest of the chapter. 
\begin{beispiel} 
Consider the plane graph $G$ in Figure 14. We want to look at the cycle matroid of the graph $G$ in more detail. 
\begin{center}
\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!10, 		thick, inner sep=0pt, minimum size=3.5mm}, baseline=-0.5ex]
	\node at (0,0) [knoten](1) {$v_1$};
	\node at (0,2) [knoten](2) {$v_2$}
		edge[->, line width= 1.25pt] node[auto]{$e_5$}(1)
		edge[->, bend left = 70, line width= 1.25pt] node[auto] {$e_2$}(1);
	\node at (-1, 1)[knoten](3) {$v_3$}
		edge[->, line width= 1.25pt] node[auto]{$e_4$}(2)
		edge[<-, line width= 1.25pt] node[auto, swap]{$e_1$}(1);

\Loop[dist=1cm,dir=NO,label = $e_3$,labelstyle=above](2);

\end{tikzpicture}
\captionof{figure}{Graph $G$ from Example 4.2 with orientation $\omega$.}
        \label{fig:label}
\end{center}
The incidence matrix for an orientation $\omega$ of $G^\omega$ is 
\[D_G = 
\begin{blockarray}{cccccc}
& e_1 & e_2 & e_3 & e_4 & e_5 \\
\begin{block}{c(ccccc)}
v_1 & \phantom{-}1 & -1 & \phantom{-}0 & \phantom{-}0 & -1 \\
v_2 & \phantom{-}0 & \phantom{-}1 & \phantom{-}0 & -1 & \phantom{-}1 \\
v_3 & -1 & \phantom{-}0 & \phantom{-}0 & \phantom{-}1 & \phantom{-}0 \\
\end{block}
\end{blockarray}
\]
and the associated matroid is
\begin{align*}
\M(G) &= \bigg(\bigg\{e_1,e_2, e_3, e_4, e_5\bigg\}, \\ & \ \ \  \bigg\{\{e_1\}, \{e_2\}, \{e_4\}, \{e_5\}, \{e_1, e_2\}, \{e_1, e_4\}, \{e_1, e_5\}, \{e_2, e_4\}, \{e_4, e_5\}\bigg\}\bigg).
\end{align*}
The next theorem shows how we can see the rank of a subgraph without setting up the incidence matrix first.
\end{beispiel}
\begin{theorem}
Let $G$ be a graph with $|V| = n$ and $A \subseteq E$. Then 
\[
\grk(A) = n - c(A).
\]
\end{theorem}
\begin{proof}
We start by noting that for the definition of the rank function of a cycle matroid, the dimension formula for any matrix $A \in \mathbb{R}^{n \times m}$ holds: 
\[
\grk(A) = \mathrm{rank}(I_S) = \dim(\mathrm{img}(I_S)) = m - \dim(\mathrm{ker}(I_S)). 
\]
For the transpose $A^T \in \mathbb{R}^{m \times n}$ we have
\[
\grk(A^T) = \mathrm{rank}(I_S^T) = \dim(\mathrm{img}(I_S^T)) = n - \dim(\mathrm{ker}(I_S^T)).
\]
To prove the theorem, we only need to compare the number of connected components of the subset $A$ with the dimension of the kernel of $I_S^T$. \\
\indent Now for an element $x \in \ker(I_S^T) = \{x \in \mathbb{R}^n: I_S^Tx = 0\} = \{x \in \mathbb{R}^n: x^T I_S = 0\}$ the following holds for each column $I_i$ such that $i \in S$: 
\[
0 = x^TI_i = x_1 I_{i_1} + x_2 I_{i_2} + \dots + x_n I_{i_n}. 
\]
Each column only has two nonzero entries, at the incident vertices of the corresponding edge. Let $k$ and $l$ be the indices of the vertices $u$ and $v$ with the edge corresponding to $i$ being directed $u \to v$. Then 
\[
0 = x^T I_i = x_k - x_l \Longleftrightarrow x_k = x_l.
\]
Hence, the enries of $x$ have to be equal whenever the corresponding vertices are connected in $A$. Therefore, for each connected component of $A$ there is exactly one element in the basis of $\mathrm{ker}(I_S^T)$, giving us $\dim(\mathrm{ker}(I_S^T)) = c(A)$.
\end{proof}
\begin{lemma}
Let $G$ be a graph. A subset $A \subseteq E(G)$ is a dependent set of the cycle matroid $\M(G)$ if and only if the induced subgraph on $A$ has a cycle. 
\end{lemma}
\begin{proof}
Let $A$ be a subset of $E(G)$ and $Y \subseteq A$ be a connected induced subgraph of $A$, hence we only connsider the vertices which are incident to some edge in $Y$. With the last theorem we get $\grk(Y) = |V(Y)| - 1$. Now suppose $Y$ is independent, then since $\grk(Y) = |E(Y)|$ we get 
\begin{equation} \label{(10)}
|E(Y)| = |V(Y)| - 1. 
\end{equation}
However, we proved in Theorem 2.11 that a connected graph satisfies equation \eqref{(10)} if and only if the graph is a tree, hence if and only if it is acyclic. 
\end{proof}
\begin{remark}
With the previous lemma, we showed that the independent sets in the cycle matroid of a graph are exactly those where the induced subgraph does not contain a cycle. Moreover, it follows that the circuits of the cycle matroid $\M(G)$ are the cycles of $G$ and the bases of $\M(G)$ are the maximal spanning forests of $G$.
\end{remark}
\begin{lemma}
If $G$ is a graph, then $e \in G$ is a loop if and only if $e \in \M(G)$ is a loop.
\end{lemma}
\begin{proof}
An element $e \in \M(G)$ is by definition a loop if it satisfies $\grk(e) = 0$. With the definition of the rank function for a cycle matroid, this means that the column in the incidence matrix of $G$ corresponding to the edge $e$ must have rank $0$. But this is true if and only if the column has only zeroes as entries. But by the definition of the incidence matrix, it has a column with only zero-entries if and only if the corresponding edge is a loop in the graph.
\end{proof}
The previous lemma justifies the name "loop" for an element with rank zero of a matroid. 
\begin{theorem}
Let $G$ be a graph, and $T \subseteq E(G)$. Then 
\[
\M(G) - T = \M(G - T) \ \ \ \ \ \ \ and  \ \ \ \ \ \ \ \M(G) / T = \M(G / T).
\]
\end{theorem}
\begin{proof}
The first statement is clear from the definition of deletion for independent sets. 
For the second one we want to show that for an arbitrary edge $e \in E(G)$ 
\[
\M(G) / e = \M(G / e).
\] If $e$ is a loop of $G$ then $G / e = G - e$ and by Lemma 3.38 $M - e = M / e$. The result then follows with the first statement of this lemma. Now suppose that $e$ is not a loop of $G$. Then we need to compare the sets of independent sets. By definition, and since $e$ is not a loop, the set of independent sets $\tilde{\mathcal{I}}$ of $\M(G) / e$ is 
\[
\tilde{\mathcal{I}} = \{I \subseteq E(G) - e  \ | \  I \cup \{e\} \in \mathcal{I}\},
\]
where $\mathcal{I}$ is the set of independent sets of $\M$. And with Lemma 4.4 these are exactly the subsets not containing a cycle in $G/ e$. Let $A \in \tilde{\mathcal{I}}$. Then $A = I \cup \{e\}$ does not contain a cycle of $G$. If we prove that $I \cup \{e\}$ is acyclic in $G$ if and only if $I$ is acyclic in $G/e$, the set of independent sets of the matroids are the same and the result follows. \\
Let $I \cup \{e\}$ be acyclic in $G$. Then there is no path in $I \cup \{e\} - \{e\}$ connecting the end-vertices of $e$, hence $I$ is acyclic in $G / e$. Let $u,v$ denote the end-vertices of $e$ and $w$ the vertex identified with $u$ and $v$ after contracting. If $I$ is acyclic in $G / e$, then there is no path in $I$ from the vertex $w$ to itself, thus before contracting there is no path in $I$ connecting the vertices $u$ and $v$. Therefore, adding the edge $e$ will not result in a cycle. \qedhere
\end{proof}
\subsection{The Bond Matroid}
We now want to discuss the dual matroid of the cycle matroid, by taking the definition of $\rk^\perp$ from Chapter 3 and applying it to $\grk$. We will construct the bond matroid of a graph and shortly discuss so-called \textit{graphic} matroids. These are matroids that are isomorphic to a cycle matroid of a graph. In fact, not all matroids are graphic. We will consider the smalles matroid that is not graphic in Example 4.12.
\begin{definition}
Let $G$ be a graph. The dual of the cycle matroid $\M(G)$ is called the \textit{bond matroid} of a graph and denoted by $\M^\perp(G)$.
\end{definition}
\begin{lemma}
If $G$ is graph, then $e \in G$ is a bridge if and only if $e \in \M(G)$ is a coloop.
\end{lemma}
\begin{proof}
An element $e \in \M(G)$ is a coloop if and only if $\grk(E(G) - e) = \grk(E(G)) - 1$. Now let  $c(G - e)$ be the number of connected components of $G-e$. With Theorem 4.3 and Lemma 3.49 we get
\[
n - c(G - e) = \grk(E(G) - e) = \grk(E(G)) - 1 = n - c(G) - 1 \Longleftrightarrow c(G - e) = c(G) - 1.
\]
Thus, deleting the edge $e$ results in having one more connected component making $e$ a bridge by definition.
\end{proof}
By this lemma, an edge $e \in G$ is a bridge if and only if $e$ is a loop in the bond matroid $\M^\perp(G)$. 
\begin{lemma} 
Let $A \subseteq E(G)$. Then $A$ is independent in $\M^\perp(G)$ if and only if $c(\bar{A}) = c(E(G))$, or equivalently, if $A$ does not contain a set of edges $F$ such that $c(G - F) > c(G)$.
\end{lemma}
\begin{proof}
We can use Theorem 4.3 to receive
\begin{align*}
\grk^\perp(A) = |A| + \grk(\overline{A}) - \grk(E(G)) &= |A| + (n - c(\overline{A})) - (n - c(E(G)))\\
&= |A| - c(\overline{A}) + c(E(G)).
\end{align*}
Hence 
\[
0 = \grk^\perp - |A|  \Longleftrightarrow c(\overline{A}) = c(E(G)).
\]
For the second part of this lemma, assume $c(\overline{A}) = c(E(G))$ holds. This is equivalent to $c(G - A) = c(E(G))$, from which $c(G - F) = c(E(G))$ follows for any subset $F \subseteq A$. Now assume $c(G - F) \leq c(E(G))$, then $c(G - A) \leq c(E(G))$ follows directly, which is equivalent to $c(\overline{A}) \leq c(E(G))$. But $c(\overline{A})$ can not be smaller than $c(E(G))$, thus $c(\overline{A}) = c(E(G))$. 
\end{proof}
\begin{definition}
Let $\M$ be a matroid. We call $\M$ \textit{graphic} if there exists a graph $G$ such that \[
\M \cong \M(G).
\]
\end{definition}
Not all matroids are graphic as the following example shows.
\begin{beispiel}
Consider the uniform matroid $\mathcal{U}^2_4$ of rank $2$ on a $4$-element set. Then 
\begin{align*}
\mathcal{U}^2_4 = \bigg(&\bigg\{1,2,3,4\bigg\}, \\ 
  &\bigg\{\emptyset, \{1\}, \{2\}, \{3\}, \{4\}, \{1,2\}, \{1,3\}, \{1,4\}, \{2,3\}, \{2,4\}, \{2,3\}\bigg\}\bigg),
\end{align*}
hence the dependent sets of $\mathcal{U}^2_4$ are $\{1,2,3\}, \{1,2,4\}, \{2,3,4\}, \{1,2,3,4\}$. In Remark 4.5 we deduced that the circuits of the cycle matroid of some graph are exactly the cycles in the graph. The circuits of $U^2_4$ are its $3$-element dependent sets. Thus if $\mathcal{U}^2_4$ is isomorphic to the cycle matroid $\M(G)$ for some graph $G$, then $G$ has 3 cycles of length 3. Now a graph with $4$ edges can have at most one cycle of length $3$. Thus $\mathcal{U}^2_4$ is not graphic. 
\end{beispiel}
\begin{beispiel} 
We want to continue Example 4.2 and compare the cycle matroid of $G$ in Figure 14 with the cycle matroid of the dual graph $G^*$.
\begin{center}
\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!10, 		thick, inner sep=1pt, minimum size=3.5mm}, baseline=-0.5ex]
	\node at (0,0) [knoten](1) {$v_1$};
	\node at (0,3) [knoten](2) {$v_2$}
		edge[-] node[auto]{$e_5$}(1)
		edge[-, bend left = 90] node[auto] {$e_2$}(1);
	\node at (-2, 1.5)[knoten](3) {$v_3$}
		edge[-] node[auto]{$e_4$}(2)
		edge[-] node[auto, swap]{$e_1$}(1);
\path  (2)   edge[my loop] node[above]  {$e_3$} (2);
	\begin{scope}[knoten/.append style={fill=blue!30,
	thick, inner sep=1pt, minimum size = 3mm, baseline=-0.5ex}]
			\node[knoten] (4) at (-1, 1.5) {$u_1$};
			\node[knoten] (5) at (0.5, 1) {$u_3$};
			\node[knoten] (6) at (0, 3.75) {$u_4$};
			\node[knoten] (7) at (-2.25, 3.25) {$u_2$};
	\end{scope}
	\draw [dashed]
		(4) to [] (5)
		(4) to [] (7)
		(7) to [] (6)
		(4) to [out=250 , in=210, looseness = 2.5 ] (7)
		(5) to [out = 290, in=210, looseness = 3.75] (7);
\end{tikzpicture}
\vspace*{-60pt}
    \captionof{figure}{Graph $G$ with dual graph $G^\star$}
        \label{fig:label}
\end{center}
We assign the graph $G$ the same orientation as in Example 4.2 and assign an arbitrary orientation to $G^\star$. The incidence matrix of $G^*$ and the collection of independent sets of $\M(G^\star)$ are
\begin{center}
$D_{G^*} = 
\begin{blockarray}{cccccc}
& \hat{e}_1 & \hat{e}_2 & \hat{e}_3 & \hat{e}_4 & \hat{e}_5 \\
\begin{block}{c(ccccc)}
u_1 & -1 & \phantom{-}0 & \phantom{-}0 & -1 & \phantom{-}1 \\
u_2 & \phantom{-}1 & -1 & -1 & \phantom{-}1 & \phantom{-}0 \\
u_3 & \phantom{-}0 & \phantom{-}1 & \phantom{-}0 & \phantom{-}0 & -1 \\
u_4 & \phantom{-}0 & \phantom{-}0 & \phantom{-}1 & \phantom{-}0 & \phantom{-}0 \\
\end{block}
\end{blockarray}$ \end{center}
\begin{center}
\begin{align*}
\M(G^*) = \bigg(&\bigg\{\hat{e}_1,\hat{e}_2,\hat{e}_3,\hat{e}_4,\hat{e}_5\bigg\}, \\  \ \ \ 
&\bigg\{\{\hat{e}_1\}, \{\hat{e}_2\}, \{\hat{e}_3\}, \{\hat{e}_4\}, \{\hat{e}_5\}, \\ & \ \ \ \{\hat{e}_5, \hat{e}_4\}, \{\hat{e}_5, \hat{e}_2\}, \{\hat{e}_5, \hat{e}_1\}, \{\hat{e}_4, \hat{e}_2\}, \{\hat{e}_2, \hat{e}_1\}, \{\hat{e}_3, \hat{e}_5\}, \{\hat{e}_3, \hat{e}_4\}, \{\hat{e}_3, \hat{e}_2\}, \\ & \ \ \
 \{\hat{e}_3, \hat{e}_1\}, \{\hat{e}_5, \hat{e}_2, \hat{e}_3\}, \{\hat{e}_5, \hat{e}_1, \hat{e}_3\}, \{\hat{e}_5, \hat{e}_4, \hat{e}_3\}, \{\hat{e}_4, \hat{e}_2, f_3\}, \{\hat{e}_2, \hat{e}_1, \hat{e}_3\}\bigg\}\bigg).
\end{align*}
\end{center}
Now let us have a closer look at the sets of bases $\mathcal{B}_1$, $\mathcal{B}_2$ of $\M(G)$,$\M(G^*)$ respectively: 
\begin{align*}
\mathcal{B}_1 &= \{ \{e_1, e_2\}, \{e_1, e_4\}, \{e_1, e_5\}, \{e_2, e_4\}, \{e_4, e_5\}\} \\
\mathcal{B}_2 &= \{\{\hat{e}_5, \hat{e}_2, \hat{e}_3\}, \{\hat{e}_5, \hat{e}_1, \hat{e}_3\}, \{\hat{e}_5, \hat{e}_4, \hat{e}_3\}, \{\hat{e}_4, \hat{e}_2, f_3\}, \{\hat{e}_2, \hat{e}_1, \hat{e}_3\}\}.
\end{align*}
Together with the incidence matrices, the sets $\mathcal{B}_1$ and $\mathcal{B}_2$ suggest a bijection:
\begin{align*}
\psi: E(G) &\to E(G^*) \\ 
e_i &\mapsto \psi(e_i) = \hat{e}_i \ \ \ \text{for all } \ i \in \{1,2,3,4,5\}.
\end{align*}
With this bijection we see that the bases of $\M(G^*)$ are the complements of the bases of $\M(G)$. This shows that the cycle matroid of $G$ is isomorphic to the cycle matroid of $G^*$ and also suggests that the cycle matroid of $G$ is the bond matroid of $G^*$.
\end{beispiel}
In \cite{Oxl2011}, James Oxley discusses duality of graphic matroids in great detail. He proves that the dual matroids of the cycle matroids for the graphs $K_5$ and $K_{3,3}$ are not graphic. Moreover, he shows that for the geometric dual $G^\star$ of a graph $G$, 
\begin{equation} \label{test23}
\M(G^\star) \cong \M^\perp(G)
\end{equation}
holds. Therefore, the cycle matroid of $G^\star$ is isomorphic to the bond matroid of $G$. However, the most interesting result is that for a graph $G$, $\M^\perp(G)$ is graphic if and only if $G$ is planar. In Chapter 2 we noted the importance of the graphs $K_5$ and $K_{3,3}$ in graph theory. We want to mention a variant of Kuratowski's Theorem, due to Wagner, which states that a graph is planar if and only if it has no minor isomorphic to $K_5$ and $K_{3,3}$. He concludes that a graph $G$ is planar if and only if $\M(G)$ has no minor isomorphic to $\M(K_5)$ or $\M(K_{3,3})$. \\
\indent 
Let $G$ be a planar graph and $G^\star$ a geometric dual. By equation \eqref{test23} and Theorem 3.48 we can conclude 
\[
T(\M(G^\star);x,y) = T(\M(G);y,x).
\]
\subsection{The Tutte Polynomial for Graphs}
In the previous sections, we described thoroughly how we can construct a matroid from a graph. This way, all statements proved in chapter 3 for matroids also hold for the cycle and bond matroids of a graph. Thus we can use Definition 3.44 to define the Tutte polynomial for graphs. We will compute the Tutte polynomials of some graphs, using the subgraph expansion and the deletion-contraction algorithm. At the end of this section, we will define the \textit{one-point join} and the \textit{disjoint union} of graphs and prove that the Tutte polynomial is multiplicative on both constructions.
\begin{definition}
Let $G$ be a graph with $|V| = n$. The \textit{Tutte polynomial} of $G$ is the Tutte polynomial of its cycle matroid $\M(G)$:
\[
T(G;x,y) \coloneqq T(\M(G);x,y) = \sum_{A \subseteq E(G)} (x - 1)^{\grk(E(G)) - \grk(A)} (y - 1)^{n(A)}.
\]
\end{definition}
\begin{beispiel}
Consider the graph in Figure 16. We want to compute its Tutte polynomial, thus we have to look at all subsets of $E(G)$.  
\begin{center}
\begin{tikzpicture}
	[	bend angle=45,
		knoten/.style={circle, draw=black!100, fill=black!20, thick, 
		inner sep=0pt, minimum size=2.5mm}, auto]	
	\node at (0,0) [knoten](1) {};
	\node at (2,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\node at (1,2) [knoten] (3) {}
		edge[-] node[auto]{$b$} (2)
		edge[-] node[auto,swap]{$d$}(1);
	\path  (3)   edge[my loop] node[above]  {$c$} (3);
\end{tikzpicture}
    \captionof{figure}{Graph $G$.}
        \label{fig:label}
\end{center}
\begin{table}[!h]
\begin{minipage}{.5\linewidth}
\scriptsize
\centering
\begin{tabular}{||c c c c||} 
 \hline
 $A$ & $\grk(A)$ & $\grk(E) - \grk(A)$ & $|A| - \grk(A)$ \\ [0.7ex] 
 \hline\hline
 $\emptyset$ & $0$ & $2$ & $0$\\
 $\{a\}$ & $1$ & $1$ & $0$\\ 
 $\{b\}$ & $1$ &$1$ & $0$\\
 $\{c\}$ &$0$ &$2$ &$1$ \\
 $\{d\}$ &$1$ &$1$ &$0$ \\
 $\{a,b\}$ &$2$ &$0$ &$0$ \\
 $\{a,c\}$ &$1$ &$1$ &$1$ \\
 $\{a,d\}$ &$2$ &$0$ &$0$ \\ [1ex] 
 \hline
\end{tabular}
\end{minipage}
\begin{minipage}{.5\linewidth}
\scriptsize
\centering
\begin{tabular}{||c c c c||} 
 \hline
 $A$ & $\grk(A)$ & $\grk(E) - \grk(A)$ & $|A| - \grk(A)$ \\ [0.7ex] 
 \hline\hline
 $\{b,c\}$ &$1$ &$1$ &$1$ \\
 $\{b,d\}$ &$2$ &$0$ &$0$ \\
 $\{c,d\}$ &$1$ &$1$ &$1$ \\
 $\{a,b,c\}$ &$2$ &$0$ &$1$ \\
$\{a,b,d\}$ &$2$ &$0$ &$1$ \\
$\{a,c,d\}$ &$2$ &$0$ &$1$ \\
$\{b,c,d\}$&$2$ &$0$ &$1$ \\
$\{a,b,c,d\}$ &$2$ &$0$ &$2$\\ [1ex] 
 \hline
\end{tabular}
\end{minipage}
\caption{all subgraphs of $G$ in Example 4.15 with their corresponding rank and nullity functions}
\label{table:1}
\end{table}
We can get all information from table 1 and get, 
\[
T(G;x,y) = \sum_{A \subseteq E(G)} (x - 1)^{\grk(E(G)) - \grk(A)}(y - 1)^{|A| - \grk(A)} = x^2y + xy + y^2.
\]
\end{beispiel} 
The last example showed how impractical it can be to compute the Tutte polynomial according to Definition 4.14. However, Theorem 3.50 also holds for the cycle matroids of graphs.
\begin{theorem}
Let $G$ be a graph. Then the Tutte polynomial for the cycle matroid $\M(G)$ satisfies the following deletion-contraction relations
\[
T(G; x,y) = \begin{cases}
x T(G/e;x,y), & \text{if} \ e \ \textit{is a bridge}; \\
y T(G - e;x,y), & \text{if} \ e \ \textit{is a loop}; \\
T(G - e;x,y) + T(G / e; x,y), & \text{if} \ e \ \textit{is ordinary}; \\ 
1, & \text{if} \ E(G) = \emptyset. 
\end{cases}
\]
\end{theorem}
\begin{proof}
By Theorem 4.7, we have $\M(G)/e = \M(G/e)$ and $\M(G) - e = \M(G - e)$. The theorem then follows directly from Theorem 3.50.
\end{proof}
\begin{beispiel} Now we can compute the Tutte polynomial of the graph in Example 4.15 in a more efficient way: 
\begin{align*}
T\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\node at (0.5,1) [knoten] (3) {}
		edge[-] node[auto]{$b$} (2)
		edge[-] node[auto,swap]{$d$}(1);
	\path  (3)   edge[my loop] node[above]  {$c$} (3);
	\\};
\end{tikzpicture} &= y \cdot \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\node at (0.5,1) [knoten] (3) {}
		edge[-] node[auto]{$b$} (2)
		edge[-] node[auto,swap]{$d$}(1); 
	\\};
\end{tikzpicture} \\ 
&= y \cdot \left( T \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\node at (0.5,1) [knoten] (3) {}
		edge[-] node[auto]{$b$} (2);
	\\};
\end{tikzpicture} + T \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1)
		edge[-, bend right = 45] node[auto,swap]{$b$} (1);
	\\};
\end{tikzpicture}\right) \\
&= y \cdot \left( x \cdot T\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\\};
\end{tikzpicture} + \left( \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
	\node at (1,0) [knoten](2) {}
		edge[-] node[auto]{$a$}(1);
	\\};
\end{tikzpicture} + \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!20, 		thick, inner sep=0pt, minimum size=2.5mm}, baseline=-0.5ex]
\matrix[left delimiter=(, right delimiter=)] {
	\node at (0,0) [knoten](1) {};
\path  (1)   edge[my loop] node[above]  {$a$} (1);
	\\};
\end{tikzpicture}\right)\right) \\ 
&= y \cdot (x \cdot x + (x + y)) \\ 
&= x^2y + y^2 + xy.
\end{align*}
\end{beispiel}
\begin{definition}
A \textit{one-point join} of two disjoint graphs $G$ and $H$, denoted by $G \star_{u,v} H$, is formed by identifying a vertex $u$ of $G$ and a vertex $v$ of $H$ into a single vertex $w$ of $G \star H$. The edge set and incidence relations of $G \star_{u,v} H$ are induced from those of $G$ and $H$. 
\end{definition}
One can think of the one-point join of two graphs as glueing the graphs together at a selected vertex. If we are not interested in the chosen vertices for the one-point join, we simply write $G \star H$.
\begin{lemma} 
If $G$ and $H$ are graphs, then 
\[
T(G \sqcup H;x,y) = T(G;x,y) \cdot T(H;x,y),
\]
and 
\[
T(G \star H;x,y) = T(G;x,y) \cdot T(H;x,y).
\]
\end{lemma}
\begin{proof}
We call $G$ and $H$ the blocks of $G \sqcup H$ and $G \star H$. Given any edge $e \in G \sqcup H$, both of its end-vertices lie in the same block. The same holds for $G \star H$. Therefore we can prove both statements at once, since the only information we will use, is in which block both endvertices of some edge $e$ are contained. We can generalize our two graph constructions and write $G \cup H$ for $G \sqcup H$ and for $G \star H$. We will induct on the number of edges $|E(G \sqcup H)| = k = |E(G \star H)|$.  By the construction of the disjoint union and one point join, it is clear that for an edge $e \in G$, we have 
\begin{center}
$(G \cup H) - e = (G  - e) \cup H$ and $(G \cup H) / e = (G / e) \cup H$.
\end{center}
Let $k = 1$, and suppose without loss of generality that $e \in G$. Since $e$ is the only edge, it is either a loop or bridge of $G$, hence it is either a loop or coloop of $G \cup H$. If $e$ is a loop, then $G - e \cup H$ is empty. We can use Theorem 4.7 and Theorem 4.16 and get 
\begin{align*}
T(\M(G \cup H);x,y) &= y \cdot T(\M(G \cup H)- e;x,y) \\ &= y \cdot T(\M(G - e \cup H);x,y) = y \cdot 1 = T(\M(G);x,y) \cdot T(\M(H);x,y).
\end{align*}
On the other hand, if $e$ is a bridge, Theorem 4.7 and 4.16 yield
\begin{align*}
T(\M(G \cup H);x,y) &= x \cdot T(\M(G \cup H)/e;x,y) \\ &= x \cdot T(\M(G/ e \cup H);x,y) = x \cdot 1 = T(\M(G);x,y) \cdot T(\M(H);x,y).
\end{align*}
Now suppose the statement is true for $k = m$ and let $k = 
m + 1$. Deleting or contracting any edge $e$ only decreases the number of edges. Without loss of generality, suppose both end-vertices of $e$ lie in the block of $G$. Firstly, if $e$ is a loop, then with Theorem 4.16 and Theorem 4.7 we have
\[
T(\M(G \cup H);x,y) = y \cdot T(\M(G \cup H)-e;x,y) = y \cdot T(\M(G - e \cup H);x,y).
\]
Then by the induction hypothesis and Theorem 4.16 we know
\[
T(\M(G \cup H);x,y) = y \cdot T(\M(G -e);x,y) T(\M(H);x,y) = T(\M(G);x,y)T(\M(H);x,y).
\]
Similarly, if $e$ is a bridge, Theorem 4.16 and Theorem 4.7 show that
\[
T(\M(G \cup H);x,y) = x \cdot T(\M(G \cup H)/e;x,y) = x \cdot T(\M(G/e \cup H);x,y).
\]
Again, by the induction hypothesis and Theorem 4.16 this results in
\[
T(\M(G \cup H);x,y) = x \cdot T(\M(G/e);x,y)T(\M(H);x,y) = T(\M(G);x,y)T(\M(H);x,y).
\]
Let $e \in G \cup H$ be an edge that is ordinary. Then by Theorem 4.16 it follows that
\begin{equation}\label{test21}
T(\M(G \cup H);x,y) = T(\M(G \cup H) - e;x,y) + T(\M(G \cup H)/e;x,y).
\end{equation}
With Theorem 4.7 we can continue equation \eqref{test21}, so that 
\begin{equation} \label{test22}
T(\M(G \cup H);x,y) = T(\M(G - e \cup H);x,y) + T(\M(G/e \cup H);x,y) 
\end{equation}
Now we can use the induction hypothesis, such that the right hand side of equation \eqref{test22} equals 
\begin{equation}
T(\M(G - e);x,y) \cdot T(\M(H);x,y) + T(\M(G/e);x,y) \cdot T(\M(H);x,y).
\end{equation}
Hence, 
\[
T(\M(G \cup H);x,y) = T(\M(H);x,y) \cdot \left[T(\M(G - e;x,y) + T(\M(G/e);x,y)\right]
,
\]
where we can use Theorem 4.16 a second time to receive 
\[
T(\M(G \cup H);x,y) = T(\M(G);x,y) T(\M(H);x,y). \qedhere
\] 
\end{proof}
\subsection{The Tutte Polynomial as a Graph Invariant}
The chromatic polynomial, the flow polynomial and the reliability polynomial are graph polynomials that satisfy a deletion-contraction recurrence as shown in Chapter 2. We would like to present these invariants as specializations of the of the Tutte polynomial, using the recipe theorem from Section 3.5. Unfortunately, when translating a graph into its cycle matroid, we lose information about possible isolated vertices. Moreover, the direct sum of two cycle matroids is isomorphic to the cycle matroid of the disjoint union and the one-point join of the underlying graphs, which are in general not the same graphs. But the chromatic polynomial, for example, is not multiplicative on one-point joins. Consequently, we need to reformulate the recipe theorem, which is the main result of this chapter and also one of the most important results of this thesis. With the modified recipe theorem we will be able to show that the graph polynomials considered in Chapter 2 are specializations of the Tutte polynomial. 
\begin{definition}
Let $\mathcal{G}$ be a minor-closed class of graphs, $\mathfrak{R}$ be a commutative ring with unity and $a,b \in \mathfrak{R}$. A graph invariant $f : \mathcal{G} \to \mathfrak{R}$ is a \textit{Tutte-Grothendieck invariant}, or T-G-\textit{invariant}, if 
\begin{align*}
f(G) &= a f(G - e) + b f(G / e) \ \text{if } \ e \ \text{is ordinary}, \\ 
f(\bullet) &= 1, \\
f(G \sqcup H) &= f(G) \cdot f(H), \\
f(G \star H) &= f(G) \cdot f(H).
\end{align*}
\end{definition}
\begin{remark}
The last three conditions replace the second condition for a T-G-invariant for matroids, from which we deduced that $f(\M) = 1$ for an empty matroid. The independent sets of the direct sum of two matroids $\M_1$ and $\M_2$ were defined as the union of two independent sets $I_1$, $I_2$ from $\M_1$ and $\M_2$ respectively. Recall that the independent sets in the cycle matroid of a graph are its acyclic forests. Since we lose some information about the vertices if we translate a graph into its cycle matroid, the forests in $G \sqcup H$ are exactly the forests in $G \star H$, explaining the last two conditions.
\end{remark}
\begin{theorem}
Let $\mathcal{G}$ be a minor-closed class of graphs, let $\mathfrak{R}$ be a commutative ring with unity and let $f: \mathcal{G} \to \mathfrak{R}$. If there exists $a,b \in \mathfrak{R}$ such that $f$ is a Tutte-Grothendieck invariant, then 
\[
f(G) = a^{|E(G)| - \grk(E(G))} b^{\grk(E(G))}T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right),
\]
where $f\big( \ $\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
\node at (0,0)[knoten](1){};
\node at (1,0)[knoten] (2){}; 
\draw (1) -- (2);
\end{tikzpicture} $\big) = x_0$ and $f\big( $     
\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
		\node at (0,0)[knoten](1){};
        \node (B) at (0.2,0) [circle,draw] {};
\end{tikzpicture}$ \ \big) = y_0$.
\end{theorem}
\begin{proof}
We will proceed similarly to the proof of the recipe theorem for matroids and induct on the number of edges. Let $G$ be a graph with no edges and $V(G) = n$. Since $f$ is a Tutte-Grothendieck invariant and the Tutte polynomial equals $1$ on the empty graph, we get 
\begin{align*}
f(G) = f( \bullet \sqcup \bullet \sqcup \dots \sqcup \bullet) &= f(\bullet) \cdot f(\bullet) \cdot ... \cdot f(\bullet) \\ &=  f(\bullet)^n = 1 = a^0 \cdot b^0 \cdot 1 = a^0 \cdot b^0 T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right).
\end{align*}
Now let $G$ be a graph with $|E(G)| = m + 1$ and suppose the statement holds for all graphs with $m$ edges. If $e \in E(G)$ is a loop, then 
\[
f(G) = f\big( \begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
		\node at (0,0)[knoten](1){};
        \node (B) at (0.2,0) [circle,draw] {};
\end{tikzpicture} \star G / e\big) 
= f\big(\begin{tikzpicture}
[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
		\node at (0,0)[knoten](1){};
        \node (B) at (0.2,0) [circle,draw] {};
\end{tikzpicture}\big) \star f(G/e).
\]
Here we can use the induction hypothesis, since $G/e$ is a graph on $m$ edges, to get 
\begin{equation}\label{test24}
f(G) = y_0 \cdot a^{|E(G) - e| - \grk_{\M(G/e)}(E(G) - e)} b^{\grk_{\M(G / e)}(E(G) - e)}T\left(\M(G / e); \frac{x_0}{b}, \frac{y_0}{a}\right).
\end{equation}
With $\M(G/e) = \M(G) / e$ and by Theorem 4.7, Lemma 3.49 and equation \eqref{test24} is equal to 
\[
\frac{y_0}{a}f(G) = y_0 \cdot a^{|E(G)| - 1- \grk(E(G))}b^{\grk(E(G))}T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right), 
\]
hence,
\[
f(G) = a^{|E(G)| - \grk(E(G))}b^{\grk(E(G))}T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right).
\]
The case for $e = (u,v)$ being a bridge is similar. We use that $G$ is a one point join of the graphs $G_1$,$G_2$ and $e$, where $G_1$ is the connected component of $G - e$ that contains the vertex $u$ and $G_2$ is a disjoint union of all connected components of $G - e$ that do not contain $u$. 
With this construction we can use the properties of a Tutte-Grothendieck invariant and get
\begin{align*}
f(G) = f((G_1 \star \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
\node at (0,0)[knoten](1){};
\node at (0.5,0)[knoten] (2){}; 
\draw (1) -- (2);
\end{tikzpicture})  \star G_2) &= f(G_1) f(G_2) f(\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
\node at (0,0)[knoten](1){};
\node at (0.5,0)[knoten] (2){}; 
\draw (1) -- (2);
\end{tikzpicture})\\ &= f(G_1 \sqcup G_2) f(\begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
\node at (0,0)[knoten](1){};
\node at (0.5,0)[knoten] (2){}; 
\draw (1) -- (2);
\end{tikzpicture}) = f(G - e) f( \begin{tikzpicture}
	[knoten/.style={circle, draw=black!100, fill=black!100, thick, 
				inner sep=0pt, minimum size=1.75mm}]
\node at (0,0)[knoten](1){};
\node at (0.5,0)[knoten] (2){}; 
\draw (1) -- (2);
\end{tikzpicture}).
\end{align*}
Then with the induction hypothesis we get
\[
f(G) = x_0 \cdot a^{|E(G) - e| - \grk_{\M(G - e)}(E(G) - e)}b^{\grk_{\M(G-e)}(E(G)-e)}T\left(\M(G - e); \frac{x_0}{b}, \frac{y_0}{a}\right).
\]
Here we use Theorem 4.7 and $\M(G)- e = \M(G - e)$ to obtain
\[
\frac{x_0}{b} f(G) = x_0 \cdot a^{|E(G)|- 1 - (\grk(E(G)) -1)}b^{\grk(E(G)) - 1}T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right).
\]
Concluding,
\[
f(G) = a^{|E(G)| - \grk(E(G))}b^{\grk(E(G))}T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right).
\]
Finally, let $e \in E(G)$ be an ordinary edge. Then 
\[
f(G) = a f(G - e) + b f(G / e),
\]
and by the induction hypothesis 
\begin{equation}\label{test25}
a f(G - e) = a \cdot a^{|E(G)| - 1 - \grk_{\M(G - e)}(E(G) - e)}b^{\grk_{\M(G - e)}(E(G) - e)}T\left(\M(G - e); \frac{x_0}{b}, \frac{y_0}{a}\right)
\end{equation}
and
\begin{equation}\label{test26}
b f(G / e) = b \cdot a^{|E(G)| - 1 - \grk_{\M(G/ e)}(E(G) - e)}b^{\grk_{\M(G / e)}(E(G) - e)} T\left(\M(G / e); \frac{x_0}{b}, \frac{y_0}{a}\right).
\end{equation}
By Lemma 3.49 and equations \eqref{test25} and \eqref{test26} we know
\[
a f(G - e) = a^{|E(G)| - \grk(E(G))}b^{\grk(E(G))}T\left(\M(G - e); \frac{x_0}{b}, \frac{y_0}{a}\right)
\]
and
\[
b f(G / e) = a^{E(G)- 1 - (\grk(E(G)) - 1)}b^{\grk(E(G)) - 1 + 1} T\left(\M(G/e); \frac{x_0}{b}, \frac{y_0}{a}\right).
\]
From this we obtain 
\[
f(G) = a^{|E(G)| - \grk(E(G))}b^{\grk(E(G))}\left(T\left(\M(G - e); \frac{x_0}{b}, \frac{y_0}{a}\right) + T\left(\M(G / e); \frac{x_0}{b}, \frac{y_0}{a}\right)\right)
\]
and by Theorem 4.7 we conclude 
\[
f(G) = a^{|E(G)| - \grk(E(G))}b^{\grk(E(G))} T\left(\M(G); \frac{x_0}{b}, \frac{y_0}{a}\right). \qedhere
\]
\end{proof}
\begin{lemma}Let $G$ be a graph. Then
\begin{itemize}
\item[a)]$T(\M(G);1,1)$ is the number of spanning trees in $G$ if it is connected.
\item[b)]$T(\M(G);2,1)$ is the number of forests in $G$.
\end{itemize}
\end{lemma}
\begin{proof}
First note that the bases of the cycle matroid of some graph $G$ are the maximal spanning forests by Remark 4.5. If $G$ is connected, the bases are the maximal spanning trees. Also, Lemma 3.58 showed that $T(\M(G);1,1)$ is exactly the number of bases of $\M(G)$. \\
\indent Furthermore, Remark 4.5 also noted that the independent sets of a cycle matroid are exactly the forests of the underlying graph. Hence, with Lemma 3.58 $T(G;2,1)$ is exactly the number of forests in $G$.
\end{proof}
\begin{remark}
Note that the chromatic polynomial is not a Tutte-Grothendieck invariant, as $P(\bullet,\lambda) = \lambda$ for each $\lambda$. Secondly consider the graph $G$ consisting of two vertices and an edge connecting these. Then by the combinatorial rule of sum
\[
P(G \sqcup H, \lambda) = \lambda( \lambda - 1) + \lambda(\lambda - 1) = 2 \lambda(\lambda - 1) \neq \lambda^2(\lambda - 1)^2 = P(G, \lambda)P(H, \lambda).
\]
Finally, the chromatic polynomial of a one-point join depends on the specific vertex at which the two graphs are joined. Consider the graph $G_1$ consisting of vertices $v_1, v_2, v_3$ with edge set $E(G_1) = \{(v_1,v_2)\}$ and the graph $G_2$ being the induced subgraph of $G_1$ on $V(G_2) = \{v_1, v_2\} \subset V(G_1)$. Then joining $G_1$ and $G_2$ at vertex $v_3$ and any vertex of $G_2$ results in the chromatic polynomial 
\[
P(G_1 \star_1 G_2, \lambda) = \lambda(\lambda - 1) + \lambda(\lambda - 1) = 2\lambda (\lambda - 1)= 2 \lambda^2 - 2\lambda.
\]
However, the join at vertex $v_1$ of $G_1$ and any vertex of $G_2$ results in the chromatic polynomial
\[
P(G_1 \star_2 G_2, \lambda) = \lambda + \lambda(\lambda - 1)^2 = \lambda ^3 -2\lambda^2 + 2\lambda.
\]
\end{remark}
Unfortunately, the last remark shows that we can not use the recipe theorem for graph invariants directly for the chromatic polynomial. But the next theorem proves that there is a unique universal polynomial, which is computed through a deletion-contraction recursion, and that this universal polynomial is an specialization of the Tutte polynomial. 
\begin{theorem}
Let $\mathcal{G}$ be a minor-closed class of graphs. Then there is a unique map $U : \mathcal{G} \to \mathbb{Z}[x,y,a,b,\alpha]$ such that 
\[
U(G) = \begin{cases}
x \ U(G - e), & \text{if} \ e \ \text{is a bridge}; \\
y \ U(G - e), & \text{if} \ e \ \text{is a loop}; \\
a \ U(G - e) + b \ U(G / e), & \text{if} \ e \ \text{is ordinary}; \\
\alpha^n, & \text{if} \ E(G) = \emptyset \ \text{and} \ V(G) = n.
\end{cases}
\]
Moreover 
\begin{equation} \label{(8)}
U(G) = \alpha^{c(G)} a^{n(G)} b^{\rk(G)} T\left(G; \frac{\alpha x}{b}, \frac{y}{a}\right).
\end{equation}
\end{theorem}
\begin{proof}
The uniqueness follows immediately from $U(G)$ being determined by $U(G - e)$ and $U(G /e)$ for an edge $e \in E(G)$. Hence we only need to prove that the function $U$ given by \eqref{(8)} has the required properties. Let $G$ be an arbitrary graph and denote by $\mathrm{deg}_x(T)$ and $\mathrm{deg}_y(T)$ the degree of $x$, $y$ respectively in $T(\M(G); x,y)$. Then $U(G) \in \mathbb{Z}[x,y,a,b, \alpha]$ since
\begin{align*}
\mathrm{deg}_x(T) &= \max\{ \grk(G) - \grk(A): A \subseteq E(G)\} = \grk(G) \\ 
\mathrm{deg}_y(T) &= \max\{\n(A): A \subseteq E(G)\} = \n(G).
\end{align*}
If $G$ is an empty graph on $n$ vertices, then $c(G) = n$ and $\rk(G) = \n(G) = 0$, hence 
\[
U(G) = \alpha^n T\left(\M(G);\frac{\alpha x }{b}, \frac{y}{a}\right) = \alpha^n. 
\]
Lastly, we need to show, that $U(G)$ as in \eqref{(8)} satisfies the reduction formulae. Let $e \in E(G)$ be a bridge. then with Theorem 4.7 $\M(G - e) = \M(G / e)$ holds and with Theorem 4.16 we obtain
\begin{equation}
U(G) = \alpha^{c(G)} a^{\n(G)}b^{\grk(G)} \frac{\alpha x}{b} T\left(\M(G / e);\frac{\alpha x}{b}, \frac{y}{a}\right).
\end{equation}
From Lemma 3.49 we know $c(G - e) = c(G) + 1$, $\n(G - e) = \n(G)$ and $\rk(G - e) = \rk(G) - 1$, so that 
\[
U(G) = x \cdot \alpha^{c(G - e)} a^{\n(G - e)}b^{\grk(G - e)} T(\M(G -e);\frac{\alpha x}{b}, \frac{y}{a}), 
\]
from which we obtain 
\[
U(G) = x \cdot U(G - e).
\]
Now let $e \in E(G)$ be a loop. Similarly to the first case, we use Theorem 4.16 to obtain
\[
U(G) = \alpha^{c(G)} a^{\n(G)}b^{\grk(G)} \frac{y}{a} T\left(\M(G - e);\frac{\alpha x}{b}, \frac{y}{a}\right).
\]
With $c(G) = c(G - e), \n(G - e) = \n(G) - 1$ and $\grk(G - e) = \grk(G)$ it follows that
\[
U(G) = \alpha^{c(G - e)}a^{\n(G - e)} b^{\grk(G - e)}y  T\left(\M(G - e);\frac{\alpha x}{b}, \frac{y}{a}\right)
= y U(G - e).
\]
Lastly, if $e \in E(G)$ is an ordinary edge, then by Theorem 4.16 we know
\begin{equation} \label{test30}
U(G) = \alpha^{c(G)} a^{\n(G)}b^{\grk(G)} \left(T(\M(G -e); \frac{\alpha x}{b}, \frac{y}{a}) + T(\M(G /e); \frac{\alpha x}{b}, \frac{y}{a})\right). 
\end{equation}
Since $e$ is ordinary, $c(G - e) = c(G / e) = c(G), \n(G - e) = \n(G) - 1$, $\n(G / e) = \n(G)$, $\grk(G - e) = \grk(G)$ and $\grk(G/ e) = \grk(G) - 1$, so that \eqref{test30} equals
\[
\alpha^{c(G - e)}a^{\n(G - e) + 1}b^{\grk(G - e)} T(\M(G - e); \frac{\alpha x}{b}, \frac{y}{a}) + \alpha^{c(G/ e)}a^{\n(G / e)}b^{\grk(G / e) + 1} T(\M(G / e); \frac{\alpha x}{b}, \frac{y}{a}).
\]
Together we obtain, 
\[
U(G) = a \cdot U(G - e) + b \cdot U(G / e). \qedhere
\]
\end{proof}
This result helps us prove that the Tutte polynomial specializes to the polynomials introduced in Chapter 2.
\begin{theorem}
The chromatic polynomial of a graph $G$ is a specialization of the Tutte polynomial:
\[
P(G;\lambda) = (-1)^{\grk(G)}\lambda^{c(G)}T(G; 1 - \lambda, 0).
\]
\end{theorem}
\begin{proof}
The deletion-contraction formula for the chromatic polynomial proved in Theorem 2.37 satisfies the conditions of Theorem 4.25, with $\alpha = \lambda$, $a = 1$, $b = -1, y = 0$ and $x = \frac{\lambda - 1}{\lambda}$. Hence,
\[
P(G, \lambda) = U\left(G; \frac{\lambda - 1}{\lambda}, 0, \lambda, 1, -1\right) = \lambda^{c(G)}(-1)^{\rk(G)} T(G;1 - \lambda, 0),
\]
as claimed. 
\end{proof}
\begin{theorem}
The flow polynomial of an oriented graph $G^\omega$ is a specialization of the Tutte polynomial: 
\[
F(G^\omega;k) = (-1)^{\n(G)}T(G; 0, 1 - k).
\]
\end{theorem}
\begin{proof} The flow polynomial $F(G^\omega; k)$ satisfies the conditions in Theorem 4.25. From the deletion-contraction formula in Theorem 2.45 we get $x = 0$, $y = k - 1$, $a = -1$, $b = 1$ and $\alpha = 1$. Thus,
\begin{align*}
F(G^\omega; k) = U(G;0, k - 1, -1, 1, 1) &= 1^{c(G)}(-1)^{\n(G)}1^{\grk(G)} T\left(G; 0, \frac{k - 1}{-1}\right) \\ &= (-1)^{\n(G)}T(G;0, 1 - k). \qedhere
\end{align*}
\end{proof}
\begin{theorem}
The Reliability Polynomial of a graph $G$ is a specialization of the Tutte polynomial: 
\[
C(G;p) = (1 - p)^{\n(G)}p^{\grk(G)}T(\M(G); 1,\frac{1}{1-p}).
\]
\end{theorem}
\begin{proof}
From the deletion-contraction formula of the reliability polynomial in Theorem 2.50 we see that $C(G;p)$ satisfies the conditions of Theorem 4.25 with $a = (1-p)$, $b = p$, $x = p$, $y = 1$ and $\alpha = 1$. Thus, 
\[
C(G;p) = U(G;p,1,(1-p),p,1) = 1^{c(G)}(1-p)^{\n(G)}p^{\grk(G)}T\left(G; 1, \frac{1}{(1-p)}\right).\qedhere
\]
\end{proof}
\newpage
\section{Complexity and Applications}
In the last chapters we discussed the Tutte polynomial and its properties in great detail. We now want to focus on applications of the Tutte polynomial and its exact complexity. This chapter is only going to scratch the surface of each topic. For a more detailed anylsis refer to \cite{ElMo2022} and \cite{GoRo2001}.
\subsection{Computational Complexity of the Tutte Polynomial}
The Tutte polynomial, being an isomorphism invariant, is an important tool to identify and extract information from a graph or matroid. Oftentimes we face the task of computing  or evaluating the Tutte polynomial for a family of graphs or matroids. Detailed techniques can be found in Chapter 7 of \cite{ElMo2022}. When evaluating the Tutte polynomial, we are usually concerned with computing the exact value of $T(G;a,b)$ where the input is a graph $G$ and two numbers $a,b \in \mathbb{C}$. If we can evaluate efficiently, we can then use interpolation to compute the coefficients of the polynomial. \\ 
\indent Dominic Welsh \cite{Wel1993} gives a nice short introduction into the basics of complexity theory.
\begin{itemize}
\item[]A \textit{decision problem} is a computational problem for which the answer is either "yes" or "no". An example of a decision problem is: For a given $\lambda$, does a given graph $G$ have a proper $\lambda$-coloring?
\item[]A computational problem for which the answer is the number of satisfying configurations is called a \textit{counting problem}. An example of a counting problem is: For a given $\lambda$, how many proper $\lambda$-colorings does a given graph $G$ have?
\end{itemize} We denote the set of decision problems, respectively counting problems, which can be solved in time polynomial in the size of the input by P, respectively FP. This means that the computation time is bounded by a polynomial which has the input parameters as variables. We consider the problems in P or FP to be efficiently computable.
\begin{itemize}
\item[]The set of decision problems for which we can verify whether a given configuration is correct in polynomial time in the size of the input will be denoted by \textit{NP}. 
\item[]The set of counting problems which count configurations whose correctness can be verified in polynomial time will be denoted by $\#$\textit{P}.
\end{itemize}
 The problem of deciding whether a given graph $G$ has a proper $\lambda$-coloring is in NP and computing the number of proper $\lambda$-colorings is $\#$P. Whether 
 \begin{center}
P $\overset{?}{=}$ NP and FP $\overset{?}{=}$ $\#$P
\end{center} are famous and difficult open problems.
\begin{itemize}
\item[]
A problem is called \textit{NP-hard}, $\mathit{\#}$\textit{P-hard} respectively,
if in terms of asymptotic runtime it is at least as hard as the hardest problems in NP, $\#$P respectively.
\item[]A problem that is NP and NP-hard is called \textit{NP-complete}. 
\item[]A problem that is $\#$P and $\#$P-hard is called $\mathit{\#}$\textit{P-complete.}
\end{itemize}
These problems are not considered effectively computable, unless NP $=$ P, FP $=$ $\#$P respectively. \\
\indent F. Jaeger, D. Vertigan and D. Welsh began the study of the complexity of the Tutte polynomial in their paper \cite{JaVeWe1990}. Their main result is the following dichotomy theorem. For a graph $G$, let $H_1$ be the hyperbola \[
H_1 \coloneqq \{(x,y) \in \mathbb{C}^2 : (x - 1)(y - 1) = 1\}
\]
and let $H$ be the union of $H_1$ with 
\[
\{(1,1) , (-1,-1), (0,-1), (-1,0), (i, -i), (-i,i), (j,j^2), (j^2,j)\},
\]
where $j = e^{2\pi i / 3}.$ Then, for every $(a,b) \in \mathbb{C}^2$ they showed:
\begin{itemize}
\item[(1)] if $(a,b) \not \in H$, then $T(G;a,b)$ is $\#$P-hard; 
\item[(2)] if $(a,b) \in H$, then $T(G;a,b)$ is computable in polynomial time.
\end{itemize} 
D. Vertigan and D. Welsh \cite{VW1992} studied the complexity of evaluating the Tutte polynomial of graphs that are both bipartite and planar. Consider the hyperbola 
\[
H_2 \coloneqq \{(x,y) \in \mathbb{C}^2: (x-1)(y-1) = 2\},
\]
and let $H_{bp}$ be the union of $\{(1,1), (-1,-1), (j^2,j), (j,j^2)\}, H_1$ and $H_2$. For every $(a,b) \in \mathbb{C}^2$, 
\begin{itemize}
\item[(1)] if $(a,b) \not \in H_{bp}$, then $T(G;a,b)$ is $\#$P-hard for bipartite planar graphs; 
\item[(2)] if $(a,b) \in H_{bp}$, then $T(G;a,b)$ is computabe in polynomial-time for bipartite planar graphs.
\end{itemize}
However, we can introduce structural graph parameters, called \textit{tree-width} and \textit{clique-width}, such that the Tutte polynomial is efficiently computable on graphs of bounded tree-width or clique-width. Steven Noble proved in \cite{No1998} that $T(G;x,y)$ can be evaluated in $\mathit{O}(|V|)$ for graps with bounded tree-width. For the case of bounded clique-width, in \cite{Hl2006} was proven that $T(G;x,y)$ can be computed in time $\exp(\mathit{O}(|V|^{1 - \frac{1}{k + 2}}))$ on graphs with a clique-width of at most $k$. %For the matroid case, P. Jensen and B. Korte showed in \textcolor{green}{Quelle} that the Tutte polynomial of a matroid $\M$ is not computable in polynomial time. However, one can define a structural parameter called \textit{branch-width}. For the class of representable matroids, for futher discussions on this see \cite{ElMo2022}, Petr \textcolor{red}{Nachname} discusses an algorithm computing the Tutte polynomial of bounded branch-width in polynomial time with a fixed exponent.
\subsection{Applications of the Tutte Polynomial}
Despite its computational hardness, the Tutte polynomial has many applications in various scientific fields, such as topological knot theory, coding theory and statistical mechanics. We will focus on the first two. The results for the latter one and many more applications can be found in \cite{ElMo2022}.
\subsubsection{Knot Theory}
Consider piecewise-linear closed curves in $\mathbb{R}^3$, called \textit{knots}. A knot is usually defined with some orientation. A collection of pairwise disjoint knots is called a \textit{link}. We call a link \textit{alternating} if, following the orientation on the strand, it alternates in over- and undercrossings. Two links are called \textit{equivalent} if they can be deformed into the other by moving it around without passing one strand through another. A formal definition of equivalence uses isotopy and Reidemeister moves and can be found in Chapter 16 of \cite{GoRo2001}. The fundamental problem in topological knot theory is to determine whether two knots are equivalent. If two knots are equivalent, we can find a sequence of isotopies and Reidemeister moves to deform one knot into the other. \\
\indent For many knots it is very hard to find such a sequence. In fact, deciding whether a diagram of a knot can be detangled to the knot without crossings with a given number of moves, as part of the input, is known to be NP-complete. Therefore, the main approach to this problem is to develop knot invariants. As in graph theory, if such an invariant takes different values on different knots, then they can not be equivalent. The main tools are topological, such as fundamental groups or homology. In 1984 Vaughan Jones \cite{Jo1985} discovered the Jones polynomial, another topological tool, which was used to answer a number of open questions about knots. \\
\indent However, we do not need topological notions to discuss knots, as it is very easy to view links as purely combinatorial objects. We consider link diagrams, which are projections of links into $\mathbb{R}^2$. One can think of the projections of a link as the shadow it casts on the plane. It is possible to look at the projections as a plane graph, in which every vertex is incident to exactly four edges, possible multiple edges are counted twice. The graph must contain information about the over- and under-crossings of the link. Therefore each edge will be assigned either a "$+$"-sign or "$-$"-sign, depending on the orientation at each under- and overcrossing. Hence we can think of a signed graph. Now Béla Bollobás \cite{Bol1998} states that the Jones polynomial of an alternating oriented link is just a specialization of the Tutte polynomial. More information about the connection between knot theory and graph theory can be found in \cite{GoRo2001}. Colin Adams \cite{Co1994} gives a figurative approach to knot theory and also discusses how we can model DNA using knot theory.
\subsubsection{Coding Theory} Another application of the Tutte polynomial can be found in coding theory. Let $\mathbb{F}_q$ be the finite field with $q$ elements, where $q$ is a prime power. Set $E \coloneqq \{1, \dots, n\}$ for some positive integer $n$. Let $\mathbb{F}_q^n \coloneqq \mathbb{F}_q^E$ be the vector space of ordered $n$-tuples of elements from $\mathbb{F}_q$ indexed by $E$. A \textit{linear code} $C$ over $\mathbb{F}_q$ is a vector space over $\mathbb{F}_q$. More specifically, an $[n,k]$ linear code $C$ over $\mathbb{F}_q$ is a $k$-dimensional subspace of the vector space $\mathbb{F}_q^n$. We call each vector in $C$ a \textit{codeword}. The \textit{support} and \textit{weight} of a codeword $x = (x_1, \dots, x_n) \in \mathbb{F}_q^n$ is given by 
\begin{align*}
\mathrm{supp}(x) &\coloneqq \{i : x_i \neq 0\}\ \text{and} \\ 
\mathrm{wt}(x) &\coloneqq |\mathrm{supp}(x)|. 
\end{align*}
Similarly, the \textit{support} and \textit{weight} of each subset $B \subseteq \mathbb{F}_q^n$ are defined
\begin{align*}
\mathrm{supp}(B) &\coloneqq \bigcup_{x \in B} \mathrm{supp}(x) \ \text{and}\\
\mathrm{wt}(B) &\coloneqq |\mathrm{supp}(B)|.
\end{align*}
The \textit{weight enumerator} $W_{C}(x,y)$ of an $[n,k]$ linear code $C$ over $\mathbb{F}_q$ enumerates the number of codewords of each given weight as follows: 
\[
W_C(x,y)\coloneqq \sum_{i = 0}^n A_i x^{n - i} y^i,
\]
where $A_i = |\{v \in C : \mathrm{wt}(v) = i\}|$. \\
\indent The \textit{vector matroid} $\M_C$ of a $[n,k]$ linear code $C$ with coordinates $E$ is the matroid $\M_C \coloneqq (E, \rk_{M_C})$ with rank function $\rk_{M_C}\coloneqq \mathrm{dim}(C|X)$ for each subset $X \subseteq E$, where $C|X$ is the linear code obtained by removing the coordinates $E - X$ from each codeword of $C$. With this definition we can compute the Tutte polynomial for a matroid belonging to a code. In his paper \cite{Gr1976} from 1976 Curtis Greene showed how the weight enumerator of a linear code can be expressed as an evaluation of the Tutte polynomial. The result is known as \textit{Greene's theorem} and is celebrated because it created a link between coding theory and matroid theory. \\
%\indent Connections between the Tutte polynomial and the Potts and Ising model from statistical mechanics can be found in \cite{ElMo2022}, where its stated that the Potts and random-cluster partition functions may be viewed as evaluations of the Tutte polynomial. \\
%\indent In this thesis, we showed the universality of the Tutte polynomial for graphs and matroids. The study about the Tutte polynomial and more specifically its connections to different scientific fields is very young, therefore there are still many open questions. We want to point out once more, that the "Handbook of the Tutte Polynomial and Related Topics" \cite{ElMo2022} was published recently and gives a great overview of the Tutte polynomial properties. More specifically, its fundamental properties on graphs and matroids, its exact complexity and approximations, and its specializations and applications. 


\newpage
\bibliographystyle{alpha}
\bibliography{refs}

%\begin{thebibliography}{Lam00}
  % Literaturbeispiel: Buch
%  \bibitem[GoRo01]{Godsil/Royle: 2001} Chris Godsil, Gordon Royle: \textit{Algebraic Graph Theory} Springer, 2001
%\bibitem[ElMo22]{El/Mo: 2022} edited by Joanna A. Ellis-Monaghan and Iain Moffatt: \textit{Handbook of the Tutte Polynomial and Related Topics} CRC Press, 2022
%\bibitem[Bol98]{Bol: 1998} Béla Bollobás: \textit{Modern Graph Theory} Springer, 1998
%\bibitem[Oxley11]{Oxley: 2011} James Oxley: \textit{Matroid Theory} Oxford University Press, 2011
%\bibitem[Welsh93]{Welsh: 1993} Dominic James Anthony Welsh: \textit{Complexity: Knots, Colourings and Counting} Cambridge University Press, 1993
%\bibitem[Welsh76]{Welsh: 1976} Dominic James Anthony Welsh: 
%\textit{Matroid Theory} Academic Press Inc.
%\bibitem[Wilson86]{Wilson: 1986} Robin James Wilson: %\textit{Introduction to Graph Theory} Longman Scientific $\&$ Technical
%\end{thebibliography}
 
      
  % ggf. hier Tabelle mit Symbolen 
  % (kann auch auf das Inhaltsverzeichnis folgen)
 


%\vspace*{8cm}
%
%\section*{Erkl\"arung}

%Hier kommt die Erklärung.
%\\[2ex] 

%\noindent
%Ort, den Datum\\[5ex]

% Unterschrift (handgeschrieben)



\end{document}
